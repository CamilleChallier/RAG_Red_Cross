{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizer head evaluation\n",
    "\n",
    "Assess the quality of the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nvme/home/durech/camille/rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    ServiceContext)\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "from llama_index.core.evaluation import (\n",
    "    BatchEvalRunner,\n",
    "    FaithfulnessEvaluator,\n",
    "    RelevancyEvaluator\n",
    ")\n",
    "\n",
    "from finetuning import get_tuned_model\n",
    "from text_generation_evaluation import generate_broad_qa, get_topic_lists_from_pdf, preprocess\n",
    "\n",
    "\n",
    "qa_dataset_path = \"../data/icrc_qa_dataset_semantic2_2_1024.pkl\"\n",
    "nodes_path = \"../data/nodes_icrc_semantic2_2_1024.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.1, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "/mnt/nvme/home/durech/camille/rag/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:210: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/mnt/nvme/home/durech/camille/rag/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
      "/mnt/nvme/home/durech/camille/rag/lib/python3.10/site-packages/sentence_transformers/models/Dense.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(input_path, \"pytorch_model.bin\"), map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "embed_model = get_tuned_model(\"test_model\") # load previously tuned model in embedding_finetuning.ipynb\n",
    "# embed_model = \"dunzhang/stella_en_400M_v5\"\n",
    "# embed_model = HuggingFaceEmbedding(model_name =embed_model, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset of precise queries\n",
    "nodes = pickle.load(open(nodes_path,'rb'))\n",
    "qa_dataset = pickle.load(open(qa_dataset_path,'rb')) # generated in data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 17 key-value pairs and 581 tensors from /tmp/llama_index/models/gpt2-xl.Q5_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = gpt2\n",
      "llama_model_loader: - kv   1:                               general.name str              = gpt2-xl\n",
      "llama_model_loader: - kv   2:                           gpt2.block_count u32              = 48\n",
      "llama_model_loader: - kv   3:                        gpt2.context_length u32              = 1024\n",
      "llama_model_loader: - kv   4:                      gpt2.embedding_length u32              = 1600\n",
      "llama_model_loader: - kv   5:                   gpt2.feed_forward_length u32              = 6400\n",
      "llama_model_loader: - kv   6:                  gpt2.attention.head_count u32              = 25\n",
      "llama_model_loader: - kv   7:          gpt2.attention.layer_norm_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv   8:                          general.file_type u32              = 17\n",
      "llama_model_loader: - kv   9:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  10:                         tokenizer.ggml.pre str              = gpt-2\n",
      "llama_model_loader: - kv  11:                      tokenizer.ggml.tokens arr[str,50257]   = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  12:                  tokenizer.ggml.token_type arr[i32,50257]   = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.merges arr[str,50000]   = [\"Ġ t\", \"Ġ a\", \"h e\", \"i n\", \"r e\",...\n",
      "llama_model_loader: - kv  14:                tokenizer.ggml.bos_token_id u32              = 50256\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.eos_token_id u32              = 50256\n",
      "llama_model_loader: - kv  16:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  386 tensors\n",
      "llama_model_loader: - type  f16:    1 tensors\n",
      "llama_model_loader: - type q5_1:   97 tensors\n",
      "llama_model_loader: - type q8_0:   49 tensors\n",
      "llama_model_loader: - type q5_K:   24 tensors\n",
      "llama_model_loader: - type q6_K:   24 tensors\n",
      "llm_load_vocab: special tokens cache size = 1\n",
      "llm_load_vocab: token to piece cache size = 0.3060 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = gpt2\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 50257\n",
      "llm_load_print_meta: n_merges         = 50000\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 1024\n",
      "llm_load_print_meta: n_embd           = 1600\n",
      "llm_load_print_meta: n_layer          = 48\n",
      "llm_load_print_meta: n_head           = 25\n",
      "llm_load_print_meta: n_head_kv        = 25\n",
      "llm_load_print_meta: n_rot            = 64\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 64\n",
      "llm_load_print_meta: n_embd_head_v    = 64\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1600\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1600\n",
      "llm_load_print_meta: f_norm_eps       = 1.0e-05\n",
      "llm_load_print_meta: f_norm_rms_eps   = 0.0e+00\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 6400\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = -1\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 1024\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 1.5B\n",
      "llm_load_print_meta: model ftype      = Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 1.64 B\n",
      "llm_load_print_meta: model size       = 1.28 GiB (6.72 BPW) \n",
      "llm_load_print_meta: general.name     = gpt2-xl\n",
      "llm_load_print_meta: BOS token        = 50256 '<|endoftext|>'\n",
      "llm_load_print_meta: EOS token        = 50256 '<|endoftext|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 50256 '<|endoftext|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: ggml ctx size =    0.25 MiB\n",
      "llm_load_tensors:        CPU buffer size =  1312.32 MiB\n",
      "............................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 3904\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  1143.75 MiB\n",
      "llama_new_context_with_model: KV self size  = 1143.75 MiB, K (f16):  571.88 MiB, V (f16):  571.88 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.19 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   204.51 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1785\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'general.architecture': 'gpt2', 'gpt2.context_length': '1024', 'gpt2.block_count': '48', 'gpt2.embedding_length': '1600', 'gpt2.attention.head_count': '25', 'gpt2.attention.layer_norm_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '50256', 'general.file_type': '17', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.name': 'gpt2-xl', 'gpt2.feed_forward_length': '6400', 'tokenizer.ggml.pre': 'gpt-2', 'tokenizer.ggml.eos_token_id': '50256'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "# model_url = \"https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf\"\n",
    "# llm = LlamaCPP(\n",
    "#     model_url=model_url,\n",
    "#     model_path=None,\n",
    "#     temperature=0.1,\n",
    "#     max_new_tokens=512,\n",
    "#     context_window=3900,\n",
    "#     generate_kwargs={},\n",
    "#     model_kwargs={\"n_gpu_layers\": -1},\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "# model_url = \"https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF/resolve/main/mistral-7b-instruct-v0.2.Q5_K_M.gguf\"\n",
    "# llm = LlamaCPP(\n",
    "#     model_url=model_url,\n",
    "#     model_path=None,\n",
    "#     temperature=0.1,\n",
    "#     max_new_tokens=512,\n",
    "#     context_window=3900,\n",
    "#     generate_kwargs={},\n",
    "#     model_kwargs={\"n_gpu_layers\": -1},\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "model_url = \"https://huggingface.co/RichardErkhov/openai-community_-_gpt2-xl-gguf/resolve/main/gpt2-xl.Q5_K_M.gguf\"\n",
    "llm = LlamaCPP(\n",
    "    model_url=model_url,\n",
    "    model_path=None,\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=512,\n",
    "    context_window=3900,\n",
    "    generate_kwargs={},\n",
    "    model_kwargs={\"n_gpu_layers\": -1},\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with precise queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 2048/2048 [01:02<00:00, 32.64it/s]\n",
      "Generating embeddings: 100%|██████████| 2048/2048 [01:09<00:00, 29.45it/s]\n",
      "Generating embeddings: 100%|██████████| 2048/2048 [01:06<00:00, 30.89it/s]\n",
      "Generating embeddings: 100%|██████████| 2048/2048 [00:34<00:00, 58.54it/s]\n",
      "Generating embeddings: 100%|██████████| 2048/2048 [00:34<00:00, 58.96it/s]\n",
      "Generating embeddings: 100%|██████████| 2048/2048 [00:38<00:00, 53.01it/s]\n",
      "Generating embeddings: 100%|██████████| 2048/2048 [00:42<00:00, 48.69it/s]\n",
      "Generating embeddings: 100%|██████████| 2048/2048 [00:42<00:00, 48.27it/s]\n",
      "Generating embeddings: 100%|██████████| 2048/2048 [00:42<00:00, 47.69it/s]\n",
      "Generating embeddings: 100%|██████████| 2048/2048 [00:43<00:00, 46.82it/s]\n",
      "Generating embeddings: 100%|██████████| 2048/2048 [00:54<00:00, 37.62it/s]\n",
      "Generating embeddings: 100%|██████████| 1295/1295 [00:27<00:00, 47.87it/s]\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex(nodes, embed_model=embed_model, show_progress=True, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(qa_dataset.queries.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_503972/358280397.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /    28 runs   (    0.14 ms per token,  7045.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7884.27 ms /   309 tokens (   25.52 ms per token,    39.19 tokens per second)\n",
      "llama_print_timings:        eval time =    2762.87 ms /    27 runs   (  102.33 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =   10659.92 ms /   336 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      49.83 ms /   322 runs   (    0.15 ms per token,  6462.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20884.63 ms /   970 tokens (   21.53 ms per token,    46.45 tokens per second)\n",
      "llama_print_timings:        eval time =   34151.31 ms /   321 runs   (  106.39 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =   55227.06 ms /  1291 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      49.16 ms /   286 runs   (    0.17 ms per token,  5818.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   57404.67 ms /  2371 tokens (   24.21 ms per token,    41.30 tokens per second)\n",
      "llama_print_timings:        eval time =   32873.83 ms /   285 runs   (  115.35 ms per token,     8.67 tokens per second)\n",
      "llama_print_timings:       total time =   90528.25 ms /  2656 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      28.24 ms /   170 runs   (    0.17 ms per token,  6020.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =   37989.09 ms /  1610 tokens (   23.60 ms per token,    42.38 tokens per second)\n",
      "llama_print_timings:        eval time =   18811.85 ms /   169 runs   (  111.31 ms per token,     8.98 tokens per second)\n",
      "llama_print_timings:       total time =   56925.66 ms /  1779 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      29.83 ms /   170 runs   (    0.18 ms per token,  5699.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12635.97 ms /   497 tokens (   25.42 ms per token,    39.33 tokens per second)\n",
      "llama_print_timings:        eval time =   17897.58 ms /   169 runs   (  105.90 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =   30655.85 ms /   666 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      12.15 ms /    70 runs   (    0.17 ms per token,  5760.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11882.98 ms /   475 tokens (   25.02 ms per token,    39.97 tokens per second)\n",
      "llama_print_timings:        eval time =    7277.81 ms /    69 runs   (  105.48 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =   19204.90 ms /   544 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    42 runs   (    0.15 ms per token,  6466.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   45035.37 ms /  1708 tokens (   26.37 ms per token,    37.93 tokens per second)\n",
      "llama_print_timings:        eval time =    4503.04 ms /    41 runs   (  109.83 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =   49560.05 ms /  1749 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      49.38 ms /   276 runs   (    0.18 ms per token,  5589.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   26440.60 ms /  1016 tokens (   26.02 ms per token,    38.43 tokens per second)\n",
      "llama_print_timings:        eval time =   30017.98 ms /   275 runs   (  109.16 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =   56688.10 ms /  1291 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      14.24 ms /    87 runs   (    0.16 ms per token,  6110.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11279.65 ms /   447 tokens (   25.23 ms per token,    39.63 tokens per second)\n",
      "llama_print_timings:        eval time =    8918.13 ms /    86 runs   (  103.70 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =   20240.31 ms /   533 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      61.18 ms /   373 runs   (    0.16 ms per token,  6096.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   24680.21 ms /   937 tokens (   26.34 ms per token,    37.97 tokens per second)\n",
      "llama_print_timings:        eval time =   39830.07 ms /   372 runs   (  107.07 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =   64743.29 ms /  1309 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      20.87 ms /   132 runs   (    0.16 ms per token,  6325.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   44617.46 ms /  1699 tokens (   26.26 ms per token,    38.08 tokens per second)\n",
      "llama_print_timings:        eval time =   14448.45 ms /   131 runs   (  110.29 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =   59137.84 ms /  1830 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    44 runs   (    0.16 ms per token,  6287.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   34152.59 ms /  1244 tokens (   27.45 ms per token,    36.42 tokens per second)\n",
      "llama_print_timings:        eval time =    4617.35 ms /    43 runs   (  107.38 ms per token,     9.31 tokens per second)\n",
      "llama_print_timings:       total time =   38791.98 ms /  1287 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      11.25 ms /    67 runs   (    0.17 ms per token,  5957.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =   62112.94 ms /  2296 tokens (   27.05 ms per token,    36.96 tokens per second)\n",
      "llama_print_timings:        eval time =    7578.88 ms /    66 runs   (  114.83 ms per token,     8.71 tokens per second)\n",
      "llama_print_timings:       total time =   69740.26 ms /  2362 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      35.94 ms /   223 runs   (    0.16 ms per token,  6205.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7230.13 ms /   306 tokens (   23.63 ms per token,    42.32 tokens per second)\n",
      "llama_print_timings:        eval time =   23264.73 ms /   222 runs   (  104.80 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =   30656.85 ms /   528 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      38.77 ms /   247 runs   (    0.16 ms per token,  6370.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13046.50 ms /   529 tokens (   24.66 ms per token,    40.55 tokens per second)\n",
      "llama_print_timings:        eval time =   26141.74 ms /   246 runs   (  106.27 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =   39375.36 ms /   775 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      54.64 ms /   308 runs   (    0.18 ms per token,  5636.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22466.24 ms /   870 tokens (   25.82 ms per token,    38.72 tokens per second)\n",
      "llama_print_timings:        eval time =   33305.97 ms /   307 runs   (  108.49 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =   56037.84 ms /  1177 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      12.93 ms /    74 runs   (    0.17 ms per token,  5724.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19239.08 ms /   731 tokens (   26.32 ms per token,    38.00 tokens per second)\n",
      "llama_print_timings:        eval time =    7820.15 ms /    73 runs   (  107.13 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =   27106.74 ms /   804 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      22.98 ms /   139 runs   (    0.17 ms per token,  6049.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13403.11 ms /   512 tokens (   26.18 ms per token,    38.20 tokens per second)\n",
      "llama_print_timings:        eval time =   14371.94 ms /   138 runs   (  104.14 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =   27848.02 ms /   650 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      16.51 ms /    91 runs   (    0.18 ms per token,  5512.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8216.75 ms /   323 tokens (   25.44 ms per token,    39.31 tokens per second)\n",
      "llama_print_timings:        eval time =    9455.06 ms /    90 runs   (  105.06 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =   17731.97 ms /   413 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      16.59 ms /    94 runs   (    0.18 ms per token,  5665.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8837.63 ms /   328 tokens (   26.94 ms per token,    37.11 tokens per second)\n",
      "llama_print_timings:        eval time =    9762.11 ms /    93 runs   (  104.97 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =   18660.77 ms /   421 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      53.78 ms /   319 runs   (    0.17 ms per token,  5931.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14152.86 ms /   544 tokens (   26.02 ms per token,    38.44 tokens per second)\n",
      "llama_print_timings:        eval time =   33303.73 ms /   318 runs   (  104.73 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =   47649.28 ms /   862 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      22.38 ms /   135 runs   (    0.17 ms per token,  6032.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20659.82 ms /   754 tokens (   27.40 ms per token,    36.50 tokens per second)\n",
      "llama_print_timings:        eval time =   14116.48 ms /   134 runs   (  105.35 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =   34847.02 ms /   888 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       5.85 ms /    37 runs   (    0.16 ms per token,  6320.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8439.28 ms /   338 tokens (   24.97 ms per token,    40.05 tokens per second)\n",
      "llama_print_timings:        eval time =    3705.78 ms /    36 runs   (  102.94 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =   12162.50 ms /   374 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      17.06 ms /   104 runs   (    0.16 ms per token,  6096.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8747.80 ms /   349 tokens (   25.07 ms per token,    39.90 tokens per second)\n",
      "llama_print_timings:        eval time =   10630.74 ms /   103 runs   (  103.21 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =   19430.88 ms /   452 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      45.41 ms /   275 runs   (    0.17 ms per token,  6056.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15393.16 ms /   585 tokens (   26.31 ms per token,    38.00 tokens per second)\n",
      "llama_print_timings:        eval time =   28713.61 ms /   274 runs   (  104.79 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =   44266.72 ms /   859 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      16.93 ms /   103 runs   (    0.16 ms per token,  6082.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =   46023.27 ms /  1749 tokens (   26.31 ms per token,    38.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11216.15 ms /   102 runs   (  109.96 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =   57295.67 ms /  1851 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      41.82 ms /   239 runs   (    0.17 ms per token,  5715.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   49265.36 ms /  1851 tokens (   26.62 ms per token,    37.57 tokens per second)\n",
      "llama_print_timings:        eval time =   26927.85 ms /   238 runs   (  113.14 ms per token,     8.84 tokens per second)\n",
      "llama_print_timings:       total time =   76390.58 ms /  2089 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      42.77 ms /   257 runs   (    0.17 ms per token,  6008.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19784.42 ms /   760 tokens (   26.03 ms per token,    38.41 tokens per second)\n",
      "llama_print_timings:        eval time =   27090.68 ms /   256 runs   (  105.82 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =   47024.86 ms /  1016 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      22.62 ms /   137 runs   (    0.17 ms per token,  6055.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10901.38 ms /   431 tokens (   25.29 ms per token,    39.54 tokens per second)\n",
      "llama_print_timings:        eval time =   14083.01 ms /   136 runs   (  103.55 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =   25055.17 ms /   567 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      23.72 ms /   144 runs   (    0.16 ms per token,  6071.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =   58760.63 ms /  2185 tokens (   26.89 ms per token,    37.18 tokens per second)\n",
      "llama_print_timings:        eval time =   16103.20 ms /   143 runs   (  112.61 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =   74946.20 ms /  2328 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      34.02 ms /   194 runs   (    0.18 ms per token,  5701.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   32991.02 ms /  1262 tokens (   26.14 ms per token,    38.25 tokens per second)\n",
      "llama_print_timings:        eval time =   21252.75 ms /   193 runs   (  110.12 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =   54395.50 ms /  1455 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      19.44 ms /   115 runs   (    0.17 ms per token,  5915.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   57594.32 ms /  2117 tokens (   27.21 ms per token,    36.76 tokens per second)\n",
      "llama_print_timings:        eval time =   13043.03 ms /   114 runs   (  114.41 ms per token,     8.74 tokens per second)\n",
      "llama_print_timings:       total time =   70721.19 ms /  2231 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      30.30 ms /   200 runs   (    0.15 ms per token,  6601.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   31226.00 ms /  1173 tokens (   26.62 ms per token,    37.56 tokens per second)\n",
      "llama_print_timings:        eval time =   21410.32 ms /   199 runs   (  107.59 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =   52745.08 ms /  1372 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      43.26 ms /   243 runs   (    0.18 ms per token,  5617.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21214.22 ms /   734 tokens (   28.90 ms per token,    34.60 tokens per second)\n",
      "llama_print_timings:        eval time =   26024.60 ms /   242 runs   (  107.54 ms per token,     9.30 tokens per second)\n",
      "llama_print_timings:       total time =   47433.43 ms /   976 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      41.40 ms /   260 runs   (    0.16 ms per token,  6280.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14798.08 ms /   581 tokens (   25.47 ms per token,    39.26 tokens per second)\n",
      "llama_print_timings:        eval time =   27115.41 ms /   259 runs   (  104.69 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =   42059.79 ms /   840 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      30.49 ms /   185 runs   (    0.16 ms per token,  6067.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15560.63 ms /   601 tokens (   25.89 ms per token,    38.62 tokens per second)\n",
      "llama_print_timings:        eval time =   19230.89 ms /   184 runs   (  104.52 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =   34890.70 ms /   785 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      23.04 ms /   140 runs   (    0.16 ms per token,  6077.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =   26386.56 ms /  1008 tokens (   26.18 ms per token,    38.20 tokens per second)\n",
      "llama_print_timings:        eval time =   14818.83 ms /   139 runs   (  106.61 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =   41280.92 ms /  1147 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      22.39 ms /   137 runs   (    0.16 ms per token,  6120.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   33541.69 ms /  1273 tokens (   26.35 ms per token,    37.95 tokens per second)\n",
      "llama_print_timings:        eval time =   14658.64 ms /   136 runs   (  107.78 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =   48273.81 ms /  1409 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      11.09 ms /    68 runs   (    0.16 ms per token,  6132.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5546.00 ms /   223 tokens (   24.87 ms per token,    40.21 tokens per second)\n",
      "llama_print_timings:        eval time =    6857.91 ms /    67 runs   (  102.36 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =   12437.33 ms /   290 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      10.75 ms /    67 runs   (    0.16 ms per token,  6231.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =   32861.86 ms /  1258 tokens (   26.12 ms per token,    38.28 tokens per second)\n",
      "llama_print_timings:        eval time =    7243.63 ms /    66 runs   (  109.75 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =   40148.74 ms /  1324 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      79.46 ms /   460 runs   (    0.17 ms per token,  5789.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   58207.87 ms /  2176 tokens (   26.75 ms per token,    37.38 tokens per second)\n",
      "llama_print_timings:        eval time =   52946.43 ms /   459 runs   (  115.35 ms per token,     8.67 tokens per second)\n",
      "llama_print_timings:       total time =  111629.15 ms /  2635 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      21.59 ms /   133 runs   (    0.16 ms per token,  6160.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12210.08 ms /   474 tokens (   25.76 ms per token,    38.82 tokens per second)\n",
      "llama_print_timings:        eval time =   13700.85 ms /   132 runs   (  103.79 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =   25978.45 ms /   606 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      49.92 ms /   307 runs   (    0.16 ms per token,  6149.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12696.68 ms /   500 tokens (   25.39 ms per token,    39.38 tokens per second)\n",
      "llama_print_timings:        eval time =   31941.40 ms /   306 runs   (  104.38 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =   44818.39 ms /   806 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      72.48 ms /   406 runs   (    0.18 ms per token,  5601.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16598.96 ms /   600 tokens (   27.66 ms per token,    36.15 tokens per second)\n",
      "llama_print_timings:        eval time =   43480.15 ms /   405 runs   (  107.36 ms per token,     9.31 tokens per second)\n",
      "llama_print_timings:       total time =   60464.58 ms /  1005 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      42.05 ms /   259 runs   (    0.16 ms per token,  6159.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16281.11 ms /   630 tokens (   25.84 ms per token,    38.70 tokens per second)\n",
      "llama_print_timings:        eval time =   27125.58 ms /   258 runs   (  105.14 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =   43553.74 ms /   888 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      13.13 ms /    85 runs   (    0.15 ms per token,  6471.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8441.30 ms /   251 tokens (   33.63 ms per token,    29.73 tokens per second)\n",
      "llama_print_timings:        eval time =    8615.35 ms /    84 runs   (  102.56 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =   17096.80 ms /   335 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      21.70 ms /   142 runs   (    0.15 ms per token,  6542.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10480.63 ms /   415 tokens (   25.25 ms per token,    39.60 tokens per second)\n",
      "llama_print_timings:        eval time =   14612.68 ms /   141 runs   (  103.64 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =   25164.13 ms /   556 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      48.91 ms /   277 runs   (    0.18 ms per token,  5663.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =   24515.50 ms /   946 tokens (   25.91 ms per token,    38.59 tokens per second)\n",
      "llama_print_timings:        eval time =   30031.90 ms /   276 runs   (  108.81 ms per token,     9.19 tokens per second)\n",
      "llama_print_timings:       total time =   54778.59 ms /  1222 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    48 runs   (    0.15 ms per token,  6454.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8511.02 ms /   326 tokens (   26.11 ms per token,    38.30 tokens per second)\n",
      "llama_print_timings:        eval time =    4843.36 ms /    47 runs   (  103.05 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =   13376.72 ms /   373 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      70.43 ms /   425 runs   (    0.17 ms per token,  6034.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =   39322.30 ms /  1501 tokens (   26.20 ms per token,    38.17 tokens per second)\n",
      "llama_print_timings:        eval time =   46337.90 ms /   424 runs   (  109.29 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:       total time =   85944.14 ms /  1925 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      49.93 ms /   309 runs   (    0.16 ms per token,  6188.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17490.44 ms /   615 tokens (   28.44 ms per token,    35.16 tokens per second)\n",
      "llama_print_timings:        eval time =   32378.95 ms /   308 runs   (  105.13 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =   50050.25 ms /   923 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      36.77 ms /   225 runs   (    0.16 ms per token,  6118.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9236.40 ms /   367 tokens (   25.17 ms per token,    39.73 tokens per second)\n",
      "llama_print_timings:        eval time =   23179.03 ms /   224 runs   (  103.48 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =   32538.65 ms /   591 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.37 ms /    61 runs   (    0.15 ms per token,  6512.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9878.28 ms /   392 tokens (   25.20 ms per token,    39.68 tokens per second)\n",
      "llama_print_timings:        eval time =    6201.53 ms /    60 runs   (  103.36 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =   16108.70 ms /   452 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      10.37 ms /    59 runs   (    0.18 ms per token,  5687.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =   53779.49 ms /  2010 tokens (   26.76 ms per token,    37.37 tokens per second)\n",
      "llama_print_timings:        eval time =    6608.26 ms /    58 runs   (  113.94 ms per token,     8.78 tokens per second)\n",
      "llama_print_timings:       total time =   60428.90 ms /  2068 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      48.99 ms /   299 runs   (    0.16 ms per token,  6102.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16908.61 ms /   653 tokens (   25.89 ms per token,    38.62 tokens per second)\n",
      "llama_print_timings:        eval time =   31321.46 ms /   298 runs   (  105.11 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =   48405.24 ms /   951 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      19.19 ms /   108 runs   (    0.18 ms per token,  5629.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   25762.91 ms /   979 tokens (   26.32 ms per token,    38.00 tokens per second)\n",
      "llama_print_timings:        eval time =   11629.45 ms /   107 runs   (  108.69 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =   37465.98 ms /  1086 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      11.02 ms /    68 runs   (    0.16 ms per token,  6173.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10814.76 ms /   430 tokens (   25.15 ms per token,    39.76 tokens per second)\n",
      "llama_print_timings:        eval time =    6934.11 ms /    67 runs   (  103.49 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =   17781.15 ms /   497 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      24.58 ms /   147 runs   (    0.17 ms per token,  5979.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   42982.63 ms /  1615 tokens (   26.61 ms per token,    37.57 tokens per second)\n",
      "llama_print_timings:        eval time =   15974.19 ms /   146 runs   (  109.41 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =   59038.63 ms /  1761 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      44.61 ms /   276 runs   (    0.16 ms per token,  6187.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   29880.15 ms /  1144 tokens (   26.12 ms per token,    38.29 tokens per second)\n",
      "llama_print_timings:        eval time =   29610.48 ms /   275 runs   (  107.67 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =   59656.44 ms /  1419 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      24.33 ms /   134 runs   (    0.18 ms per token,  5507.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10958.57 ms /   372 tokens (   29.46 ms per token,    33.95 tokens per second)\n",
      "llama_print_timings:        eval time =   13997.49 ms /   133 runs   (  105.24 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =   25049.25 ms /   505 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.95 ms /    62 runs   (    0.16 ms per token,  6231.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =   25008.55 ms /   963 tokens (   25.97 ms per token,    38.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6478.54 ms /    61 runs   (  106.21 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =   31517.72 ms /  1024 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    27 runs   (    0.16 ms per token,  6264.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17091.67 ms /   665 tokens (   25.70 ms per token,    38.91 tokens per second)\n",
      "llama_print_timings:        eval time =    2715.06 ms /    26 runs   (  104.43 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =   19819.47 ms /   691 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      26.26 ms /   165 runs   (    0.16 ms per token,  6283.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   36588.54 ms /  1398 tokens (   26.17 ms per token,    38.21 tokens per second)\n",
      "llama_print_timings:        eval time =   17791.98 ms /   164 runs   (  108.49 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =   54470.61 ms /  1562 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       6.03 ms /    39 runs   (    0.15 ms per token,  6467.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5284.07 ms /   183 tokens (   28.87 ms per token,    34.63 tokens per second)\n",
      "llama_print_timings:        eval time =    3881.93 ms /    38 runs   (  102.16 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =    9184.26 ms /   221 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    45 runs   (    0.16 ms per token,  6170.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7323.45 ms /   272 tokens (   26.92 ms per token,    37.14 tokens per second)\n",
      "llama_print_timings:        eval time =    4561.14 ms /    44 runs   (  103.66 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =   11906.40 ms /   316 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      19.91 ms /   125 runs   (    0.16 ms per token,  6276.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   23349.44 ms /   802 tokens (   29.11 ms per token,    34.35 tokens per second)\n",
      "llama_print_timings:        eval time =   13067.87 ms /   124 runs   (  105.39 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =   36483.08 ms /   926 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      20.33 ms /   126 runs   (    0.16 ms per token,  6197.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7806.90 ms /   312 tokens (   25.02 ms per token,    39.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12877.73 ms /   125 runs   (  103.02 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =   20748.08 ms /   437 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    30 runs   (    0.16 ms per token,  6415.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11126.11 ms /   438 tokens (   25.40 ms per token,    39.37 tokens per second)\n",
      "llama_print_timings:        eval time =    3002.69 ms /    29 runs   (  103.54 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =   14142.13 ms /   467 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      11.50 ms /    72 runs   (    0.16 ms per token,  6262.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6419.87 ms /   257 tokens (   24.98 ms per token,    40.03 tokens per second)\n",
      "llama_print_timings:        eval time =    7280.10 ms /    71 runs   (  102.54 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =   13735.89 ms /   328 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      49.00 ms /   297 runs   (    0.16 ms per token,  6061.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13399.33 ms /   514 tokens (   26.07 ms per token,    38.36 tokens per second)\n",
      "llama_print_timings:        eval time =   30921.32 ms /   296 runs   (  104.46 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =   44494.52 ms /   810 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      40.05 ms /   252 runs   (    0.16 ms per token,  6292.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21340.01 ms /   824 tokens (   25.90 ms per token,    38.61 tokens per second)\n",
      "llama_print_timings:        eval time =   26591.64 ms /   251 runs   (  105.94 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =   48074.24 ms /  1075 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      81.77 ms /   512 runs   (    0.16 ms per token,  6261.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   28341.62 ms /  1087 tokens (   26.07 ms per token,    38.35 tokens per second)\n",
      "llama_print_timings:        eval time =   55278.63 ms /   511 runs   (  108.18 ms per token,     9.24 tokens per second)\n",
      "llama_print_timings:       total time =   83972.94 ms /  1598 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      69.39 ms /   426 runs   (    0.16 ms per token,  6138.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19637.78 ms /   768 tokens (   25.57 ms per token,    39.11 tokens per second)\n",
      "llama_print_timings:        eval time =   45082.57 ms /   425 runs   (  106.08 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =   64993.94 ms /  1193 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     5 runs   (    0.17 ms per token,  5760.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13808.26 ms /   531 tokens (   26.00 ms per token,    38.46 tokens per second)\n",
      "llama_print_timings:        eval time =     416.62 ms /     4 runs   (  104.15 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =   14227.56 ms /   535 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    38 runs   (    0.16 ms per token,  6215.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   35604.49 ms /  1366 tokens (   26.06 ms per token,    38.37 tokens per second)\n",
      "llama_print_timings:        eval time =    4000.77 ms /    37 runs   (  108.13 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =   39624.76 ms /  1403 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      37.20 ms /   227 runs   (    0.16 ms per token,  6101.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   50111.02 ms /  1883 tokens (   26.61 ms per token,    37.58 tokens per second)\n",
      "llama_print_timings:        eval time =   25195.04 ms /   226 runs   (  111.48 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =   75441.82 ms /  2109 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     4 runs   (    0.16 ms per token,  6230.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11176.61 ms /   443 tokens (   25.23 ms per token,    39.64 tokens per second)\n",
      "llama_print_timings:        eval time =     311.04 ms /     3 runs   (  103.68 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =   11489.50 ms /   446 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      15.94 ms /    90 runs   (    0.18 ms per token,  5646.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11504.83 ms /   448 tokens (   25.68 ms per token,    38.94 tokens per second)\n",
      "llama_print_timings:        eval time =    9406.33 ms /    89 runs   (  105.69 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =   20969.87 ms /   537 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      28.40 ms /   182 runs   (    0.16 ms per token,  6407.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16595.38 ms /   640 tokens (   25.93 ms per token,    38.56 tokens per second)\n",
      "llama_print_timings:        eval time =   18992.95 ms /   181 runs   (  104.93 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =   35684.69 ms /   821 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    34 runs   (    0.15 ms per token,  6529.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   37358.39 ms /  1408 tokens (   26.53 ms per token,    37.69 tokens per second)\n",
      "llama_print_timings:        eval time =    3580.88 ms /    33 runs   (  108.51 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =   40955.81 ms /  1441 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      29.34 ms /   181 runs   (    0.16 ms per token,  6169.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   59227.69 ms /  2204 tokens (   26.87 ms per token,    37.21 tokens per second)\n",
      "llama_print_timings:        eval time =   20204.62 ms /   180 runs   (  112.25 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =   79538.16 ms /  2384 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      56.01 ms /   353 runs   (    0.16 ms per token,  6302.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22566.23 ms /   882 tokens (   25.59 ms per token,    39.08 tokens per second)\n",
      "llama_print_timings:        eval time =   37468.60 ms /   352 runs   (  106.44 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =   60253.26 ms /  1234 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      26.20 ms /   161 runs   (    0.16 ms per token,  6144.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12240.52 ms /   470 tokens (   26.04 ms per token,    38.40 tokens per second)\n",
      "llama_print_timings:        eval time =   16624.98 ms /   160 runs   (  103.91 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =   28950.30 ms /   630 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      16.18 ms /   104 runs   (    0.16 ms per token,  6428.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =   44940.77 ms /  1688 tokens (   26.62 ms per token,    37.56 tokens per second)\n",
      "llama_print_timings:        eval time =   11299.36 ms /   103 runs   (  109.70 ms per token,     9.12 tokens per second)\n",
      "llama_print_timings:       total time =   56295.72 ms /  1791 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      18.49 ms /   104 runs   (    0.18 ms per token,  5624.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7202.78 ms /   271 tokens (   26.58 ms per token,    37.62 tokens per second)\n",
      "llama_print_timings:        eval time =   10781.96 ms /   103 runs   (  104.68 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =   18053.43 ms /   374 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      15.81 ms /    96 runs   (    0.16 ms per token,  6072.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7794.78 ms /   312 tokens (   24.98 ms per token,    40.03 tokens per second)\n",
      "llama_print_timings:        eval time =    9782.18 ms /    95 runs   (  102.97 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =   17624.11 ms /   407 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      32.22 ms /   181 runs   (    0.18 ms per token,  5617.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20841.94 ms /   809 tokens (   25.76 ms per token,    38.82 tokens per second)\n",
      "llama_print_timings:        eval time =   19409.77 ms /   180 runs   (  107.83 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =   40386.42 ms /   989 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      53.92 ms /   301 runs   (    0.18 ms per token,  5582.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20592.09 ms /   797 tokens (   25.84 ms per token,    38.70 tokens per second)\n",
      "llama_print_timings:        eval time =   32411.69 ms /   300 runs   (  108.04 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:       total time =   53260.35 ms /  1097 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      36.28 ms /   200 runs   (    0.18 ms per token,  5512.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14099.75 ms /   532 tokens (   26.50 ms per token,    37.73 tokens per second)\n",
      "llama_print_timings:        eval time =   21170.68 ms /   199 runs   (  106.39 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =   35422.67 ms /   731 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      62.33 ms /   379 runs   (    0.16 ms per token,  6080.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =   28482.39 ms /  1086 tokens (   26.23 ms per token,    38.13 tokens per second)\n",
      "llama_print_timings:        eval time =   40712.09 ms /   378 runs   (  107.70 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =   69438.11 ms /  1464 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      50.30 ms /   306 runs   (    0.16 ms per token,  6082.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   60480.02 ms /  2230 tokens (   27.12 ms per token,    36.87 tokens per second)\n",
      "llama_print_timings:        eval time =   34337.45 ms /   305 runs   (  112.58 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =   95014.53 ms /  2535 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      55.71 ms /   344 runs   (    0.16 ms per token,  6175.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   33461.04 ms /  1264 tokens (   26.47 ms per token,    37.78 tokens per second)\n",
      "llama_print_timings:        eval time =   37180.51 ms /   343 runs   (  108.40 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =   70857.49 ms /  1607 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      26.45 ms /   156 runs   (    0.17 ms per token,  5897.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   57311.76 ms /  2130 tokens (   26.91 ms per token,    37.17 tokens per second)\n",
      "llama_print_timings:        eval time =   17744.59 ms /   155 runs   (  114.48 ms per token,     8.74 tokens per second)\n",
      "llama_print_timings:       total time =   75174.89 ms /  2285 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      14.49 ms /    91 runs   (    0.16 ms per token,  6281.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7535.98 ms /   286 tokens (   26.35 ms per token,    37.95 tokens per second)\n",
      "llama_print_timings:        eval time =    9262.12 ms /    90 runs   (  102.91 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =   16842.83 ms /   376 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      47.31 ms /   289 runs   (    0.16 ms per token,  6108.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20071.36 ms /   763 tokens (   26.31 ms per token,    38.01 tokens per second)\n",
      "llama_print_timings:        eval time =   30451.11 ms /   288 runs   (  105.73 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =   50690.33 ms /  1051 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      53.35 ms /   336 runs   (    0.16 ms per token,  6298.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10128.83 ms /   402 tokens (   25.20 ms per token,    39.69 tokens per second)\n",
      "llama_print_timings:        eval time =   34839.48 ms /   335 runs   (  104.00 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =   45166.59 ms /   737 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      14.05 ms /    90 runs   (    0.16 ms per token,  6405.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   36805.88 ms /  1403 tokens (   26.23 ms per token,    38.12 tokens per second)\n",
      "llama_print_timings:        eval time =    9672.60 ms /    89 runs   (  108.68 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =   46525.00 ms /  1492 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      36.46 ms /   224 runs   (    0.16 ms per token,  6143.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   27966.72 ms /  1081 tokens (   25.87 ms per token,    38.65 tokens per second)\n",
      "llama_print_timings:        eval time =   23902.24 ms /   223 runs   (  107.18 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =   51995.55 ms /  1304 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      17.97 ms /   113 runs   (    0.16 ms per token,  6287.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   36091.81 ms /  1370 tokens (   26.34 ms per token,    37.96 tokens per second)\n",
      "llama_print_timings:        eval time =   12131.15 ms /   112 runs   (  108.31 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =   48281.62 ms /  1482 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      81.22 ms /   463 runs   (    0.18 ms per token,  5700.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   57885.15 ms /  2168 tokens (   26.70 ms per token,    37.45 tokens per second)\n",
      "llama_print_timings:        eval time =   52785.34 ms /   462 runs   (  114.25 ms per token,     8.75 tokens per second)\n",
      "llama_print_timings:       total time =  111115.46 ms /  2630 tokens\n",
      "100%|██████████| 100/100 [1:13:42<00:00, 44.23s/it]    \n",
      "  0%|          | 0/200 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      49.23 ms /   294 runs   (    0.17 ms per token,  5971.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =   43702.12 ms /  1623 tokens (   26.93 ms per token,    37.14 tokens per second)\n",
      "llama_print_timings:        eval time =   32292.40 ms /   293 runs   (  110.21 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =   76174.92 ms /  1916 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     3 runs   (    0.18 ms per token,  5714.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14072.26 ms /   540 tokens (   26.06 ms per token,    38.37 tokens per second)\n",
      "llama_print_timings:        eval time =     208.86 ms /     2 runs   (  104.43 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =   14283.10 ms /   542 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      19.36 ms /   117 runs   (    0.17 ms per token,  6043.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =   27581.89 ms /  1064 tokens (   25.92 ms per token,    38.58 tokens per second)\n",
      "llama_print_timings:        eval time =   12402.53 ms /   116 runs   (  106.92 ms per token,     9.35 tokens per second)\n",
      "llama_print_timings:       total time =   40045.59 ms /  1180 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4878.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14178.60 ms /   552 tokens (   25.69 ms per token,    38.93 tokens per second)\n",
      "llama_print_timings:        eval time =     213.27 ms /     2 runs   (  106.63 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =   14393.50 ms /   554 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      10.28 ms /    62 runs   (    0.17 ms per token,  6031.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11799.17 ms /   386 tokens (   30.57 ms per token,    32.71 tokens per second)\n",
      "llama_print_timings:        eval time =    6289.35 ms /    61 runs   (  103.10 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =   18118.67 ms /   447 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      40.33 ms /   257 runs   (    0.16 ms per token,  6373.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   45497.18 ms /  1678 tokens (   27.11 ms per token,    36.88 tokens per second)\n",
      "llama_print_timings:        eval time =   28136.97 ms /   256 runs   (  109.91 ms per token,     9.10 tokens per second)\n",
      "llama_print_timings:       total time =   73785.25 ms /  1934 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    52 runs   (    0.17 ms per token,  6023.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9585.88 ms /   381 tokens (   25.16 ms per token,    39.75 tokens per second)\n",
      "llama_print_timings:        eval time =    5256.13 ms /    51 runs   (  103.06 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =   14866.30 ms /   432 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      33.37 ms /   180 runs   (    0.19 ms per token,  5393.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   56178.52 ms /  2103 tokens (   26.71 ms per token,    37.43 tokens per second)\n",
      "llama_print_timings:        eval time =   20477.36 ms /   179 runs   (  114.40 ms per token,     8.74 tokens per second)\n",
      "llama_print_timings:       total time =   76800.96 ms /  2282 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      18.50 ms /   114 runs   (    0.16 ms per token,  6163.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   39681.03 ms /  1505 tokens (   26.37 ms per token,    37.93 tokens per second)\n",
      "llama_print_timings:        eval time =   12345.13 ms /   113 runs   (  109.25 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:       total time =   52087.69 ms /  1618 tokens\n",
      "  0%|          | 1/200 [06:20<21:02:29, 380.65s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.52 ms /     3 runs   (    0.17 ms per token,  5747.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   23502.18 ms /   913 tokens (   25.74 ms per token,    38.85 tokens per second)\n",
      "llama_print_timings:        eval time =     216.52 ms /     2 runs   (  108.26 ms per token,     9.24 tokens per second)\n",
      "llama_print_timings:       total time =   23721.13 ms /   915 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      10.52 ms /    65 runs   (    0.16 ms per token,  6181.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   51109.74 ms /  1937 tokens (   26.39 ms per token,    37.90 tokens per second)\n",
      "llama_print_timings:        eval time =    7088.52 ms /    64 runs   (  110.76 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =   58233.39 ms /  2001 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      10.52 ms /    63 runs   (    0.17 ms per token,  5989.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =   44550.06 ms /  1672 tokens (   26.64 ms per token,    37.53 tokens per second)\n",
      "llama_print_timings:        eval time =    6778.57 ms /    62 runs   (  109.33 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:       total time =   51362.53 ms /  1734 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      14.49 ms /    92 runs   (    0.16 ms per token,  6349.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19128.74 ms /   750 tokens (   25.50 ms per token,    39.21 tokens per second)\n",
      "llama_print_timings:        eval time =    9560.84 ms /    91 runs   (  105.06 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =   28736.02 ms /   841 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    33 runs   (    0.18 ms per token,  5530.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =   28846.60 ms /  1091 tokens (   26.44 ms per token,    37.82 tokens per second)\n",
      "llama_print_timings:        eval time =    3480.32 ms /    32 runs   (  108.76 ms per token,     9.19 tokens per second)\n",
      "llama_print_timings:       total time =   32347.40 ms /  1123 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      10.92 ms /    62 runs   (    0.18 ms per token,  5679.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   38959.34 ms /  1492 tokens (   26.11 ms per token,    38.30 tokens per second)\n",
      "llama_print_timings:        eval time =    6791.42 ms /    61 runs   (  111.33 ms per token,     8.98 tokens per second)\n",
      "llama_print_timings:       total time =   45792.13 ms /  1553 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      18.41 ms /   117 runs   (    0.16 ms per token,  6353.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   38818.78 ms /  1471 tokens (   26.39 ms per token,    37.89 tokens per second)\n",
      "llama_print_timings:        eval time =   12606.39 ms /   116 runs   (  108.68 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =   51488.06 ms /  1587 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.73 ms /    58 runs   (    0.17 ms per token,  5961.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   24152.78 ms /   926 tokens (   26.08 ms per token,    38.34 tokens per second)\n",
      "llama_print_timings:        eval time =    6036.25 ms /    57 runs   (  105.90 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =   30217.82 ms /   983 tokens\n",
      "  4%|▍         | 9/200 [11:42<3:35:18, 67.64s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      20.56 ms /   114 runs   (    0.18 ms per token,  5544.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   77032.02 ms /  2808 tokens (   27.43 ms per token,    36.45 tokens per second)\n",
      "llama_print_timings:        eval time =   13268.70 ms /   113 runs   (  117.42 ms per token,     8.52 tokens per second)\n",
      "llama_print_timings:       total time =   90388.98 ms /  2921 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    55 runs   (    0.16 ms per token,  6403.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   34863.96 ms /  1313 tokens (   26.55 ms per token,    37.66 tokens per second)\n",
      "llama_print_timings:        eval time =    5816.28 ms /    54 runs   (  107.71 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =   40707.71 ms /  1367 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.52 ms /     3 runs   (    0.17 ms per token,  5825.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19588.64 ms /   761 tokens (   25.74 ms per token,    38.85 tokens per second)\n",
      "llama_print_timings:        eval time =     210.63 ms /     2 runs   (  105.32 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =   19801.63 ms /   763 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      25.60 ms /   141 runs   (    0.18 ms per token,  5507.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   72839.27 ms /  2643 tokens (   27.56 ms per token,    36.29 tokens per second)\n",
      "llama_print_timings:        eval time =   16342.10 ms /   140 runs   (  116.73 ms per token,     8.57 tokens per second)\n",
      "llama_print_timings:       total time =   89292.53 ms /  2783 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    31 runs   (    0.19 ms per token,  5354.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =   38672.03 ms /  1475 tokens (   26.22 ms per token,    38.14 tokens per second)\n",
      "llama_print_timings:        eval time =    3327.37 ms /    30 runs   (  110.91 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =   42020.39 ms /  1505 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      16.14 ms /    99 runs   (    0.16 ms per token,  6134.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17275.00 ms /   604 tokens (   28.60 ms per token,    34.96 tokens per second)\n",
      "llama_print_timings:        eval time =   10225.28 ms /    98 runs   (  104.34 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =   27550.57 ms /   702 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     3 runs   (    0.18 ms per token,  5535.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13149.69 ms /   505 tokens (   26.04 ms per token,    38.40 tokens per second)\n",
      "llama_print_timings:        eval time =     207.63 ms /     2 runs   (  103.82 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =   13358.84 ms /   507 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      14.69 ms /    87 runs   (    0.17 ms per token,  5923.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   34095.47 ms /  1303 tokens (   26.17 ms per token,    38.22 tokens per second)\n",
      "llama_print_timings:        eval time =    9269.73 ms /    86 runs   (  107.79 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =   43411.20 ms /  1389 tokens\n",
      "  8%|▊         | 17/200 [17:49<2:48:31, 55.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    30 runs   (    0.15 ms per token,  6665.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16775.47 ms /   644 tokens (   26.05 ms per token,    38.39 tokens per second)\n",
      "llama_print_timings:        eval time =    3027.57 ms /    29 runs   (  104.40 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =   19816.88 ms /   673 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    46 runs   (    0.17 ms per token,  6027.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8165.82 ms /   327 tokens (   24.97 ms per token,    40.04 tokens per second)\n",
      "llama_print_timings:        eval time =    4621.57 ms /    45 runs   (  102.70 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =   12809.50 ms /   372 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /    17 runs   (    0.19 ms per token,  5325.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =   52624.68 ms /  1965 tokens (   26.78 ms per token,    37.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1812.04 ms /    16 runs   (  113.25 ms per token,     8.83 tokens per second)\n",
      "llama_print_timings:       total time =   54448.67 ms /  1981 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    33 runs   (    0.17 ms per token,  5940.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11744.78 ms /   465 tokens (   25.26 ms per token,    39.59 tokens per second)\n",
      "llama_print_timings:        eval time =    3372.15 ms /    32 runs   (  105.38 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =   15136.15 ms /   497 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /    18 runs   (    0.17 ms per token,  5911.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   77909.96 ms /  2839 tokens (   27.44 ms per token,    36.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1951.72 ms /    17 runs   (  114.81 ms per token,     8.71 tokens per second)\n",
      "llama_print_timings:       total time =   79872.74 ms /  2856 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      32.81 ms /   180 runs   (    0.18 ms per token,  5485.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   47640.79 ms /  1790 tokens (   26.61 ms per token,    37.57 tokens per second)\n",
      "llama_print_timings:        eval time =   20149.93 ms /   179 runs   (  112.57 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =   67931.53 ms /  1969 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      13.38 ms /    72 runs   (    0.19 ms per token,  5380.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   60501.10 ms /  2247 tokens (   26.93 ms per token,    37.14 tokens per second)\n",
      "llama_print_timings:        eval time =    8171.40 ms /    71 runs   (  115.09 ms per token,     8.69 tokens per second)\n",
      "llama_print_timings:       total time =   68724.17 ms /  2318 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      16.42 ms /    99 runs   (    0.17 ms per token,  6029.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =   73011.96 ms /  2667 tokens (   27.38 ms per token,    36.53 tokens per second)\n",
      "llama_print_timings:        eval time =   11175.62 ms /    98 runs   (  114.04 ms per token,     8.77 tokens per second)\n",
      "llama_print_timings:       total time =   84244.37 ms /  2765 tokens\n",
      " 12%|█▎        | 25/200 [24:32<2:34:47, 53.07s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      10.64 ms /    66 runs   (    0.16 ms per token,  6204.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18513.77 ms /   712 tokens (   26.00 ms per token,    38.46 tokens per second)\n",
      "llama_print_timings:        eval time =    6825.55 ms /    65 runs   (  105.01 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =   25371.07 ms /   777 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.85 ms /    64 runs   (    0.15 ms per token,  6500.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   55629.15 ms /  2084 tokens (   26.69 ms per token,    37.46 tokens per second)\n",
      "llama_print_timings:        eval time =    7009.40 ms /    63 runs   (  111.26 ms per token,     8.99 tokens per second)\n",
      "llama_print_timings:       total time =   62673.56 ms /  2147 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4934.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21627.92 ms /   844 tokens (   25.63 ms per token,    39.02 tokens per second)\n",
      "llama_print_timings:        eval time =     215.84 ms /     2 runs   (  107.92 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =   21845.50 ms /   846 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      19.24 ms /   118 runs   (    0.16 ms per token,  6132.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14460.03 ms /   558 tokens (   25.91 ms per token,    38.59 tokens per second)\n",
      "llama_print_timings:        eval time =   12184.99 ms /   117 runs   (  104.15 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =   26705.24 ms /   675 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.84 ms /    58 runs   (    0.17 ms per token,  5894.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   29706.92 ms /  1108 tokens (   26.81 ms per token,    37.30 tokens per second)\n",
      "llama_print_timings:        eval time =    6092.33 ms /    57 runs   (  106.88 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =   35829.85 ms /  1165 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.62 ms /    56 runs   (    0.17 ms per token,  5822.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17632.21 ms /   669 tokens (   26.36 ms per token,    37.94 tokens per second)\n",
      "llama_print_timings:        eval time =    5755.69 ms /    55 runs   (  104.65 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =   23415.90 ms /   724 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      84.47 ms /   512 runs   (    0.16 ms per token,  6061.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   38539.29 ms /  1458 tokens (   26.43 ms per token,    37.83 tokens per second)\n",
      "llama_print_timings:        eval time =   55881.41 ms /   511 runs   (  109.36 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =   94794.03 ms /  1969 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      11.27 ms /    67 runs   (    0.17 ms per token,  5947.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   24390.21 ms /   952 tokens (   25.62 ms per token,    39.03 tokens per second)\n",
      "llama_print_timings:        eval time =    6987.85 ms /    66 runs   (  105.88 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =   31412.14 ms /  1018 tokens\n",
      " 16%|█▋        | 33/200 [29:54<2:13:48, 48.08s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    56 runs   (    0.16 ms per token,  6374.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   51186.29 ms /  1929 tokens (   26.54 ms per token,    37.69 tokens per second)\n",
      "llama_print_timings:        eval time =    6094.29 ms /    55 runs   (  110.81 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =   57310.78 ms /  1984 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      14.55 ms /    80 runs   (    0.18 ms per token,  5499.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =   34191.60 ms /  1290 tokens (   26.51 ms per token,    37.73 tokens per second)\n",
      "llama_print_timings:        eval time =    8705.38 ms /    79 runs   (  110.19 ms per token,     9.07 tokens per second)\n",
      "llama_print_timings:       total time =   42950.91 ms /  1369 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.56 ms /     3 runs   (    0.19 ms per token,  5328.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   33373.16 ms /  1276 tokens (   26.15 ms per token,    38.23 tokens per second)\n",
      "llama_print_timings:        eval time =     217.54 ms /     2 runs   (  108.77 ms per token,     9.19 tokens per second)\n",
      "llama_print_timings:       total time =   33593.19 ms /  1278 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      17.16 ms /    94 runs   (    0.18 ms per token,  5479.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   46643.56 ms /  1761 tokens (   26.49 ms per token,    37.75 tokens per second)\n",
      "llama_print_timings:        eval time =   10460.33 ms /    93 runs   (  112.48 ms per token,     8.89 tokens per second)\n",
      "llama_print_timings:       total time =   57171.12 ms /  1854 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      35.72 ms /   216 runs   (    0.17 ms per token,  6047.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =   39110.56 ms /  1478 tokens (   26.46 ms per token,    37.79 tokens per second)\n",
      "llama_print_timings:        eval time =   23439.31 ms /   215 runs   (  109.02 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =   62676.22 ms /  1693 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      13.56 ms /    74 runs   (    0.18 ms per token,  5458.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   29219.89 ms /  1098 tokens (   26.61 ms per token,    37.58 tokens per second)\n",
      "llama_print_timings:        eval time =    7951.00 ms /    73 runs   (  108.92 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =   37219.65 ms /  1171 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      10.23 ms /    64 runs   (    0.16 ms per token,  6257.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18680.38 ms /   714 tokens (   26.16 ms per token,    38.22 tokens per second)\n",
      "llama_print_timings:        eval time =    6605.94 ms /    63 runs   (  104.86 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =   25317.77 ms /   777 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      21.45 ms /   119 runs   (    0.18 ms per token,  5547.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =   34584.68 ms /  1318 tokens (   26.24 ms per token,    38.11 tokens per second)\n",
      "llama_print_timings:        eval time =   12980.46 ms /   118 runs   (  110.00 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =   47649.42 ms /  1436 tokens\n",
      " 20%|██        | 41/200 [35:58<2:04:57, 47.15s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       8.66 ms /    53 runs   (    0.16 ms per token,  6120.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17355.56 ms /   685 tokens (   25.34 ms per token,    39.47 tokens per second)\n",
      "llama_print_timings:        eval time =    5433.81 ms /    52 runs   (  104.50 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =   22816.06 ms /   737 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      12.38 ms /    77 runs   (    0.16 ms per token,  6217.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13837.18 ms /   546 tokens (   25.34 ms per token,    39.46 tokens per second)\n",
      "llama_print_timings:        eval time =    7890.76 ms /    76 runs   (  103.83 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =   21764.87 ms /   622 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     3 runs   (    0.18 ms per token,  5660.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   38344.33 ms /  1472 tokens (   26.05 ms per token,    38.39 tokens per second)\n",
      "llama_print_timings:        eval time =     218.15 ms /     2 runs   (  109.08 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =   38564.70 ms /  1474 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       8.82 ms /    49 runs   (    0.18 ms per token,  5553.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12933.48 ms /   508 tokens (   25.46 ms per token,    39.28 tokens per second)\n",
      "llama_print_timings:        eval time =    5066.07 ms /    48 runs   (  105.54 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =   18030.01 ms /   556 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /    20 runs   (    0.17 ms per token,  5836.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   52842.33 ms /  2003 tokens (   26.38 ms per token,    37.91 tokens per second)\n",
      "llama_print_timings:        eval time =    2106.06 ms /    19 runs   (  110.85 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =   54960.56 ms /  2022 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      12.24 ms /    74 runs   (    0.17 ms per token,  6045.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   33560.56 ms /  1300 tokens (   25.82 ms per token,    38.74 tokens per second)\n",
      "llama_print_timings:        eval time =    7849.51 ms /    73 runs   (  107.53 ms per token,     9.30 tokens per second)\n",
      "llama_print_timings:       total time =   41448.23 ms /  1373 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /    19 runs   (    0.17 ms per token,  6054.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =   47443.76 ms /  1810 tokens (   26.21 ms per token,    38.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1980.22 ms /    18 runs   (  110.01 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =   49434.52 ms /  1828 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      18.17 ms /   110 runs   (    0.17 ms per token,  6053.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =   47943.53 ms /  1829 tokens (   26.21 ms per token,    38.15 tokens per second)\n",
      "llama_print_timings:        eval time =   12010.36 ms /   109 runs   (  110.19 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =   60014.71 ms /  1938 tokens\n",
      " 24%|██▍       | 49/200 [41:05<1:51:12, 44.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /    30 runs   (    0.17 ms per token,  5869.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18382.36 ms /   719 tokens (   25.57 ms per token,    39.11 tokens per second)\n",
      "llama_print_timings:        eval time =    3034.99 ms /    29 runs   (  104.65 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =   21432.61 ms /   748 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      13.83 ms /    84 runs   (    0.16 ms per token,  6074.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =   46479.34 ms /  1772 tokens (   26.23 ms per token,    38.12 tokens per second)\n",
      "llama_print_timings:        eval time =    9139.19 ms /    83 runs   (  110.11 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =   55664.58 ms /  1855 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    54 runs   (    0.17 ms per token,  5923.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   67870.13 ms /  2530 tokens (   26.83 ms per token,    37.28 tokens per second)\n",
      "llama_print_timings:        eval time =    6017.13 ms /    53 runs   (  113.53 ms per token,     8.81 tokens per second)\n",
      "llama_print_timings:       total time =   73917.99 ms /  2583 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      23.98 ms /   132 runs   (    0.18 ms per token,  5504.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13556.18 ms /   535 tokens (   25.34 ms per token,    39.47 tokens per second)\n",
      "llama_print_timings:        eval time =   13878.25 ms /   131 runs   (  105.94 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =   27524.78 ms /   666 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    27 runs   (    0.16 ms per token,  6268.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   41640.50 ms /  1596 tokens (   26.09 ms per token,    38.33 tokens per second)\n",
      "llama_print_timings:        eval time =    2839.69 ms /    26 runs   (  109.22 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =   44494.17 ms /  1622 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      15.63 ms /    93 runs   (    0.17 ms per token,  5948.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   63069.03 ms /  2362 tokens (   26.70 ms per token,    37.45 tokens per second)\n",
      "llama_print_timings:        eval time =   10357.73 ms /    92 runs   (  112.58 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =   73478.45 ms /  2454 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      20.63 ms /   124 runs   (    0.17 ms per token,  6011.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   35057.48 ms /  1353 tokens (   25.91 ms per token,    38.59 tokens per second)\n",
      "llama_print_timings:        eval time =   13289.33 ms /   123 runs   (  108.04 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:       total time =   48412.70 ms /  1476 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      12.36 ms /    76 runs   (    0.16 ms per token,  6148.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   36714.85 ms /  1414 tokens (   25.97 ms per token,    38.51 tokens per second)\n",
      "llama_print_timings:        eval time =    8141.85 ms /    75 runs   (  108.56 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =   44895.35 ms /  1489 tokens\n",
      " 28%|██▊       | 57/200 [47:35<1:48:50, 45.67s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.58 ms /    67 runs   (    0.14 ms per token,  6993.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   24305.53 ms /   947 tokens (   25.67 ms per token,    38.96 tokens per second)\n",
      "llama_print_timings:        eval time =    6990.93 ms /    66 runs   (  105.92 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =   31328.27 ms /  1013 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     3 runs   (    0.18 ms per token,  5535.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   24883.60 ms /   956 tokens (   26.03 ms per token,    38.42 tokens per second)\n",
      "llama_print_timings:        eval time =     216.04 ms /     2 runs   (  108.02 ms per token,     9.26 tokens per second)\n",
      "llama_print_timings:       total time =   25102.00 ms /   958 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      20.85 ms /   128 runs   (    0.16 ms per token,  6137.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   30759.07 ms /  1188 tokens (   25.89 ms per token,    38.62 tokens per second)\n",
      "llama_print_timings:        eval time =   13649.35 ms /   127 runs   (  107.48 ms per token,     9.30 tokens per second)\n",
      "llama_print_timings:       total time =   44477.07 ms /  1315 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     3 runs   (    0.18 ms per token,  5535.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17286.79 ms /   681 tokens (   25.38 ms per token,    39.39 tokens per second)\n",
      "llama_print_timings:        eval time =     211.09 ms /     2 runs   (  105.55 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =   17499.69 ms /   683 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      23.97 ms /   149 runs   (    0.16 ms per token,  6216.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19840.25 ms /   778 tokens (   25.50 ms per token,    39.21 tokens per second)\n",
      "llama_print_timings:        eval time =   15882.18 ms /   148 runs   (  107.31 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =   35823.53 ms /   926 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       5.02 ms /    29 runs   (    0.17 ms per token,  5781.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20989.41 ms /   826 tokens (   25.41 ms per token,    39.35 tokens per second)\n",
      "llama_print_timings:        eval time =    3005.83 ms /    28 runs   (  107.35 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =   24013.92 ms /   854 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      12.03 ms /    67 runs   (    0.18 ms per token,  5568.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12813.19 ms /   508 tokens (   25.22 ms per token,    39.65 tokens per second)\n",
      "llama_print_timings:        eval time =    6965.83 ms /    66 runs   (  105.54 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =   19821.15 ms /   574 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      12.39 ms /    76 runs   (    0.16 ms per token,  6132.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   25499.94 ms /   995 tokens (   25.63 ms per token,    39.02 tokens per second)\n",
      "llama_print_timings:        eval time =    7949.12 ms /    75 runs   (  105.99 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =   33487.72 ms /  1070 tokens\n",
      " 32%|███▎      | 65/200 [51:27<1:30:48, 40.36s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      17.29 ms /    96 runs   (    0.18 ms per token,  5553.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16923.36 ms /   664 tokens (   25.49 ms per token,    39.24 tokens per second)\n",
      "llama_print_timings:        eval time =   10114.20 ms /    95 runs   (  106.47 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =   27101.11 ms /   759 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      11.19 ms /    73 runs   (    0.15 ms per token,  6526.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   30621.51 ms /  1189 tokens (   25.75 ms per token,    38.83 tokens per second)\n",
      "llama_print_timings:        eval time =    7718.32 ms /    72 runs   (  107.20 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =   38376.73 ms /  1261 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      22.70 ms /   141 runs   (    0.16 ms per token,  6210.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   20808.65 ms /   817 tokens (   25.47 ms per token,    39.26 tokens per second)\n",
      "llama_print_timings:        eval time =   14751.79 ms /   140 runs   (  105.37 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =   35634.26 ms /   957 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     3 runs   (    0.20 ms per token,  4893.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15254.19 ms /   602 tokens (   25.34 ms per token,    39.46 tokens per second)\n",
      "llama_print_timings:        eval time =     213.06 ms /     2 runs   (  106.53 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =   15469.02 ms /   604 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      14.11 ms /    86 runs   (    0.16 ms per token,  6093.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   26533.25 ms /  1031 tokens (   25.74 ms per token,    38.86 tokens per second)\n",
      "llama_print_timings:        eval time =    9049.73 ms /    85 runs   (  106.47 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =   35626.65 ms /  1116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       4.19 ms /    25 runs   (    0.17 ms per token,  5965.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15486.53 ms /   610 tokens (   25.39 ms per token,    39.39 tokens per second)\n",
      "llama_print_timings:        eval time =    2498.79 ms /    24 runs   (  104.12 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =   17997.20 ms /   634 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.34 ms /    52 runs   (    0.18 ms per token,  5568.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10841.23 ms /   430 tokens (   25.21 ms per token,    39.66 tokens per second)\n",
      "llama_print_timings:        eval time =    5362.23 ms /    51 runs   (  105.14 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =   16235.64 ms /   481 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      13.40 ms /    76 runs   (    0.18 ms per token,  5672.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22955.87 ms /   872 tokens (   26.33 ms per token,    37.99 tokens per second)\n",
      "llama_print_timings:        eval time =    8093.70 ms /    75 runs   (  107.92 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =   31099.77 ms /   947 tokens\n",
      " 36%|███▋      | 73/200 [55:04<1:16:44, 36.25s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.65 ms /    55 runs   (    0.18 ms per token,  5700.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10712.67 ms /   426 tokens (   25.15 ms per token,    39.77 tokens per second)\n",
      "llama_print_timings:        eval time =    5675.78 ms /    54 runs   (  105.11 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =   16422.72 ms /   480 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      58.13 ms /   316 runs   (    0.18 ms per token,  5436.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   28183.14 ms /  1069 tokens (   26.36 ms per token,    37.93 tokens per second)\n",
      "llama_print_timings:        eval time =   34529.55 ms /   315 runs   (  109.62 ms per token,     9.12 tokens per second)\n",
      "llama_print_timings:       total time =   62987.24 ms /  1384 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    47 runs   (    0.16 ms per token,  6372.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17871.35 ms /   694 tokens (   25.75 ms per token,    38.83 tokens per second)\n",
      "llama_print_timings:        eval time =    4821.53 ms /    46 runs   (  104.82 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =   22715.33 ms /   740 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      14.07 ms /    80 runs   (    0.18 ms per token,  5684.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   26387.01 ms /  1012 tokens (   26.07 ms per token,    38.35 tokens per second)\n",
      "llama_print_timings:        eval time =    8571.42 ms /    79 runs   (  108.50 ms per token,     9.22 tokens per second)\n",
      "llama_print_timings:       total time =   35010.97 ms /  1091 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      18.73 ms /   110 runs   (    0.17 ms per token,  5873.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   23405.04 ms /   900 tokens (   26.01 ms per token,    38.45 tokens per second)\n",
      "llama_print_timings:        eval time =   11542.13 ms /   109 runs   (  105.89 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =   35004.82 ms /  1009 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       3.27 ms /    18 runs   (    0.18 ms per token,  5497.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   45614.02 ms /  1731 tokens (   26.35 ms per token,    37.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1907.59 ms /    17 runs   (  112.21 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =   47534.34 ms /  1748 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      16.92 ms /    91 runs   (    0.19 ms per token,  5378.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22671.76 ms /   865 tokens (   26.21 ms per token,    38.15 tokens per second)\n",
      "llama_print_timings:        eval time =    9685.64 ms /    90 runs   (  107.62 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =   32419.29 ms /   955 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.52 ms /     3 runs   (    0.17 ms per token,  5825.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16332.91 ms /   630 tokens (   25.93 ms per token,    38.57 tokens per second)\n",
      "llama_print_timings:        eval time =     210.37 ms /     2 runs   (  105.18 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =   16545.25 ms /   632 tokens\n",
      " 40%|████      | 81/200 [59:33<1:10:16, 35.43s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      21.29 ms /   129 runs   (    0.17 ms per token,  6058.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   41361.43 ms /  1562 tokens (   26.48 ms per token,    37.76 tokens per second)\n",
      "llama_print_timings:        eval time =   14025.52 ms /   128 runs   (  109.57 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =   55458.05 ms /  1690 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       2.92 ms /    16 runs   (    0.18 ms per token,  5475.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15233.56 ms /   566 tokens (   26.91 ms per token,    37.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1591.70 ms /    15 runs   (  106.11 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =   16834.44 ms /   581 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      13.26 ms /    73 runs   (    0.18 ms per token,  5506.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11465.43 ms /   451 tokens (   25.42 ms per token,    39.34 tokens per second)\n",
      "llama_print_timings:        eval time =    7584.64 ms /    72 runs   (  105.34 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =   19097.33 ms /   523 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /    27 runs   (    0.17 ms per token,  6052.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10294.43 ms /   406 tokens (   25.36 ms per token,    39.44 tokens per second)\n",
      "llama_print_timings:        eval time =    2737.74 ms /    26 runs   (  105.30 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =   13048.07 ms /   432 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      13.36 ms /    73 runs   (    0.18 ms per token,  5465.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10384.01 ms /   388 tokens (   26.76 ms per token,    37.37 tokens per second)\n",
      "llama_print_timings:        eval time =    7570.71 ms /    72 runs   (  105.15 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =   18001.45 ms /   460 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      24.04 ms /   133 runs   (    0.18 ms per token,  5532.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   54507.71 ms /  2028 tokens (   26.88 ms per token,    37.21 tokens per second)\n",
      "llama_print_timings:        eval time =   15067.82 ms /   132 runs   (  114.15 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =   69675.56 ms /  2160 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    38 runs   (    0.17 ms per token,  5756.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5621.74 ms /   225 tokens (   24.99 ms per token,    40.02 tokens per second)\n",
      "llama_print_timings:        eval time =    3848.82 ms /    37 runs   (  104.02 ms per token,     9.61 tokens per second)\n",
      "llama_print_timings:       total time =    9493.59 ms /   262 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.51 ms /    52 runs   (    0.18 ms per token,  5469.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   26800.21 ms /  1040 tokens (   25.77 ms per token,    38.81 tokens per second)\n",
      "llama_print_timings:        eval time =    5544.09 ms /    51 runs   (  108.71 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =   32377.89 ms /  1091 tokens\n",
      " 44%|████▍     | 89/200 [1:03:27<1:02:03, 33.54s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      17.01 ms /   106 runs   (    0.16 ms per token,  6230.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =   49534.09 ms /  1861 tokens (   26.62 ms per token,    37.57 tokens per second)\n",
      "llama_print_timings:        eval time =   11599.79 ms /   105 runs   (  110.47 ms per token,     9.05 tokens per second)\n",
      "llama_print_timings:       total time =   61191.79 ms /  1966 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     3 runs   (    0.18 ms per token,  5671.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12273.81 ms /   486 tokens (   25.25 ms per token,    39.60 tokens per second)\n",
      "llama_print_timings:        eval time =     207.65 ms /     2 runs   (  103.82 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =   12482.37 ms /   488 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      22.22 ms /   134 runs   (    0.17 ms per token,  6030.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22442.40 ms /   872 tokens (   25.74 ms per token,    38.86 tokens per second)\n",
      "llama_print_timings:        eval time =   14054.35 ms /   133 runs   (  105.67 ms per token,     9.46 tokens per second)\n",
      "llama_print_timings:       total time =   36567.94 ms /  1005 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      12.52 ms /    68 runs   (    0.18 ms per token,  5432.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   31070.60 ms /  1187 tokens (   26.18 ms per token,    38.20 tokens per second)\n",
      "llama_print_timings:        eval time =    7330.09 ms /    67 runs   (  109.40 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =   38446.19 ms /  1254 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    57 runs   (    0.16 ms per token,  6094.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8422.33 ms /   325 tokens (   25.91 ms per token,    38.59 tokens per second)\n",
      "llama_print_timings:        eval time =    5756.37 ms /    56 runs   (  102.79 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =   14206.15 ms /   381 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      11.32 ms /    70 runs   (    0.16 ms per token,  6182.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   60490.04 ms /  2261 tokens (   26.75 ms per token,    37.38 tokens per second)\n",
      "llama_print_timings:        eval time =    7797.96 ms /    69 runs   (  113.01 ms per token,     8.85 tokens per second)\n",
      "llama_print_timings:       total time =   68327.09 ms /  2330 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      18.63 ms /   112 runs   (    0.17 ms per token,  6011.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   26510.57 ms /  1019 tokens (   26.02 ms per token,    38.44 tokens per second)\n",
      "llama_print_timings:        eval time =   11824.36 ms /   111 runs   (  106.53 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =   38393.66 ms /  1130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    28 runs   (    0.17 ms per token,  5735.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   29035.71 ms /  1107 tokens (   26.23 ms per token,    38.13 tokens per second)\n",
      "llama_print_timings:        eval time =    2889.29 ms /    27 runs   (  107.01 ms per token,     9.34 tokens per second)\n",
      "llama_print_timings:       total time =   31940.35 ms /  1134 tokens\n",
      " 48%|████▊     | 97/200 [1:08:29<59:45, 34.81s/it]  Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /    38 runs   (    0.16 ms per token,  6107.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   56978.59 ms /  2106 tokens (   27.06 ms per token,    36.96 tokens per second)\n",
      "llama_print_timings:        eval time =    4133.10 ms /    37 runs   (  111.71 ms per token,     8.95 tokens per second)\n",
      "llama_print_timings:       total time =   61132.53 ms /  2143 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /    19 runs   (    0.16 ms per token,  6348.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   68441.98 ms /  2510 tokens (   27.27 ms per token,    36.67 tokens per second)\n",
      "llama_print_timings:        eval time =    2035.97 ms /    18 runs   (  113.11 ms per token,     8.84 tokens per second)\n",
      "llama_print_timings:       total time =   70489.40 ms /  2528 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      14.35 ms /    86 runs   (    0.17 ms per token,  5993.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =   24721.80 ms /   944 tokens (   26.19 ms per token,    38.18 tokens per second)\n",
      "llama_print_timings:        eval time =    9012.26 ms /    85 runs   (  106.03 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =   33777.96 ms /  1029 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.58 ms /     3 runs   (    0.19 ms per token,  5163.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19909.03 ms /   758 tokens (   26.27 ms per token,    38.07 tokens per second)\n",
      "llama_print_timings:        eval time =     214.95 ms /     2 runs   (  107.48 ms per token,     9.30 tokens per second)\n",
      "llama_print_timings:       total time =   20125.72 ms /   760 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      10.91 ms /    58 runs   (    0.19 ms per token,  5315.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   63128.09 ms /  2344 tokens (   26.93 ms per token,    37.13 tokens per second)\n",
      "llama_print_timings:        eval time =    6557.06 ms /    57 runs   (  115.04 ms per token,     8.69 tokens per second)\n",
      "llama_print_timings:       total time =   69726.33 ms /  2401 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /     3 runs   (    0.18 ms per token,  5434.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16651.58 ms /   624 tokens (   26.69 ms per token,    37.47 tokens per second)\n",
      "llama_print_timings:        eval time =     210.24 ms /     2 runs   (  105.12 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =   16863.67 ms /   626 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.24 ms /    50 runs   (    0.18 ms per token,  5409.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15271.32 ms /   583 tokens (   26.19 ms per token,    38.18 tokens per second)\n",
      "llama_print_timings:        eval time =    5192.26 ms /    49 runs   (  105.96 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =   20495.67 ms /   632 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       5.93 ms /    36 runs   (    0.16 ms per token,  6067.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   44748.10 ms /  1649 tokens (   27.14 ms per token,    36.85 tokens per second)\n",
      "llama_print_timings:        eval time =    3820.48 ms /    35 runs   (  109.16 ms per token,     9.16 tokens per second)\n",
      "llama_print_timings:       total time =   48588.40 ms /  1684 tokens\n",
      " 52%|█████▎    | 105/200 [1:14:10<58:52, 37.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    48 runs   (    0.16 ms per token,  6099.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11134.97 ms /   442 tokens (   25.19 ms per token,    39.69 tokens per second)\n",
      "llama_print_timings:        eval time =    4851.54 ms /    47 runs   (  103.22 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =   16009.50 ms /   489 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      17.85 ms /   111 runs   (    0.16 ms per token,  6218.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =   37327.59 ms /  1410 tokens (   26.47 ms per token,    37.77 tokens per second)\n",
      "llama_print_timings:        eval time =   11952.61 ms /   110 runs   (  108.66 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =   49339.51 ms /  1520 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    41 runs   (    0.16 ms per token,  6313.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18576.73 ms /   672 tokens (   27.64 ms per token,    36.17 tokens per second)\n",
      "llama_print_timings:        eval time =    4185.06 ms /    40 runs   (  104.63 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =   22781.77 ms /   712 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      49.90 ms /   310 runs   (    0.16 ms per token,  6212.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   57978.90 ms /  2143 tokens (   27.06 ms per token,    36.96 tokens per second)\n",
      "llama_print_timings:        eval time =   35081.80 ms /   309 runs   (  113.53 ms per token,     8.81 tokens per second)\n",
      "llama_print_timings:       total time =   93258.36 ms /  2452 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       6.19 ms /    38 runs   (    0.16 ms per token,  6142.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12622.04 ms /   490 tokens (   25.76 ms per token,    38.82 tokens per second)\n",
      "llama_print_timings:        eval time =    3840.10 ms /    37 runs   (  103.79 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =   16480.66 ms /   527 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      17.55 ms /   111 runs   (    0.16 ms per token,  6324.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   58704.95 ms /  2185 tokens (   26.87 ms per token,    37.22 tokens per second)\n",
      "llama_print_timings:        eval time =   12362.71 ms /   110 runs   (  112.39 ms per token,     8.90 tokens per second)\n",
      "llama_print_timings:       total time =   71128.70 ms /  2295 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.51 ms /     3 runs   (    0.17 ms per token,  5917.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13422.91 ms /   519 tokens (   25.86 ms per token,    38.67 tokens per second)\n",
      "llama_print_timings:        eval time =     209.13 ms /     2 runs   (  104.56 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =   13633.27 ms /   521 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /     3 runs   (    0.18 ms per token,  5454.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   33691.75 ms /  1274 tokens (   26.45 ms per token,    37.81 tokens per second)\n",
      "llama_print_timings:        eval time =     221.01 ms /     2 runs   (  110.51 ms per token,     9.05 tokens per second)\n",
      "llama_print_timings:       total time =   33915.18 ms /  1276 tokens\n",
      " 56%|█████▋    | 113/200 [1:19:27<54:58, 37.91s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       5.95 ms /    34 runs   (    0.18 ms per token,  5713.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8438.07 ms /   337 tokens (   25.04 ms per token,    39.94 tokens per second)\n",
      "llama_print_timings:        eval time =    3461.78 ms /    33 runs   (  104.90 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =   11920.54 ms /   370 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      15.17 ms /    93 runs   (    0.16 ms per token,  6129.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   34599.06 ms /  1314 tokens (   26.33 ms per token,    37.98 tokens per second)\n",
      "llama_print_timings:        eval time =    9945.58 ms /    92 runs   (  108.10 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =   44593.15 ms /  1406 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /    17 runs   (    0.17 ms per token,  5841.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   25315.03 ms /   983 tokens (   25.75 ms per token,    38.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1696.07 ms /    16 runs   (  106.00 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =   27019.69 ms /   999 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      29.41 ms /   176 runs   (    0.17 ms per token,  5985.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   22655.89 ms /   870 tokens (   26.04 ms per token,    38.40 tokens per second)\n",
      "llama_print_timings:        eval time =   18747.18 ms /   175 runs   (  107.13 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =   41500.03 ms /  1045 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      19.06 ms /   105 runs   (    0.18 ms per token,  5507.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21062.85 ms /   814 tokens (   25.88 ms per token,    38.65 tokens per second)\n",
      "llama_print_timings:        eval time =   11181.87 ms /   104 runs   (  107.52 ms per token,     9.30 tokens per second)\n",
      "llama_print_timings:       total time =   32316.43 ms /   918 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      14.78 ms /    88 runs   (    0.17 ms per token,  5954.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   23916.07 ms /   912 tokens (   26.22 ms per token,    38.13 tokens per second)\n",
      "llama_print_timings:        eval time =    9259.16 ms /    87 runs   (  106.43 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =   33220.97 ms /   999 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      31.11 ms /   192 runs   (    0.16 ms per token,  6172.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   32742.76 ms /  1246 tokens (   26.28 ms per token,    38.05 tokens per second)\n",
      "llama_print_timings:        eval time =   20643.71 ms /   191 runs   (  108.08 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =   53494.30 ms /  1437 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /    19 runs   (    0.18 ms per token,  5507.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19164.33 ms /   723 tokens (   26.51 ms per token,    37.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1953.55 ms /    18 runs   (  108.53 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =   21129.69 ms /   741 tokens\n",
      " 60%|██████    | 121/200 [1:23:52<48:01, 36.48s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      21.85 ms /   122 runs   (    0.18 ms per token,  5584.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   28506.10 ms /  1089 tokens (   26.18 ms per token,    38.20 tokens per second)\n",
      "llama_print_timings:        eval time =   13191.77 ms /   121 runs   (  109.02 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =   41783.55 ms /  1210 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      25.00 ms /   154 runs   (    0.16 ms per token,  6161.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21895.71 ms /   776 tokens (   28.22 ms per token,    35.44 tokens per second)\n",
      "llama_print_timings:        eval time =   16190.71 ms /   153 runs   (  105.82 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =   38167.69 ms /   929 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      28.07 ms /   175 runs   (    0.16 ms per token,  6233.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   47584.65 ms /  1783 tokens (   26.69 ms per token,    37.47 tokens per second)\n",
      "llama_print_timings:        eval time =   19262.87 ms /   174 runs   (  110.71 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =   66947.88 ms /  1957 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.51 ms /     3 runs   (    0.17 ms per token,  5870.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18386.62 ms /   681 tokens (   27.00 ms per token,    37.04 tokens per second)\n",
      "llama_print_timings:        eval time =     211.19 ms /     2 runs   (  105.59 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =   18599.19 ms /   683 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      19.07 ms /   104 runs   (    0.18 ms per token,  5452.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   42512.48 ms /  1612 tokens (   26.37 ms per token,    37.92 tokens per second)\n",
      "llama_print_timings:        eval time =   11516.59 ms /   103 runs   (  111.81 ms per token,     8.94 tokens per second)\n",
      "llama_print_timings:       total time =   54104.78 ms /  1715 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      15.89 ms /    97 runs   (    0.16 ms per token,  6104.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18521.87 ms /   715 tokens (   25.90 ms per token,    38.60 tokens per second)\n",
      "llama_print_timings:        eval time =   10101.84 ms /    96 runs   (  105.23 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =   28672.94 ms /   811 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      92.92 ms /   512 runs   (    0.18 ms per token,  5510.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =   35282.41 ms /  1347 tokens (   26.19 ms per token,    38.18 tokens per second)\n",
      "llama_print_timings:        eval time =   56958.26 ms /   511 runs   (  111.46 ms per token,     8.97 tokens per second)\n",
      "llama_print_timings:       total time =   92788.93 ms /  1858 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      42.75 ms /   268 runs   (    0.16 ms per token,  6268.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   27052.62 ms /  1034 tokens (   26.16 ms per token,    38.22 tokens per second)\n",
      "llama_print_timings:        eval time =   28914.12 ms /   267 runs   (  108.29 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =   56126.05 ms /  1301 tokens\n",
      " 64%|██████▍   | 129/200 [1:30:29<47:51, 40.44s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      13.80 ms /    81 runs   (    0.17 ms per token,  5869.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =   35039.91 ms /  1202 tokens (   29.15 ms per token,    34.30 tokens per second)\n",
      "llama_print_timings:        eval time =    8588.90 ms /    80 runs   (  107.36 ms per token,     9.31 tokens per second)\n",
      "llama_print_timings:       total time =   43671.97 ms /  1282 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      14.88 ms /    90 runs   (    0.17 ms per token,  6048.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   28957.39 ms /  1089 tokens (   26.59 ms per token,    37.61 tokens per second)\n",
      "llama_print_timings:        eval time =    9554.74 ms /    89 runs   (  107.36 ms per token,     9.31 tokens per second)\n",
      "llama_print_timings:       total time =   38559.96 ms /  1178 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      19.60 ms /   119 runs   (    0.16 ms per token,  6072.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18942.15 ms /   717 tokens (   26.42 ms per token,    37.85 tokens per second)\n",
      "llama_print_timings:        eval time =   12388.38 ms /   118 runs   (  104.99 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =   31393.53 ms /   835 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      14.86 ms /    91 runs   (    0.16 ms per token,  6123.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   34620.20 ms /  1310 tokens (   26.43 ms per token,    37.84 tokens per second)\n",
      "llama_print_timings:        eval time =    9804.06 ms /    90 runs   (  108.93 ms per token,     9.18 tokens per second)\n",
      "llama_print_timings:       total time =   44473.59 ms /  1400 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    51 runs   (    0.16 ms per token,  6112.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13973.42 ms /   548 tokens (   25.50 ms per token,    39.22 tokens per second)\n",
      "llama_print_timings:        eval time =    5188.27 ms /    50 runs   (  103.77 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =   19186.36 ms /   598 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      11.62 ms /    69 runs   (    0.17 ms per token,  5938.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   35586.27 ms /  1345 tokens (   26.46 ms per token,    37.80 tokens per second)\n",
      "llama_print_timings:        eval time =    7364.58 ms /    68 runs   (  108.30 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =   42987.53 ms /  1413 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.52 ms /     3 runs   (    0.17 ms per token,  5747.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   42388.85 ms /  1603 tokens (   26.44 ms per token,    37.82 tokens per second)\n",
      "llama_print_timings:        eval time =     220.93 ms /     2 runs   (  110.46 ms per token,     9.05 tokens per second)\n",
      "llama_print_timings:       total time =   42612.10 ms /  1605 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     3 runs   (    0.18 ms per token,  5514.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5294.17 ms /   209 tokens (   25.33 ms per token,    39.48 tokens per second)\n",
      "llama_print_timings:        eval time =     209.96 ms /     2 runs   (  104.98 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =    5505.98 ms /   211 tokens\n",
      " 68%|██████▊   | 137/200 [1:34:58<40:17, 38.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    42 runs   (    0.17 ms per token,  5972.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   37117.84 ms /  1416 tokens (   26.21 ms per token,    38.15 tokens per second)\n",
      "llama_print_timings:        eval time =    4439.25 ms /    41 runs   (  108.27 ms per token,     9.24 tokens per second)\n",
      "llama_print_timings:       total time =   41579.31 ms /  1457 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      10.67 ms /    64 runs   (    0.17 ms per token,  5996.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6113.49 ms /   237 tokens (   25.80 ms per token,    38.77 tokens per second)\n",
      "llama_print_timings:        eval time =    6467.71 ms /    63 runs   (  102.66 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =   12612.68 ms /   300 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.45 ms /     3 runs   (    0.15 ms per token,  6681.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18323.79 ms /   631 tokens (   29.04 ms per token,    34.44 tokens per second)\n",
      "llama_print_timings:        eval time =     209.96 ms /     2 runs   (  104.98 ms per token,     9.53 tokens per second)\n",
      "llama_print_timings:       total time =   18535.72 ms /   633 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /    18 runs   (    0.16 ms per token,  6284.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   34046.04 ms /  1236 tokens (   27.55 ms per token,    36.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1859.31 ms /    17 runs   (  109.37 ms per token,     9.14 tokens per second)\n",
      "llama_print_timings:       total time =   35914.75 ms /  1253 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /    30 runs   (    0.14 ms per token,  7178.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11549.52 ms /   449 tokens (   25.72 ms per token,    38.88 tokens per second)\n",
      "llama_print_timings:        eval time =    2996.00 ms /    29 runs   (  103.31 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =   14558.61 ms /   478 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      13.37 ms /    77 runs   (    0.17 ms per token,  5760.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   33030.41 ms /  1269 tokens (   26.03 ms per token,    38.42 tokens per second)\n",
      "llama_print_timings:        eval time =    8370.69 ms /    76 runs   (  110.14 ms per token,     9.08 tokens per second)\n",
      "llama_print_timings:       total time =   41452.40 ms /  1345 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      14.58 ms /    91 runs   (    0.16 ms per token,  6240.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   61201.26 ms /  2272 tokens (   26.94 ms per token,    37.12 tokens per second)\n",
      "llama_print_timings:        eval time =   10101.10 ms /    90 runs   (  112.23 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =   71352.55 ms /  2362 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      11.63 ms /    64 runs   (    0.18 ms per token,  5502.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19864.05 ms /   720 tokens (   27.59 ms per token,    36.25 tokens per second)\n",
      "llama_print_timings:        eval time =    6824.01 ms /    63 runs   (  108.32 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =   26729.74 ms /   783 tokens\n",
      " 72%|███████▎  | 145/200 [1:39:20<33:39, 36.71s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    35 runs   (    0.19 ms per token,  5328.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   73686.90 ms /  2651 tokens (   27.80 ms per token,    35.98 tokens per second)\n",
      "llama_print_timings:        eval time =    3956.07 ms /    34 runs   (  116.35 ms per token,     8.59 tokens per second)\n",
      "llama_print_timings:       total time =   77668.39 ms /  2685 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      23.09 ms /   140 runs   (    0.16 ms per token,  6063.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   55346.25 ms /  2047 tokens (   27.04 ms per token,    36.99 tokens per second)\n",
      "llama_print_timings:        eval time =   15512.87 ms /   139 runs   (  111.60 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =   70941.95 ms /  2186 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      15.61 ms /   100 runs   (    0.16 ms per token,  6406.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21114.45 ms /   763 tokens (   27.67 ms per token,    36.14 tokens per second)\n",
      "llama_print_timings:        eval time =   10423.76 ms /    99 runs   (  105.29 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =   31588.98 ms /   862 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      84.35 ms /   512 runs   (    0.16 ms per token,  6070.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   77320.60 ms /  2819 tokens (   27.43 ms per token,    36.46 tokens per second)\n",
      "llama_print_timings:        eval time =   59247.38 ms /   511 runs   (  115.94 ms per token,     8.62 tokens per second)\n",
      "llama_print_timings:       total time =  136950.17 ms /  3330 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     3 runs   (    0.18 ms per token,  5545.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11620.51 ms /   448 tokens (   25.94 ms per token,    38.55 tokens per second)\n",
      "llama_print_timings:        eval time =     211.82 ms /     2 runs   (  105.91 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =   11833.81 ms /   450 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.56 ms /     3 runs   (    0.19 ms per token,  5386.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13252.19 ms /   503 tokens (   26.35 ms per token,    37.96 tokens per second)\n",
      "llama_print_timings:        eval time =     211.16 ms /     2 runs   (  105.58 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =   13465.28 ms /   505 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    18 runs   (    0.18 ms per token,  5583.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   62885.22 ms /  2303 tokens (   27.31 ms per token,    36.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1978.53 ms /    17 runs   (  116.38 ms per token,     8.59 tokens per second)\n",
      "llama_print_timings:       total time =   64877.07 ms /  2320 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      15.86 ms /    95 runs   (    0.17 ms per token,  5990.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15548.97 ms /   609 tokens (   25.53 ms per token,    39.17 tokens per second)\n",
      "llama_print_timings:        eval time =    9808.58 ms /    94 runs   (  104.35 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =   25405.75 ms /   703 tokens\n",
      " 76%|███████▋  | 153/200 [1:46:33<32:51, 41.94s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      32.62 ms /   193 runs   (    0.17 ms per token,  5916.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12708.91 ms /   481 tokens (   26.42 ms per token,    37.85 tokens per second)\n",
      "llama_print_timings:        eval time =   20022.48 ms /   192 runs   (  104.28 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =   32836.88 ms /   673 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      21.31 ms /   128 runs   (    0.17 ms per token,  6006.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   63326.31 ms /  2337 tokens (   27.10 ms per token,    36.90 tokens per second)\n",
      "llama_print_timings:        eval time =   14353.00 ms /   127 runs   (  113.02 ms per token,     8.85 tokens per second)\n",
      "llama_print_timings:       total time =   77754.84 ms /  2464 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     3 runs   (    0.18 ms per token,  5660.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   25324.26 ms /   982 tokens (   25.79 ms per token,    38.78 tokens per second)\n",
      "llama_print_timings:        eval time =     213.71 ms /     2 runs   (  106.85 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =   25540.03 ms /   984 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      19.56 ms /   111 runs   (    0.18 ms per token,  5674.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   36019.02 ms /  1351 tokens (   26.66 ms per token,    37.51 tokens per second)\n",
      "llama_print_timings:        eval time =   12284.31 ms /   110 runs   (  111.68 ms per token,     8.95 tokens per second)\n",
      "llama_print_timings:       total time =   48381.56 ms /  1461 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     3 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14361.11 ms /   535 tokens (   26.84 ms per token,    37.25 tokens per second)\n",
      "llama_print_timings:        eval time =     215.85 ms /     2 runs   (  107.92 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =   14579.75 ms /   537 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      19.48 ms /   122 runs   (    0.16 ms per token,  6264.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =   21372.61 ms /   819 tokens (   26.10 ms per token,    38.32 tokens per second)\n",
      "llama_print_timings:        eval time =   12780.33 ms /   121 runs   (  105.62 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =   34214.32 ms /   940 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    48 runs   (    0.17 ms per token,  5833.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   37172.80 ms /  1391 tokens (   26.72 ms per token,    37.42 tokens per second)\n",
      "llama_print_timings:        eval time =    5091.93 ms /    47 runs   (  108.34 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =   42290.41 ms /  1438 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      16.40 ms /    99 runs   (    0.17 ms per token,  6036.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14958.56 ms /   576 tokens (   25.97 ms per token,    38.51 tokens per second)\n",
      "llama_print_timings:        eval time =   10234.81 ms /    98 runs   (  104.44 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =   25243.93 ms /   674 tokens\n",
      " 80%|████████  | 161/200 [1:51:34<26:24, 40.64s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    37 runs   (    0.17 ms per token,  5862.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   30949.80 ms /  1184 tokens (   26.14 ms per token,    38.26 tokens per second)\n",
      "llama_print_timings:        eval time =    3857.49 ms /    36 runs   (  107.15 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =   34826.07 ms /  1220 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      10.90 ms /    67 runs   (    0.16 ms per token,  6147.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   32133.80 ms /  1134 tokens (   28.34 ms per token,    35.29 tokens per second)\n",
      "llama_print_timings:        eval time =    7142.09 ms /    66 runs   (  108.21 ms per token,     9.24 tokens per second)\n",
      "llama_print_timings:       total time =   39311.01 ms /  1200 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     3 runs   (    0.18 ms per token,  5671.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7253.25 ms /   284 tokens (   25.54 ms per token,    39.15 tokens per second)\n",
      "llama_print_timings:        eval time =     208.31 ms /     2 runs   (  104.16 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =    7462.86 ms /   286 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      18.83 ms /   113 runs   (    0.17 ms per token,  6001.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   26405.54 ms /  1018 tokens (   25.94 ms per token,    38.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11945.24 ms /   112 runs   (  106.65 ms per token,     9.38 tokens per second)\n",
      "llama_print_timings:       total time =   38410.11 ms /  1130 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    38 runs   (    0.16 ms per token,  6292.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   31436.11 ms /  1172 tokens (   26.82 ms per token,    37.28 tokens per second)\n",
      "llama_print_timings:        eval time =    3971.55 ms /    37 runs   (  107.34 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =   35426.56 ms /  1209 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      10.62 ms /    64 runs   (    0.17 ms per token,  6025.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7768.35 ms /   310 tokens (   25.06 ms per token,    39.91 tokens per second)\n",
      "llama_print_timings:        eval time =    6488.87 ms /    63 runs   (  103.00 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =   14288.50 ms /   373 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     3 runs   (    0.18 ms per token,  5714.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   27569.70 ms /  1056 tokens (   26.11 ms per token,    38.30 tokens per second)\n",
      "llama_print_timings:        eval time =     213.73 ms /     2 runs   (  106.86 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =   27785.42 ms /  1058 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      23.64 ms /   146 runs   (    0.16 ms per token,  6176.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   45424.49 ms /  1685 tokens (   26.96 ms per token,    37.09 tokens per second)\n",
      "llama_print_timings:        eval time =   16136.96 ms /   145 runs   (  111.29 ms per token,     8.99 tokens per second)\n",
      "llama_print_timings:       total time =   61643.96 ms /  1830 tokens\n",
      " 84%|████████▍ | 169/200 [1:55:53<19:43, 38.17s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      15.93 ms /    95 runs   (    0.17 ms per token,  5965.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   23154.88 ms /   882 tokens (   26.25 ms per token,    38.09 tokens per second)\n",
      "llama_print_timings:        eval time =   10073.31 ms /    94 runs   (  107.16 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =   33278.09 ms /   976 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      21.89 ms /   124 runs   (    0.18 ms per token,  5665.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =   23326.04 ms /   902 tokens (   25.86 ms per token,    38.67 tokens per second)\n",
      "llama_print_timings:        eval time =   13292.46 ms /   123 runs   (  108.07 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =   36705.44 ms /  1025 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      31.39 ms /   176 runs   (    0.18 ms per token,  5607.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   46030.88 ms /  1726 tokens (   26.67 ms per token,    37.50 tokens per second)\n",
      "llama_print_timings:        eval time =   19742.54 ms /   175 runs   (  112.81 ms per token,     8.86 tokens per second)\n",
      "llama_print_timings:       total time =   65909.71 ms /  1901 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      17.60 ms /   109 runs   (    0.16 ms per token,  6192.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   24282.51 ms /   936 tokens (   25.94 ms per token,    38.55 tokens per second)\n",
      "llama_print_timings:        eval time =   11500.22 ms /   108 runs   (  106.48 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =   35838.67 ms /  1044 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.48 ms /     3 runs   (    0.16 ms per token,  6224.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13835.50 ms /   536 tokens (   25.81 ms per token,    38.74 tokens per second)\n",
      "llama_print_timings:        eval time =     208.24 ms /     2 runs   (  104.12 ms per token,     9.60 tokens per second)\n",
      "llama_print_timings:       total time =   14044.98 ms /   538 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     3 runs   (    0.18 ms per token,  5607.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8009.33 ms /   315 tokens (   25.43 ms per token,    39.33 tokens per second)\n",
      "llama_print_timings:        eval time =     210.86 ms /     2 runs   (  105.43 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =    8221.67 ms /   317 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.57 ms /     3 runs   (    0.19 ms per token,  5253.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17652.46 ms /   639 tokens (   27.63 ms per token,    36.20 tokens per second)\n",
      "llama_print_timings:        eval time =     211.77 ms /     2 runs   (  105.89 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =   17865.59 ms /   641 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    45 runs   (    0.17 ms per token,  5882.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9281.55 ms /   349 tokens (   26.59 ms per token,    37.60 tokens per second)\n",
      "llama_print_timings:        eval time =    4614.23 ms /    44 runs   (  104.87 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =   13923.84 ms /   393 tokens\n",
      " 88%|████████▊ | 177/200 [1:59:39<13:29, 35.19s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      18.37 ms /   112 runs   (    0.16 ms per token,  6096.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9719.30 ms /   351 tokens (   27.69 ms per token,    36.11 tokens per second)\n",
      "llama_print_timings:        eval time =   11493.07 ms /   111 runs   (  103.54 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =   21268.82 ms /   462 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      30.57 ms /   169 runs   (    0.18 ms per token,  5527.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17670.46 ms /   675 tokens (   26.18 ms per token,    38.20 tokens per second)\n",
      "llama_print_timings:        eval time =   18035.15 ms /   168 runs   (  107.35 ms per token,     9.32 tokens per second)\n",
      "llama_print_timings:       total time =   35828.92 ms /   843 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /     3 runs   (    0.18 ms per token,  5434.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   19283.27 ms /   738 tokens (   26.13 ms per token,    38.27 tokens per second)\n",
      "llama_print_timings:        eval time =     214.96 ms /     2 runs   (  107.48 ms per token,     9.30 tokens per second)\n",
      "llama_print_timings:       total time =   19500.57 ms /   740 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.56 ms /     3 runs   (    0.19 ms per token,  5338.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =   26863.00 ms /  1010 tokens (   26.60 ms per token,    37.60 tokens per second)\n",
      "llama_print_timings:        eval time =     223.17 ms /     2 runs   (  111.59 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =   27088.66 ms /  1012 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      11.40 ms /    68 runs   (    0.17 ms per token,  5965.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   67491.26 ms /  2442 tokens (   27.64 ms per token,    36.18 tokens per second)\n",
      "llama_print_timings:        eval time =    7648.93 ms /    67 runs   (  114.16 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =   75180.18 ms /  2509 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      16.39 ms /    98 runs   (    0.17 ms per token,  5978.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14502.95 ms /   569 tokens (   25.49 ms per token,    39.23 tokens per second)\n",
      "llama_print_timings:        eval time =   10310.49 ms /    97 runs   (  106.29 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =   24877.13 ms /   666 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      10.77 ms /    66 runs   (    0.16 ms per token,  6127.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   27345.93 ms /  1043 tokens (   26.22 ms per token,    38.14 tokens per second)\n",
      "llama_print_timings:        eval time =    6945.89 ms /    65 runs   (  106.86 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =   34325.82 ms /  1108 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      17.20 ms /   102 runs   (    0.17 ms per token,  5931.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =   67209.10 ms /  2478 tokens (   27.12 ms per token,    36.87 tokens per second)\n",
      "llama_print_timings:        eval time =   11512.55 ms /   101 runs   (  113.99 ms per token,     8.77 tokens per second)\n",
      "llama_print_timings:       total time =   78781.33 ms /  2579 tokens\n",
      " 92%|█████████▎| 185/200 [2:04:56<09:07, 36.52s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     3 runs   (    0.18 ms per token,  5514.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   36810.00 ms /  1410 tokens (   26.11 ms per token,    38.30 tokens per second)\n",
      "llama_print_timings:        eval time =     218.59 ms /     2 runs   (  109.30 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:       total time =   37030.47 ms /  1412 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     4 runs   (    0.17 ms per token,  6042.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   36570.71 ms /  1368 tokens (   26.73 ms per token,    37.41 tokens per second)\n",
      "llama_print_timings:        eval time =     327.81 ms /     3 runs   (  109.27 ms per token,     9.15 tokens per second)\n",
      "llama_print_timings:       total time =   36901.64 ms /  1371 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =       9.95 ms /    55 runs   (    0.18 ms per token,  5526.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =   59178.71 ms /  2158 tokens (   27.42 ms per token,    36.47 tokens per second)\n",
      "llama_print_timings:        eval time =    6256.23 ms /    54 runs   (  115.86 ms per token,     8.63 tokens per second)\n",
      "llama_print_timings:       total time =   65473.46 ms /  2212 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      22.78 ms /   127 runs   (    0.18 ms per token,  5575.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   33826.07 ms /  1237 tokens (   27.35 ms per token,    36.57 tokens per second)\n",
      "llama_print_timings:        eval time =   13826.53 ms /   126 runs   (  109.73 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =   47744.80 ms /  1363 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      13.83 ms /    75 runs   (    0.18 ms per token,  5422.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   37025.21 ms /  1410 tokens (   26.26 ms per token,    38.08 tokens per second)\n",
      "llama_print_timings:        eval time =    8203.67 ms /    74 runs   (  110.86 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =   45280.99 ms /  1484 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      13.17 ms /    81 runs   (    0.16 ms per token,  6149.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   59752.98 ms /  2217 tokens (   26.95 ms per token,    37.10 tokens per second)\n",
      "llama_print_timings:        eval time =    8975.18 ms /    80 runs   (  112.19 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =   68773.11 ms /  2297 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    7884.44 ms\n",
      "llama_print_timings:      sample time =      56.93 ms /   318 runs   (    0.18 ms per token,  5585.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   47854.96 ms /  1788 tokens (   26.76 ms per token,    37.36 tokens per second)\n",
      "llama_print_timings:        eval time =   35849.23 ms /   317 runs   (  113.09 ms per token,     8.84 tokens per second)\n",
      "llama_print_timings:       total time =   83990.14 ms /  2105 tokens\n",
      "100%|██████████| 200/200 [2:11:21<00:00, 39.41s/it]\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model)\n",
    "\n",
    "faithfulness = FaithfulnessEvaluator(service_context=service_context)\n",
    "relevancy = RelevancyEvaluator(service_context=service_context)\n",
    "\n",
    "batch_eval_queries = list(qa_dataset.queries.values())[0:100]\n",
    "\n",
    "# Initiate BatchEvalRunner to compute FaithFulness and Relevancy Evaluation.\n",
    "runner = BatchEvalRunner(\n",
    "    {\"faithfulness\": faithfulness, \"relevancy\": relevancy},\n",
    "    workers=8,\n",
    "    show_progress=True\n",
    ")\n",
    "query_engine = index.as_query_engine(llm=llm, similar_top_k=3)\n",
    "# Compute evaluation\n",
    "eval_results = await runner.aevaluate_queries(\n",
    "    query_engine, queries=batch_eval_queries\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness_score 0.84\n",
      "relevancy_score 0.97\n"
     ]
    }
   ],
   "source": [
    "# Let's get faithfulness score\n",
    "\n",
    "faithfulness_score = sum(result.passing for result in eval_results['faithfulness']) / len(eval_results['faithfulness'])\n",
    "\n",
    "print(\"faithfulness_score\", faithfulness_score)\n",
    "\n",
    "# Let's get relevancy score\n",
    "\n",
    "relevancy_score = sum(result.passing for result in eval_results['relevancy']) / len(eval_results['relevancy'])\n",
    "\n",
    "print(\"relevancy_score\", relevancy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation with broad questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 26 key-value pairs and 291 tensors from /tmp/llama_index/models/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = Meta-Llama-3-8B-Instruct\n",
      "llama_model_loader: - kv   2:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   3:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   4:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   7:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   8:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  12:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  13:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  14:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  16:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  17:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 128001\n",
      "llama_model_loader: - kv  20:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  21:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  22:                      quantize.imatrix.file str              = /models/Meta-Llama-3-8B-Instruct-GGUF...\n",
      "llama_model_loader: - kv  23:                   quantize.imatrix.dataset str              = /training_data/groups_merged.txt\n",
      "llama_model_loader: - kv  24:             quantize.imatrix.entries_count i32              = 224\n",
      "llama_model_loader: - kv  25:              quantize.imatrix.chunks_count i32              = 88\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.58 GiB (4.89 BPW) \n",
      "llm_load_print_meta: general.name     = Meta-Llama-3-8B-Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4685.30 MiB\n",
      "........................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 3904\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   488.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  488.00 MiB, K (f16):  244.00 MiB, V (f16):  244.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   283.63 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'quantize.imatrix.entries_count': '224', 'quantize.imatrix.dataset': '/training_data/groups_merged.txt', 'quantize.imatrix.chunks_count': '88', 'quantize.imatrix.file': '/models/Meta-Llama-3-8B-Instruct-GGUF/Meta-Llama-3-8B-Instruct.imatrix', 'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128001', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Meta-Llama-3-8B-Instruct', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.file_type': '15', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: llama-3\n"
     ]
    }
   ],
   "source": [
    "model_url = \"https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf\"\n",
    "llm_gen = LlamaCPP(\n",
    "    model_url=model_url,\n",
    "    model_path=None,\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=512,\n",
    "    context_window=3900,\n",
    "    generate_kwargs={},\n",
    "    model_kwargs={\"n_gpu_layers\": -1},\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /mnt/nvme/home/durech/camille/rag/lib/python3.10/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     127.66 ms /   233 runs   (    0.55 ms per token,  1825.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2971.75 ms /   102 tokens (   29.13 ms per token,    34.32 tokens per second)\n",
      "llama_print_timings:        eval time =   21696.75 ms /   232 runs   (   93.52 ms per token,    10.69 tokens per second)\n",
      "llama_print_timings:       total time =   24954.75 ms /   334 tokens\n",
      "  5%|▌         | 1/20 [00:24<07:54, 24.96s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =      25.34 ms /    45 runs   (    0.56 ms per token,  1776.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1496.60 ms /    80 tokens (   18.71 ms per token,    53.45 tokens per second)\n",
      "llama_print_timings:        eval time =    4099.85 ms /    44 runs   (   93.18 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =    5646.17 ms /   124 tokens\n",
      " 10%|█         | 2/20 [00:30<04:04, 13.60s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     100.60 ms /   185 runs   (    0.54 ms per token,  1839.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.09 ms /    82 tokens (   14.79 ms per token,    67.60 tokens per second)\n",
      "llama_print_timings:        eval time =   17215.69 ms /   184 runs   (   93.56 ms per token,    10.69 tokens per second)\n",
      "llama_print_timings:       total time =   18642.05 ms /   266 tokens\n",
      " 15%|█▌        | 3/20 [00:49<04:30, 15.90s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     128.36 ms /   236 runs   (    0.54 ms per token,  1838.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1362.79 ms /    91 tokens (   14.98 ms per token,    66.77 tokens per second)\n",
      "llama_print_timings:        eval time =   21987.01 ms /   235 runs   (   93.56 ms per token,    10.69 tokens per second)\n",
      "llama_print_timings:       total time =   23628.25 ms /   326 tokens\n",
      " 20%|██        | 4/20 [01:12<05:03, 18.95s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     131.59 ms /   224 runs   (    0.59 ms per token,  1702.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1694.05 ms /    76 tokens (   22.29 ms per token,    44.86 tokens per second)\n",
      "llama_print_timings:        eval time =   21225.83 ms /   223 runs   (   95.18 ms per token,    10.51 tokens per second)\n",
      "llama_print_timings:       total time =   23247.36 ms /   299 tokens\n",
      " 25%|██▌       | 5/20 [01:36<05:07, 20.50s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     129.26 ms /   221 runs   (    0.58 ms per token,  1709.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1791.72 ms /    81 tokens (   22.12 ms per token,    45.21 tokens per second)\n",
      "llama_print_timings:        eval time =   20933.19 ms /   220 runs   (   95.15 ms per token,    10.51 tokens per second)\n",
      "llama_print_timings:       total time =   23043.56 ms /   301 tokens\n",
      " 30%|███       | 6/20 [01:59<04:59, 21.37s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     163.82 ms /   283 runs   (    0.58 ms per token,  1727.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1305.86 ms /    83 tokens (   15.73 ms per token,    63.56 tokens per second)\n",
      "llama_print_timings:        eval time =   26871.62 ms /   282 runs   (   95.29 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:       total time =   28601.99 ms /   365 tokens\n",
      " 35%|███▌      | 7/20 [02:27<05:08, 23.74s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     273.02 ms /   482 runs   (    0.57 ms per token,  1765.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2619.25 ms /    80 tokens (   32.74 ms per token,    30.54 tokens per second)\n",
      "llama_print_timings:        eval time =   45332.51 ms /   481 runs   (   94.25 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =   48595.30 ms /   561 tokens\n",
      " 40%|████      | 8/20 [03:16<06:19, 31.65s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     301.19 ms /   512 runs   (    0.59 ms per token,  1699.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1597.84 ms /    85 tokens (   18.80 ms per token,    53.20 tokens per second)\n",
      "llama_print_timings:        eval time =   48209.38 ms /   511 runs   (   94.34 ms per token,    10.60 tokens per second)\n",
      "llama_print_timings:       total time =   50503.26 ms /   596 tokens\n",
      " 45%|████▌     | 9/20 [04:06<06:53, 37.55s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     118.61 ms /   209 runs   (    0.57 ms per token,  1762.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1584.04 ms /    85 tokens (   18.64 ms per token,    53.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19469.49 ms /   208 runs   (   93.60 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =   21305.14 ms /   293 tokens\n",
      " 50%|█████     | 10/20 [04:28<05:25, 32.53s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     289.53 ms /   510 runs   (    0.57 ms per token,  1761.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1515.94 ms /    81 tokens (   18.72 ms per token,    53.43 tokens per second)\n",
      "llama_print_timings:        eval time =   48104.15 ms /   509 runs   (   94.51 ms per token,    10.58 tokens per second)\n",
      "llama_print_timings:       total time =   50303.18 ms /   590 tokens\n",
      " 55%|█████▌    | 11/20 [05:18<05:41, 37.97s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     205.31 ms /   323 runs   (    0.64 ms per token,  1573.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1513.30 ms /    81 tokens (   18.68 ms per token,    53.53 tokens per second)\n",
      "llama_print_timings:        eval time =   30820.92 ms /   322 runs   (   95.72 ms per token,    10.45 tokens per second)\n",
      "llama_print_timings:       total time =   32858.50 ms /   403 tokens\n",
      " 60%|██████    | 12/20 [05:51<04:51, 36.42s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     190.27 ms /   305 runs   (    0.62 ms per token,  1602.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.10 ms /    80 tokens (   18.56 ms per token,    53.87 tokens per second)\n",
      "llama_print_timings:        eval time =   29081.28 ms /   304 runs   (   95.66 ms per token,    10.45 tokens per second)\n",
      "llama_print_timings:       total time =   31052.05 ms /   384 tokens\n",
      " 65%|██████▌   | 13/20 [06:22<04:03, 34.79s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     223.38 ms /   365 runs   (    0.61 ms per token,  1633.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1491.10 ms /    80 tokens (   18.64 ms per token,    53.65 tokens per second)\n",
      "llama_print_timings:        eval time =   34947.69 ms /   364 runs   (   96.01 ms per token,    10.42 tokens per second)\n",
      "llama_print_timings:       total time =   37036.41 ms /   444 tokens\n",
      " 70%|███████   | 14/20 [06:59<03:32, 35.47s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     310.69 ms /   512 runs   (    0.61 ms per token,  1647.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1562.05 ms /    83 tokens (   18.82 ms per token,    53.14 tokens per second)\n",
      "llama_print_timings:        eval time =   49287.91 ms /   511 runs   (   96.45 ms per token,    10.37 tokens per second)\n",
      "llama_print_timings:       total time =   51755.61 ms /   594 tokens\n",
      " 75%|███████▌  | 15/20 [07:51<03:21, 40.38s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     182.78 ms /   298 runs   (    0.61 ms per token,  1630.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1585.19 ms /    85 tokens (   18.65 ms per token,    53.62 tokens per second)\n",
      "llama_print_timings:        eval time =   28403.06 ms /   297 runs   (   95.63 ms per token,    10.46 tokens per second)\n",
      "llama_print_timings:       total time =   30460.31 ms /   382 tokens\n",
      " 80%|████████  | 16/20 [08:21<02:29, 37.40s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     288.53 ms /   460 runs   (    0.63 ms per token,  1594.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1534.27 ms /    82 tokens (   18.71 ms per token,    53.45 tokens per second)\n",
      "llama_print_timings:        eval time =   44101.19 ms /   459 runs   (   96.08 ms per token,    10.41 tokens per second)\n",
      "llama_print_timings:       total time =   46438.62 ms /   541 tokens\n",
      " 85%|████████▌ | 17/20 [09:08<02:00, 40.12s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     208.45 ms /   512 runs   (    0.41 ms per token,  2456.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1528.30 ms /    82 tokens (   18.64 ms per token,    53.65 tokens per second)\n",
      "llama_print_timings:        eval time =   48270.18 ms /   511 runs   (   94.46 ms per token,    10.59 tokens per second)\n",
      "llama_print_timings:       total time =   50371.88 ms /   593 tokens\n",
      " 90%|█████████ | 18/20 [09:58<01:26, 43.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     251.61 ms /   435 runs   (    0.58 ms per token,  1728.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1774.78 ms /    79 tokens (   22.47 ms per token,    44.51 tokens per second)\n",
      "llama_print_timings:        eval time =   40857.64 ms /   434 runs   (   94.14 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =   43198.68 ms /   513 tokens\n",
      " 95%|█████████▌| 19/20 [10:41<00:43, 43.20s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2971.87 ms\n",
      "llama_print_timings:      sample time =     192.08 ms /   346 runs   (    0.56 ms per token,  1801.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1523.61 ms /    81 tokens (   18.81 ms per token,    53.16 tokens per second)\n",
      "llama_print_timings:        eval time =   32451.34 ms /   345 runs   (   94.06 ms per token,    10.63 tokens per second)\n",
      "llama_print_timings:       total time =   34400.86 ms /   426 tokens\n",
      "100%|██████████| 20/20 [11:16<00:00, 33.81s/it]\n"
     ]
    }
   ],
   "source": [
    "#generate broad queries\n",
    "list_of_topicwords = get_topic_lists_from_pdf(nodes[:500], 100, 10)\n",
    "broad_queries = generate_broad_qa(list_of_topicwords, llm_gen, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(broad_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_750906/1406956713.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model)\n",
      "  0%|          | 0/173 [00:00<?, ?it/s]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     108.39 ms /   512 runs   (    0.21 ms per token,  4723.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2114.21 ms /   336 tokens (    6.29 ms per token,   158.92 tokens per second)\n",
      "llama_print_timings:        eval time =   17853.29 ms /   511 runs   (   34.94 ms per token,    28.62 tokens per second)\n",
      "llama_print_timings:       total time =   20358.63 ms /   847 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      68.46 ms /   512 runs   (    0.13 ms per token,  7479.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6110.95 ms /  1119 tokens (    5.46 ms per token,   183.11 tokens per second)\n",
      "llama_print_timings:        eval time =   20512.79 ms /   511 runs   (   40.14 ms per token,    24.91 tokens per second)\n",
      "llama_print_timings:       total time =   26960.90 ms /  1630 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      94.68 ms /   512 runs   (    0.18 ms per token,  5407.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1019.64 ms /   211 tokens (    4.83 ms per token,   206.94 tokens per second)\n",
      "llama_print_timings:        eval time =   17268.51 ms /   511 runs   (   33.79 ms per token,    29.59 tokens per second)\n",
      "llama_print_timings:       total time =   18652.03 ms /   722 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      88.78 ms /   512 runs   (    0.17 ms per token,  5766.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1476.82 ms /   292 tokens (    5.06 ms per token,   197.72 tokens per second)\n",
      "llama_print_timings:        eval time =   17602.12 ms /   511 runs   (   34.45 ms per token,    29.03 tokens per second)\n",
      "llama_print_timings:       total time =   19438.46 ms /   803 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      98.91 ms /   512 runs   (    0.19 ms per token,  5176.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.23 ms /   219 tokens (    5.46 ms per token,   183.23 tokens per second)\n",
      "llama_print_timings:        eval time =   17863.37 ms /   511 runs   (   34.96 ms per token,    28.61 tokens per second)\n",
      "llama_print_timings:       total time =   19598.05 ms /   730 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      76.99 ms /   512 runs   (    0.15 ms per token,  6650.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5679.21 ms /  1020 tokens (    5.57 ms per token,   179.60 tokens per second)\n",
      "llama_print_timings:        eval time =   20801.15 ms /   511 runs   (   40.71 ms per token,    24.57 tokens per second)\n",
      "llama_print_timings:       total time =   26974.80 ms /  1531 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.02 ms /   512 runs   (    0.14 ms per token,  7209.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5062.94 ms /   769 tokens (    6.58 ms per token,   151.89 tokens per second)\n",
      "llama_print_timings:        eval time =   19350.81 ms /   511 runs   (   37.87 ms per token,    26.41 tokens per second)\n",
      "llama_print_timings:       total time =   24748.92 ms /  1280 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.04 ms /   512 runs   (    0.14 ms per token,  7310.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2999.33 ms /   509 tokens (    5.89 ms per token,   169.70 tokens per second)\n",
      "llama_print_timings:        eval time =   18485.09 ms /   511 runs   (   36.17 ms per token,    27.64 tokens per second)\n",
      "llama_print_timings:       total time =   21807.47 ms /  1020 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.89 ms /   512 runs   (    0.14 ms per token,  7325.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1200.53 ms /   222 tokens (    5.41 ms per token,   184.92 tokens per second)\n",
      "llama_print_timings:        eval time =   17388.11 ms /   511 runs   (   34.03 ms per token,    29.39 tokens per second)\n",
      "llama_print_timings:       total time =   18909.02 ms /   733 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.14 ms /   512 runs   (    0.14 ms per token,  7196.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2514.39 ms /   431 tokens (    5.83 ms per token,   171.41 tokens per second)\n",
      "llama_print_timings:        eval time =   18157.14 ms /   511 runs   (   35.53 ms per token,    28.14 tokens per second)\n",
      "llama_print_timings:       total time =   20995.08 ms /   942 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.45 ms /   512 runs   (    0.16 ms per token,  6364.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4445.64 ms /   653 tokens (    6.81 ms per token,   146.89 tokens per second)\n",
      "llama_print_timings:        eval time =   19736.62 ms /   511 runs   (   38.62 ms per token,    25.89 tokens per second)\n",
      "llama_print_timings:       total time =   24686.31 ms /  1164 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.75 ms /   512 runs   (    0.14 ms per token,  7340.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12726.87 ms /  1766 tokens (    7.21 ms per token,   138.76 tokens per second)\n",
      "llama_print_timings:        eval time =   22853.08 ms /   511 runs   (   44.72 ms per token,    22.36 tokens per second)\n",
      "llama_print_timings:       total time =   35929.24 ms /  2277 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.93 ms /   512 runs   (    0.14 ms per token,  7218.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1749.92 ms /   309 tokens (    5.66 ms per token,   176.58 tokens per second)\n",
      "llama_print_timings:        eval time =   17828.83 ms /   511 runs   (   34.89 ms per token,    28.66 tokens per second)\n",
      "llama_print_timings:       total time =   19901.90 ms /   820 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.04 ms /   512 runs   (    0.14 ms per token,  7206.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1755.69 ms /   289 tokens (    6.08 ms per token,   164.61 tokens per second)\n",
      "llama_print_timings:        eval time =   17661.87 ms /   511 runs   (   34.56 ms per token,    28.93 tokens per second)\n",
      "llama_print_timings:       total time =   19741.17 ms /   800 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.20 ms /   512 runs   (    0.14 ms per token,  7191.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4697.14 ms /   765 tokens (    6.14 ms per token,   162.87 tokens per second)\n",
      "llama_print_timings:        eval time =   19356.88 ms /   511 runs   (   37.88 ms per token,    26.40 tokens per second)\n",
      "llama_print_timings:       total time =   24383.33 ms /  1276 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.25 ms /   512 runs   (    0.14 ms per token,  7186.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1544.10 ms /   200 tokens (    7.72 ms per token,   129.53 tokens per second)\n",
      "llama_print_timings:        eval time =   17232.77 ms /   511 runs   (   33.72 ms per token,    29.65 tokens per second)\n",
      "llama_print_timings:       total time =   19099.82 ms /   711 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.56 ms /   512 runs   (    0.16 ms per token,  6355.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12296.35 ms /  1778 tokens (    6.92 ms per token,   144.60 tokens per second)\n",
      "llama_print_timings:        eval time =   23750.13 ms /   511 runs   (   46.48 ms per token,    21.52 tokens per second)\n",
      "llama_print_timings:       total time =   36566.32 ms /  2289 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.84 ms /   512 runs   (    0.16 ms per token,  6333.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1477.57 ms /   221 tokens (    6.69 ms per token,   149.57 tokens per second)\n",
      "llama_print_timings:        eval time =   17916.99 ms /   511 runs   (   35.06 ms per token,    28.52 tokens per second)\n",
      "llama_print_timings:       total time =   19893.12 ms /   732 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.02 ms /   512 runs   (    0.14 ms per token,  7209.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3760.68 ms /   623 tokens (    6.04 ms per token,   165.66 tokens per second)\n",
      "llama_print_timings:        eval time =   18889.53 ms /   511 runs   (   36.97 ms per token,    27.05 tokens per second)\n",
      "llama_print_timings:       total time =   22977.38 ms /  1134 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.39 ms /   512 runs   (    0.14 ms per token,  7171.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     895.20 ms /   168 tokens (    5.33 ms per token,   187.67 tokens per second)\n",
      "llama_print_timings:        eval time =   17127.27 ms /   511 runs   (   33.52 ms per token,    29.84 tokens per second)\n",
      "llama_print_timings:       total time =   18346.09 ms /   679 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.75 ms /   512 runs   (    0.14 ms per token,  7237.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2053.32 ms /   309 tokens (    6.65 ms per token,   150.49 tokens per second)\n",
      "llama_print_timings:        eval time =   17864.35 ms /   511 runs   (   34.96 ms per token,    28.60 tokens per second)\n",
      "llama_print_timings:       total time =   20242.74 ms /   820 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.28 ms /   512 runs   (    0.14 ms per token,  7284.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12819.92 ms /  1751 tokens (    7.32 ms per token,   136.58 tokens per second)\n",
      "llama_print_timings:        eval time =   22763.12 ms /   511 runs   (   44.55 ms per token,    22.45 tokens per second)\n",
      "llama_print_timings:       total time =   35926.97 ms /  2262 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.69 ms /   512 runs   (    0.14 ms per token,  7243.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9399.97 ms /  1308 tokens (    7.19 ms per token,   139.15 tokens per second)\n",
      "llama_print_timings:        eval time =   21298.58 ms /   511 runs   (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =   31038.67 ms /  1819 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.08 ms /   512 runs   (    0.14 ms per token,  7203.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1907.39 ms /   338 tokens (    5.64 ms per token,   177.21 tokens per second)\n",
      "llama_print_timings:        eval time =   17907.10 ms /   511 runs   (   35.04 ms per token,    28.54 tokens per second)\n",
      "llama_print_timings:       total time =   20139.88 ms /   849 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.59 ms /   512 runs   (    0.14 ms per token,  7252.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4521.01 ms /   736 tokens (    6.14 ms per token,   162.80 tokens per second)\n",
      "llama_print_timings:        eval time =   19259.90 ms /   511 runs   (   37.69 ms per token,    26.53 tokens per second)\n",
      "llama_print_timings:       total time =   24112.37 ms /  1247 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      81.09 ms /   512 runs   (    0.16 ms per token,  6313.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1958.26 ms /   272 tokens (    7.20 ms per token,   138.90 tokens per second)\n",
      "llama_print_timings:        eval time =   18177.40 ms /   511 runs   (   35.57 ms per token,    28.11 tokens per second)\n",
      "llama_print_timings:       total time =   20636.54 ms /   783 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.19 ms /   512 runs   (    0.14 ms per token,  7191.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1302.16 ms /   237 tokens (    5.49 ms per token,   182.01 tokens per second)\n",
      "llama_print_timings:        eval time =   17367.71 ms /   511 runs   (   33.99 ms per token,    29.42 tokens per second)\n",
      "llama_print_timings:       total time =   18994.35 ms /   748 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.07 ms /   512 runs   (    0.14 ms per token,  7203.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1913.95 ms /   309 tokens (    6.19 ms per token,   161.45 tokens per second)\n",
      "llama_print_timings:        eval time =   17707.61 ms /   511 runs   (   34.65 ms per token,    28.86 tokens per second)\n",
      "llama_print_timings:       total time =   19948.02 ms /   820 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.53 ms /   512 runs   (    0.16 ms per token,  6358.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1357.49 ms /   214 tokens (    6.34 ms per token,   157.64 tokens per second)\n",
      "llama_print_timings:        eval time =   17910.32 ms /   511 runs   (   35.05 ms per token,    28.53 tokens per second)\n",
      "llama_print_timings:       total time =   19766.99 ms /   725 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.14 ms /   512 runs   (    0.16 ms per token,  6389.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15509.25 ms /  2129 tokens (    7.28 ms per token,   137.27 tokens per second)\n",
      "llama_print_timings:        eval time =   24992.46 ms /   511 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_print_timings:       total time =   41036.09 ms /  2640 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.47 ms /   512 runs   (    0.14 ms per token,  7163.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     938.61 ms /   176 tokens (    5.33 ms per token,   187.51 tokens per second)\n",
      "llama_print_timings:        eval time =   17137.35 ms /   511 runs   (   33.54 ms per token,    29.82 tokens per second)\n",
      "llama_print_timings:       total time =   18399.59 ms /   687 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.39 ms /   512 runs   (    0.14 ms per token,  7171.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1544.22 ms /   263 tokens (    5.87 ms per token,   170.31 tokens per second)\n",
      "llama_print_timings:        eval time =   17469.04 ms /   511 runs   (   34.19 ms per token,    29.25 tokens per second)\n",
      "llama_print_timings:       total time =   19337.79 ms /   774 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.78 ms /   512 runs   (    0.14 ms per token,  7233.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5681.70 ms /   875 tokens (    6.49 ms per token,   154.00 tokens per second)\n",
      "llama_print_timings:        eval time =   19701.90 ms /   511 runs   (   38.56 ms per token,    25.94 tokens per second)\n",
      "llama_print_timings:       total time =   25716.60 ms /  1386 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.47 ms /   512 runs   (    0.16 ms per token,  6362.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1667.41 ms /   219 tokens (    7.61 ms per token,   131.34 tokens per second)\n",
      "llama_print_timings:        eval time =   18041.80 ms /   511 runs   (   35.31 ms per token,    28.32 tokens per second)\n",
      "llama_print_timings:       total time =   20207.21 ms /   730 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.25 ms /   512 runs   (    0.14 ms per token,  7186.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2019.26 ms /   276 tokens (    7.32 ms per token,   136.68 tokens per second)\n",
      "llama_print_timings:        eval time =   17695.13 ms /   511 runs   (   34.63 ms per token,    28.88 tokens per second)\n",
      "llama_print_timings:       total time =   20035.50 ms /   787 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.41 ms /   512 runs   (    0.14 ms per token,  7271.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5062.49 ms /   824 tokens (    6.14 ms per token,   162.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19617.58 ms /   511 runs   (   38.39 ms per token,    26.05 tokens per second)\n",
      "llama_print_timings:       total time =   25009.37 ms /  1335 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      79.89 ms /   512 runs   (    0.16 ms per token,  6409.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8793.56 ms /  1307 tokens (    6.73 ms per token,   148.63 tokens per second)\n",
      "llama_print_timings:        eval time =   22224.79 ms /   511 runs   (   43.49 ms per token,    22.99 tokens per second)\n",
      "llama_print_timings:       total time =   31528.40 ms /  1818 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.35 ms /   512 runs   (    0.14 ms per token,  7176.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1358.31 ms /   245 tokens (    5.54 ms per token,   180.37 tokens per second)\n",
      "llama_print_timings:        eval time =   17514.98 ms /   511 runs   (   34.28 ms per token,    29.18 tokens per second)\n",
      "llama_print_timings:       total time =   19198.37 ms /   756 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.19 ms /   512 runs   (    0.14 ms per token,  7191.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1479.67 ms /   263 tokens (    5.63 ms per token,   177.74 tokens per second)\n",
      "llama_print_timings:        eval time =   17479.67 ms /   511 runs   (   34.21 ms per token,    29.23 tokens per second)\n",
      "llama_print_timings:       total time =   19284.46 ms /   774 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      74.71 ms /   512 runs   (    0.15 ms per token,  6853.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9299.12 ms /  1366 tokens (    6.81 ms per token,   146.90 tokens per second)\n",
      "llama_print_timings:        eval time =   21764.16 ms /   511 runs   (   42.59 ms per token,    23.48 tokens per second)\n",
      "llama_print_timings:       total time =   31509.99 ms /  1877 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.61 ms /   512 runs   (    0.14 ms per token,  7250.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2047.75 ms /   325 tokens (    6.30 ms per token,   158.71 tokens per second)\n",
      "llama_print_timings:        eval time =   17744.16 ms /   511 runs   (   34.72 ms per token,    28.80 tokens per second)\n",
      "llama_print_timings:       total time =   20116.95 ms /   836 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.66 ms /   512 runs   (    0.14 ms per token,  7246.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15925.36 ms /  2174 tokens (    7.33 ms per token,   136.51 tokens per second)\n",
      "llama_print_timings:        eval time =   24036.13 ms /   511 runs   (   47.04 ms per token,    21.26 tokens per second)\n",
      "llama_print_timings:       total time =   40312.53 ms /  2685 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.77 ms /   512 runs   (    0.14 ms per token,  7234.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2469.11 ms /   389 tokens (    6.35 ms per token,   157.55 tokens per second)\n",
      "llama_print_timings:        eval time =   18081.16 ms /   511 runs   (   35.38 ms per token,    28.26 tokens per second)\n",
      "llama_print_timings:       total time =   20872.76 ms /   900 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.74 ms /   512 runs   (    0.14 ms per token,  7341.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12073.40 ms /  1736 tokens (    6.95 ms per token,   143.79 tokens per second)\n",
      "llama_print_timings:        eval time =   22616.94 ms /   511 runs   (   44.26 ms per token,    22.59 tokens per second)\n",
      "llama_print_timings:       total time =   35030.02 ms /  2247 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.54 ms /   512 runs   (    0.16 ms per token,  6357.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8236.84 ms /  1257 tokens (    6.55 ms per token,   152.61 tokens per second)\n",
      "llama_print_timings:        eval time =   21881.79 ms /   511 runs   (   42.82 ms per token,    23.35 tokens per second)\n",
      "llama_print_timings:       total time =   30629.77 ms /  1768 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.00 ms /   512 runs   (    0.14 ms per token,  7313.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10704.67 ms /  1484 tokens (    7.21 ms per token,   138.63 tokens per second)\n",
      "llama_print_timings:        eval time =   21874.40 ms /   511 runs   (   42.81 ms per token,    23.36 tokens per second)\n",
      "llama_print_timings:       total time =   32918.70 ms /  1995 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.87 ms /   512 runs   (    0.16 ms per token,  6331.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.12 ms /   170 tokens (    6.95 ms per token,   143.93 tokens per second)\n",
      "llama_print_timings:        eval time =   17709.42 ms /   511 runs   (   34.66 ms per token,    28.85 tokens per second)\n",
      "llama_print_timings:       total time =   19388.29 ms /   681 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.42 ms /   512 runs   (    0.14 ms per token,  7169.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2762.91 ms /   404 tokens (    6.84 ms per token,   146.22 tokens per second)\n",
      "llama_print_timings:        eval time =   18046.68 ms /   511 runs   (   35.32 ms per token,    28.32 tokens per second)\n",
      "llama_print_timings:       total time =   21134.20 ms /   915 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.64 ms /   512 runs   (    0.16 ms per token,  6348.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2576.83 ms /   406 tokens (    6.35 ms per token,   157.56 tokens per second)\n",
      "llama_print_timings:        eval time =   18789.03 ms /   511 runs   (   36.77 ms per token,    27.20 tokens per second)\n",
      "llama_print_timings:       total time =   21866.77 ms /   917 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.17 ms /   512 runs   (    0.16 ms per token,  6386.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9176.84 ms /  1366 tokens (    6.72 ms per token,   148.85 tokens per second)\n",
      "llama_print_timings:        eval time =   22047.46 ms /   511 runs   (   43.15 ms per token,    23.18 tokens per second)\n",
      "llama_print_timings:       total time =   31740.22 ms /  1877 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.49 ms /   512 runs   (    0.14 ms per token,  7368.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16773.69 ms /  2277 tokens (    7.37 ms per token,   135.75 tokens per second)\n",
      "llama_print_timings:        eval time =   24359.65 ms /   511 runs   (   47.67 ms per token,    20.98 tokens per second)\n",
      "llama_print_timings:       total time =   41482.56 ms /  2788 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      75.49 ms /   512 runs   (    0.15 ms per token,  6782.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17381.77 ms /  2382 tokens (    7.30 ms per token,   137.04 tokens per second)\n",
      "llama_print_timings:        eval time =   25242.61 ms /   511 runs   (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_print_timings:       total time =   43047.90 ms /  2893 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.80 ms /   512 runs   (    0.14 ms per token,  7130.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2078.86 ms /   309 tokens (    6.73 ms per token,   148.64 tokens per second)\n",
      "llama_print_timings:        eval time =   17643.50 ms /   511 runs   (   34.53 ms per token,    28.96 tokens per second)\n",
      "llama_print_timings:       total time =   20045.47 ms /   820 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      77.11 ms /   512 runs   (    0.15 ms per token,  6639.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2231.27 ms /   249 tokens (    8.96 ms per token,   111.60 tokens per second)\n",
      "llama_print_timings:        eval time =   17454.40 ms /   511 runs   (   34.16 ms per token,    29.28 tokens per second)\n",
      "llama_print_timings:       total time =   20022.53 ms /   760 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.48 ms /   512 runs   (    0.14 ms per token,  7264.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5248.97 ms /   851 tokens (    6.17 ms per token,   162.13 tokens per second)\n",
      "llama_print_timings:        eval time =   19699.73 ms /   511 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
      "llama_print_timings:       total time =   25275.08 ms /  1362 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.02 ms /   512 runs   (    0.14 ms per token,  7209.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3452.95 ms /   576 tokens (    5.99 ms per token,   166.81 tokens per second)\n",
      "llama_print_timings:        eval time =   18698.83 ms /   511 runs   (   36.59 ms per token,    27.33 tokens per second)\n",
      "llama_print_timings:       total time =   22478.61 ms /  1087 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.66 ms /   512 runs   (    0.14 ms per token,  7245.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5430.65 ms /   872 tokens (    6.23 ms per token,   160.57 tokens per second)\n",
      "llama_print_timings:        eval time =   19699.32 ms /   511 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
      "llama_print_timings:       total time =   25458.27 ms /  1383 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.68 ms /   512 runs   (    0.14 ms per token,  7244.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2252.72 ms /   290 tokens (    7.77 ms per token,   128.73 tokens per second)\n",
      "llama_print_timings:        eval time =   17700.96 ms /   511 runs   (   34.64 ms per token,    28.87 tokens per second)\n",
      "llama_print_timings:       total time =   20277.51 ms /   801 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.18 ms /   512 runs   (    0.14 ms per token,  7193.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3106.68 ms /   482 tokens (    6.45 ms per token,   155.15 tokens per second)\n",
      "llama_print_timings:        eval time =   18367.33 ms /   511 runs   (   35.94 ms per token,    27.82 tokens per second)\n",
      "llama_print_timings:       total time =   21800.80 ms /   993 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.29 ms /   512 runs   (    0.14 ms per token,  7182.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2720.98 ms /   442 tokens (    6.16 ms per token,   162.44 tokens per second)\n",
      "llama_print_timings:        eval time =   18224.23 ms /   511 runs   (   35.66 ms per token,    28.04 tokens per second)\n",
      "llama_print_timings:       total time =   21270.70 ms /   953 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.23 ms /   512 runs   (    0.14 ms per token,  7187.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1802.64 ms /   317 tokens (    5.69 ms per token,   175.85 tokens per second)\n",
      "llama_print_timings:        eval time =   17732.41 ms /   511 runs   (   34.70 ms per token,    28.82 tokens per second)\n",
      "llama_print_timings:       total time =   19859.97 ms /   828 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.84 ms /   512 runs   (    0.14 ms per token,  7227.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16536.65 ms /  2203 tokens (    7.51 ms per token,   133.22 tokens per second)\n",
      "llama_print_timings:        eval time =   24102.66 ms /   511 runs   (   47.17 ms per token,    21.20 tokens per second)\n",
      "llama_print_timings:       total time =   40989.85 ms /  2714 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.74 ms /   512 runs   (    0.14 ms per token,  7237.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9209.10 ms /  1325 tokens (    6.95 ms per token,   143.88 tokens per second)\n",
      "llama_print_timings:        eval time =   21381.54 ms /   511 runs   (   41.84 ms per token,    23.90 tokens per second)\n",
      "llama_print_timings:       total time =   30930.41 ms /  1836 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.12 ms /   512 runs   (    0.14 ms per token,  7198.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10248.51 ms /  1509 tokens (    6.79 ms per token,   147.24 tokens per second)\n",
      "llama_print_timings:        eval time =   21842.40 ms /   511 runs   (   42.74 ms per token,    23.39 tokens per second)\n",
      "llama_print_timings:       total time =   32433.57 ms /  2020 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.38 ms /   512 runs   (    0.14 ms per token,  7275.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9049.22 ms /  1322 tokens (    6.85 ms per token,   146.09 tokens per second)\n",
      "llama_print_timings:        eval time =   21182.86 ms /   511 runs   (   41.45 ms per token,    24.12 tokens per second)\n",
      "llama_print_timings:       total time =   30565.63 ms /  1833 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.21 ms /   512 runs   (    0.14 ms per token,  7190.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     959.80 ms /   176 tokens (    5.45 ms per token,   183.37 tokens per second)\n",
      "llama_print_timings:        eval time =   17093.88 ms /   511 runs   (   33.45 ms per token,    29.89 tokens per second)\n",
      "llama_print_timings:       total time =   18374.68 ms /   687 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.15 ms /   512 runs   (    0.14 ms per token,  7196.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1657.23 ms /   276 tokens (    6.00 ms per token,   166.54 tokens per second)\n",
      "llama_print_timings:        eval time =   17564.31 ms /   511 runs   (   34.37 ms per token,    29.09 tokens per second)\n",
      "llama_print_timings:       total time =   19544.84 ms /   787 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.17 ms /   512 runs   (    0.14 ms per token,  7194.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2088.79 ms /   362 tokens (    5.77 ms per token,   173.31 tokens per second)\n",
      "llama_print_timings:        eval time =   17899.85 ms /   511 runs   (   35.03 ms per token,    28.55 tokens per second)\n",
      "llama_print_timings:       total time =   20312.02 ms /   873 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.39 ms /   512 runs   (    0.14 ms per token,  7171.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3023.15 ms /   490 tokens (    6.17 ms per token,   162.08 tokens per second)\n",
      "llama_print_timings:        eval time =   18431.10 ms /   511 runs   (   36.07 ms per token,    27.72 tokens per second)\n",
      "llama_print_timings:       total time =   21778.69 ms /  1001 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.98 ms /   512 runs   (    0.14 ms per token,  7212.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1327.43 ms /   240 tokens (    5.53 ms per token,   180.80 tokens per second)\n",
      "llama_print_timings:        eval time =   17533.56 ms /   511 runs   (   34.31 ms per token,    29.14 tokens per second)\n",
      "llama_print_timings:       total time =   19182.60 ms /   751 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.93 ms /   512 runs   (    0.14 ms per token,  7218.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5121.40 ms /   784 tokens (    6.53 ms per token,   153.08 tokens per second)\n",
      "llama_print_timings:        eval time =   19386.30 ms /   511 runs   (   37.94 ms per token,    26.36 tokens per second)\n",
      "llama_print_timings:       total time =   24835.56 ms /  1295 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.14 ms /   512 runs   (    0.14 ms per token,  7299.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10421.65 ms /  1536 tokens (    6.78 ms per token,   147.39 tokens per second)\n",
      "llama_print_timings:        eval time =   21893.33 ms /   511 runs   (   42.84 ms per token,    23.34 tokens per second)\n",
      "llama_print_timings:       total time =   32657.62 ms /  2047 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.57 ms /   512 runs   (    0.14 ms per token,  7153.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1454.16 ms /   260 tokens (    5.59 ms per token,   178.80 tokens per second)\n",
      "llama_print_timings:        eval time =   17596.30 ms /   511 runs   (   34.44 ms per token,    29.04 tokens per second)\n",
      "llama_print_timings:       total time =   19373.16 ms /   771 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.79 ms /   512 runs   (    0.14 ms per token,  7232.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4911.15 ms /   719 tokens (    6.83 ms per token,   146.40 tokens per second)\n",
      "llama_print_timings:        eval time =   19185.19 ms /   511 runs   (   37.54 ms per token,    26.64 tokens per second)\n",
      "llama_print_timings:       total time =   24425.07 ms /  1230 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.04 ms /   512 runs   (    0.14 ms per token,  7207.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4002.63 ms /   580 tokens (    6.90 ms per token,   144.90 tokens per second)\n",
      "llama_print_timings:        eval time =   18693.81 ms /   511 runs   (   36.58 ms per token,    27.34 tokens per second)\n",
      "llama_print_timings:       total time =   23020.97 ms /  1091 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.41 ms /   512 runs   (    0.14 ms per token,  7170.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     949.54 ms /   171 tokens (    5.55 ms per token,   180.09 tokens per second)\n",
      "llama_print_timings:        eval time =   17151.99 ms /   511 runs   (   33.57 ms per token,    29.79 tokens per second)\n",
      "llama_print_timings:       total time =   18422.60 ms /   682 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.82 ms /   512 runs   (    0.14 ms per token,  7229.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5071.92 ms /   811 tokens (    6.25 ms per token,   159.90 tokens per second)\n",
      "llama_print_timings:        eval time =   19601.29 ms /   511 runs   (   38.36 ms per token,    26.07 tokens per second)\n",
      "llama_print_timings:       total time =   25000.19 ms /  1322 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.92 ms /   512 runs   (    0.16 ms per token,  6327.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5095.09 ms /   780 tokens (    6.53 ms per token,   153.09 tokens per second)\n",
      "llama_print_timings:        eval time =   20055.39 ms /   511 runs   (   39.25 ms per token,    25.48 tokens per second)\n",
      "llama_print_timings:       total time =   25656.18 ms /  1291 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.18 ms /   512 runs   (    0.14 ms per token,  7193.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11586.17 ms /  1651 tokens (    7.02 ms per token,   142.50 tokens per second)\n",
      "llama_print_timings:        eval time =   22301.15 ms /   511 runs   (   43.64 ms per token,    22.91 tokens per second)\n",
      "llama_print_timings:       total time =   34227.51 ms /  2162 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.91 ms /   512 runs   (    0.14 ms per token,  7119.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2488.04 ms /   408 tokens (    6.10 ms per token,   163.98 tokens per second)\n",
      "llama_print_timings:        eval time =   18023.32 ms /   511 runs   (   35.27 ms per token,    28.35 tokens per second)\n",
      "llama_print_timings:       total time =   20837.78 ms /   919 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.73 ms /   512 runs   (    0.16 ms per token,  6341.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1922.56 ms /   317 tokens (    6.06 ms per token,   164.88 tokens per second)\n",
      "llama_print_timings:        eval time =   18324.65 ms /   511 runs   (   35.86 ms per token,    27.89 tokens per second)\n",
      "llama_print_timings:       total time =   20745.08 ms /   828 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.21 ms /   512 runs   (    0.16 ms per token,  6383.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14070.10 ms /  2008 tokens (    7.01 ms per token,   142.71 tokens per second)\n",
      "llama_print_timings:        eval time =   24514.73 ms /   511 runs   (   47.97 ms per token,    20.84 tokens per second)\n",
      "llama_print_timings:       total time =   39108.11 ms /  2519 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.90 ms /   512 runs   (    0.16 ms per token,  6328.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4522.03 ms /   708 tokens (    6.39 ms per token,   156.57 tokens per second)\n",
      "llama_print_timings:        eval time =   19896.87 ms /   511 runs   (   38.94 ms per token,    25.68 tokens per second)\n",
      "llama_print_timings:       total time =   24921.61 ms /  1219 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.40 ms /   512 runs   (    0.14 ms per token,  7171.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1670.35 ms /   278 tokens (    6.01 ms per token,   166.43 tokens per second)\n",
      "llama_print_timings:        eval time =   17535.96 ms /   511 runs   (   34.32 ms per token,    29.14 tokens per second)\n",
      "llama_print_timings:       total time =   19528.52 ms /   789 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.42 ms /   512 runs   (    0.14 ms per token,  7168.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1487.71 ms /   267 tokens (    5.57 ms per token,   179.47 tokens per second)\n",
      "llama_print_timings:        eval time =   17480.74 ms /   511 runs   (   34.21 ms per token,    29.23 tokens per second)\n",
      "llama_print_timings:       total time =   19291.75 ms /   778 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.69 ms /   512 runs   (    0.16 ms per token,  6345.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11183.60 ms /  1627 tokens (    6.87 ms per token,   145.48 tokens per second)\n",
      "llama_print_timings:        eval time =   22890.59 ms /   511 runs   (   44.80 ms per token,    22.32 tokens per second)\n",
      "llama_print_timings:       total time =   34591.14 ms /  2138 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.10 ms /   512 runs   (    0.14 ms per token,  7201.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8423.84 ms /  1253 tokens (    6.72 ms per token,   148.74 tokens per second)\n",
      "llama_print_timings:        eval time =   20980.21 ms /   511 runs   (   41.06 ms per token,    24.36 tokens per second)\n",
      "llama_print_timings:       total time =   29738.11 ms /  1764 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.53 ms /   512 runs   (    0.16 ms per token,  6357.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6256.89 ms /   996 tokens (    6.28 ms per token,   159.18 tokens per second)\n",
      "llama_print_timings:        eval time =   20837.54 ms /   511 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
      "llama_print_timings:       total time =   27601.23 ms /  1507 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.25 ms /   512 runs   (    0.14 ms per token,  7185.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7162.01 ms /  1100 tokens (    6.51 ms per token,   153.59 tokens per second)\n",
      "llama_print_timings:        eval time =   20523.48 ms /   511 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
      "llama_print_timings:       total time =   28022.77 ms /  1611 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.46 ms /   512 runs   (    0.14 ms per token,  7165.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     985.85 ms /   183 tokens (    5.39 ms per token,   185.63 tokens per second)\n",
      "llama_print_timings:        eval time =   17315.62 ms /   511 runs   (   33.89 ms per token,    29.51 tokens per second)\n",
      "llama_print_timings:       total time =   18622.69 ms /   694 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.50 ms /   512 runs   (    0.14 ms per token,  7160.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1836.52 ms /   324 tokens (    5.67 ms per token,   176.42 tokens per second)\n",
      "llama_print_timings:        eval time =   17804.21 ms /   511 runs   (   34.84 ms per token,    28.70 tokens per second)\n",
      "llama_print_timings:       total time =   19963.59 ms /   835 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.45 ms /   512 runs   (    0.16 ms per token,  6364.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12188.45 ms /  1745 tokens (    6.98 ms per token,   143.17 tokens per second)\n",
      "llama_print_timings:        eval time =   23291.92 ms /   511 runs   (   45.58 ms per token,    21.94 tokens per second)\n",
      "llama_print_timings:       total time =   36000.50 ms /  2256 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.91 ms /   512 runs   (    0.14 ms per token,  7220.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5457.86 ms /   855 tokens (    6.38 ms per token,   156.65 tokens per second)\n",
      "llama_print_timings:        eval time =   19641.10 ms /   511 runs   (   38.44 ms per token,    26.02 tokens per second)\n",
      "llama_print_timings:       total time =   25426.69 ms /  1366 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.79 ms /   512 runs   (    0.16 ms per token,  6337.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4455.02 ms /   663 tokens (    6.72 ms per token,   148.82 tokens per second)\n",
      "llama_print_timings:        eval time =   19800.72 ms /   511 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
      "llama_print_timings:       total time =   24757.33 ms /  1174 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.01 ms /   512 runs   (    0.14 ms per token,  7210.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10320.47 ms /  1198 tokens (    8.61 ms per token,   116.08 tokens per second)\n",
      "llama_print_timings:        eval time =   20787.50 ms /   511 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:       total time =   31446.18 ms /  1709 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.63 ms /   512 runs   (    0.14 ms per token,  7147.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2019.97 ms /   160 tokens (   12.62 ms per token,    79.21 tokens per second)\n",
      "llama_print_timings:        eval time =   17066.48 ms /   511 runs   (   33.40 ms per token,    29.94 tokens per second)\n",
      "llama_print_timings:       total time =   19409.95 ms /   671 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.20 ms /   512 runs   (    0.16 ms per token,  6384.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5579.74 ms /   786 tokens (    7.10 ms per token,   140.87 tokens per second)\n",
      "llama_print_timings:        eval time =   20350.76 ms /   511 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
      "llama_print_timings:       total time =   26430.81 ms /  1297 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.55 ms /   512 runs   (    0.14 ms per token,  7155.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.61 ms /   250 tokens (    5.58 ms per token,   179.13 tokens per second)\n",
      "llama_print_timings:        eval time =   17561.16 ms /   511 runs   (   34.37 ms per token,    29.10 tokens per second)\n",
      "llama_print_timings:       total time =   19279.12 ms /   761 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.55 ms /   512 runs   (    0.14 ms per token,  7256.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6882.08 ms /  1085 tokens (    6.34 ms per token,   157.66 tokens per second)\n",
      "llama_print_timings:        eval time =   20444.85 ms /   511 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
      "llama_print_timings:       total time =   27657.85 ms /  1596 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.34 ms /   512 runs   (    0.14 ms per token,  7176.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3271.19 ms /   476 tokens (    6.87 ms per token,   145.51 tokens per second)\n",
      "llama_print_timings:        eval time =   18351.88 ms /   511 runs   (   35.91 ms per token,    27.84 tokens per second)\n",
      "llama_print_timings:       total time =   21945.07 ms /   987 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      81.02 ms /   512 runs   (    0.16 ms per token,  6319.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3006.92 ms /   497 tokens (    6.05 ms per token,   165.29 tokens per second)\n",
      "llama_print_timings:        eval time =   19045.64 ms /   511 runs   (   37.27 ms per token,    26.83 tokens per second)\n",
      "llama_print_timings:       total time =   22550.30 ms /  1008 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.49 ms /   512 runs   (    0.16 ms per token,  6361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13735.92 ms /  1982 tokens (    6.93 ms per token,   144.29 tokens per second)\n",
      "llama_print_timings:        eval time =   24223.06 ms /   511 runs   (   47.40 ms per token,    21.10 tokens per second)\n",
      "llama_print_timings:       total time =   38478.78 ms /  2493 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.32 ms /   512 runs   (    0.14 ms per token,  7178.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.49 ms /   219 tokens (    5.49 ms per token,   182.12 tokens per second)\n",
      "llama_print_timings:        eval time =   17434.28 ms /   511 runs   (   34.12 ms per token,    29.31 tokens per second)\n",
      "llama_print_timings:       total time =   18957.59 ms /   730 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.24 ms /   512 runs   (    0.14 ms per token,  7186.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1647.88 ms /   281 tokens (    5.86 ms per token,   170.52 tokens per second)\n",
      "llama_print_timings:        eval time =   17530.68 ms /   511 runs   (   34.31 ms per token,    29.15 tokens per second)\n",
      "llama_print_timings:       total time =   19500.99 ms /   792 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.07 ms /   512 runs   (    0.14 ms per token,  7204.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5590.82 ms /   864 tokens (    6.47 ms per token,   154.54 tokens per second)\n",
      "llama_print_timings:        eval time =   19686.47 ms /   511 runs   (   38.53 ms per token,    25.96 tokens per second)\n",
      "llama_print_timings:       total time =   25610.80 ms /  1375 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.02 ms /   512 runs   (    0.14 ms per token,  7209.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5850.45 ms /   862 tokens (    6.79 ms per token,   147.34 tokens per second)\n",
      "llama_print_timings:        eval time =   19662.56 ms /   511 runs   (   38.48 ms per token,    25.99 tokens per second)\n",
      "llama_print_timings:       total time =   25842.59 ms /  1373 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.52 ms /   512 runs   (    0.16 ms per token,  6358.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9141.48 ms /  1378 tokens (    6.63 ms per token,   150.74 tokens per second)\n",
      "llama_print_timings:        eval time =   22314.98 ms /   511 runs   (   43.67 ms per token,    22.90 tokens per second)\n",
      "llama_print_timings:       total time =   31970.08 ms /  1889 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.35 ms /   512 runs   (    0.16 ms per token,  6371.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8646.44 ms /  1326 tokens (    6.52 ms per token,   153.36 tokens per second)\n",
      "llama_print_timings:        eval time =   22120.04 ms /   511 runs   (   43.29 ms per token,    23.10 tokens per second)\n",
      "llama_print_timings:       total time =   31276.77 ms /  1837 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.13 ms /   512 runs   (    0.16 ms per token,  6389.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5817.12 ms /   916 tokens (    6.35 ms per token,   157.47 tokens per second)\n",
      "llama_print_timings:        eval time =   20837.43 ms /   511 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
      "llama_print_timings:       total time =   27154.68 ms /  1427 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.60 ms /   512 runs   (    0.16 ms per token,  6352.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8694.97 ms /  1122 tokens (    7.75 ms per token,   129.04 tokens per second)\n",
      "llama_print_timings:        eval time =   21254.68 ms /   511 runs   (   41.59 ms per token,    24.04 tokens per second)\n",
      "llama_print_timings:       total time =   30457.25 ms /  1633 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.49 ms /   512 runs   (    0.14 ms per token,  7162.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3670.71 ms /   572 tokens (    6.42 ms per token,   155.83 tokens per second)\n",
      "llama_print_timings:        eval time =   18679.02 ms /   511 runs   (   36.55 ms per token,    27.36 tokens per second)\n",
      "llama_print_timings:       total time =   22676.66 ms /  1083 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.76 ms /   512 runs   (    0.14 ms per token,  7134.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3823.70 ms /   604 tokens (    6.33 ms per token,   157.96 tokens per second)\n",
      "llama_print_timings:        eval time =   18806.77 ms /   511 runs   (   36.80 ms per token,    27.17 tokens per second)\n",
      "llama_print_timings:       total time =   22959.03 ms /  1115 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.44 ms /   512 runs   (    0.14 ms per token,  7166.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1877.36 ms /   330 tokens (    5.69 ms per token,   175.78 tokens per second)\n",
      "llama_print_timings:        eval time =   17803.49 ms /   511 runs   (   34.84 ms per token,    28.70 tokens per second)\n",
      "llama_print_timings:       total time =   20002.54 ms /   841 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      81.05 ms /   512 runs   (    0.16 ms per token,  6316.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2492.14 ms /   362 tokens (    6.88 ms per token,   145.26 tokens per second)\n",
      "llama_print_timings:        eval time =   18640.66 ms /   511 runs   (   36.48 ms per token,    27.41 tokens per second)\n",
      "llama_print_timings:       total time =   21629.25 ms /   873 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.78 ms /   512 runs   (    0.14 ms per token,  7233.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9858.85 ms /  1443 tokens (    6.83 ms per token,   146.37 tokens per second)\n",
      "llama_print_timings:        eval time =   21643.93 ms /   511 runs   (   42.36 ms per token,    23.61 tokens per second)\n",
      "llama_print_timings:       total time =   31839.47 ms /  1954 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.82 ms /   512 runs   (    0.14 ms per token,  7229.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2275.98 ms /   393 tokens (    5.79 ms per token,   172.67 tokens per second)\n",
      "llama_print_timings:        eval time =   18049.13 ms /   511 runs   (   35.32 ms per token,    28.31 tokens per second)\n",
      "llama_print_timings:       total time =   20650.36 ms /   904 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.10 ms /   512 runs   (    0.14 ms per token,  7201.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1047.13 ms /   193 tokens (    5.43 ms per token,   184.31 tokens per second)\n",
      "llama_print_timings:        eval time =   17272.46 ms /   511 runs   (   33.80 ms per token,    29.58 tokens per second)\n",
      "llama_print_timings:       total time =   18641.41 ms /   704 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.29 ms /   512 runs   (    0.14 ms per token,  7182.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2629.89 ms /   445 tokens (    5.91 ms per token,   169.21 tokens per second)\n",
      "llama_print_timings:        eval time =   18288.81 ms /   511 runs   (   35.79 ms per token,    27.94 tokens per second)\n",
      "llama_print_timings:       total time =   21244.09 ms /   956 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.14 ms /   512 runs   (    0.14 ms per token,  7197.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3354.77 ms /   519 tokens (    6.46 ms per token,   154.71 tokens per second)\n",
      "llama_print_timings:        eval time =   18590.70 ms /   511 runs   (   36.38 ms per token,    27.49 tokens per second)\n",
      "llama_print_timings:       total time =   22269.02 ms /  1030 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.43 ms /   512 runs   (    0.16 ms per token,  6365.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8895.39 ms /  1271 tokens (    7.00 ms per token,   142.88 tokens per second)\n",
      "llama_print_timings:        eval time =   21831.26 ms /   511 runs   (   42.72 ms per token,    23.41 tokens per second)\n",
      "llama_print_timings:       total time =   31236.93 ms /  1782 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.14 ms /   512 runs   (    0.14 ms per token,  7196.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     836.53 ms /   157 tokens (    5.33 ms per token,   187.68 tokens per second)\n",
      "llama_print_timings:        eval time =   17074.50 ms /   511 runs   (   33.41 ms per token,    29.93 tokens per second)\n",
      "llama_print_timings:       total time =   18231.81 ms /   668 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.26 ms /   512 runs   (    0.14 ms per token,  7185.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7433.48 ms /  1123 tokens (    6.62 ms per token,   151.07 tokens per second)\n",
      "llama_print_timings:        eval time =   20565.06 ms /   511 runs   (   40.24 ms per token,    24.85 tokens per second)\n",
      "llama_print_timings:       total time =   28334.21 ms /  1634 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.15 ms /   512 runs   (    0.14 ms per token,  7196.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5262.73 ms /   854 tokens (    6.16 ms per token,   162.27 tokens per second)\n",
      "llama_print_timings:        eval time =   19597.35 ms /   511 runs   (   38.35 ms per token,    26.07 tokens per second)\n",
      "llama_print_timings:       total time =   25187.97 ms /  1365 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.87 ms /   512 runs   (    0.14 ms per token,  7224.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1845.80 ms /   325 tokens (    5.68 ms per token,   176.08 tokens per second)\n",
      "llama_print_timings:        eval time =   17709.95 ms /   511 runs   (   34.66 ms per token,    28.85 tokens per second)\n",
      "llama_print_timings:       total time =   19876.58 ms /   836 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.91 ms /   512 runs   (    0.14 ms per token,  7220.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6601.75 ms /  1043 tokens (    6.33 ms per token,   157.99 tokens per second)\n",
      "llama_print_timings:        eval time =   20282.90 ms /   511 runs   (   39.69 ms per token,    25.19 tokens per second)\n",
      "llama_print_timings:       total time =   27213.58 ms /  1554 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.67 ms /   512 runs   (    0.14 ms per token,  7244.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6478.54 ms /  1013 tokens (    6.40 ms per token,   156.36 tokens per second)\n",
      "llama_print_timings:        eval time =   20175.07 ms /   511 runs   (   39.48 ms per token,    25.33 tokens per second)\n",
      "llama_print_timings:       total time =   26982.93 ms /  1524 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.29 ms /   512 runs   (    0.14 ms per token,  7181.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3268.70 ms /   543 tokens (    6.02 ms per token,   166.12 tokens per second)\n",
      "llama_print_timings:        eval time =   18686.67 ms /   511 runs   (   36.57 ms per token,    27.35 tokens per second)\n",
      "llama_print_timings:       total time =   22278.04 ms /  1054 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.91 ms /   512 runs   (    0.14 ms per token,  7324.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15744.69 ms /  2189 tokens (    7.19 ms per token,   139.03 tokens per second)\n",
      "llama_print_timings:        eval time =   24068.97 ms /   511 runs   (   47.10 ms per token,    21.23 tokens per second)\n",
      "llama_print_timings:       total time =   40157.69 ms /  2700 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.76 ms /   512 runs   (    0.14 ms per token,  7235.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8693.82 ms /  1272 tokens (    6.83 ms per token,   146.31 tokens per second)\n",
      "llama_print_timings:        eval time =   21097.94 ms /   511 runs   (   41.29 ms per token,    24.22 tokens per second)\n",
      "llama_print_timings:       total time =   30130.89 ms /  1783 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.73 ms /   512 runs   (    0.14 ms per token,  7239.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4221.08 ms /   639 tokens (    6.61 ms per token,   151.38 tokens per second)\n",
      "llama_print_timings:        eval time =   19010.44 ms /   511 runs   (   37.20 ms per token,    26.88 tokens per second)\n",
      "llama_print_timings:       total time =   23560.56 ms /  1150 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.92 ms /   512 runs   (    0.14 ms per token,  7219.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.77 ms /   161 tokens (    7.22 ms per token,   138.46 tokens per second)\n",
      "llama_print_timings:        eval time =   17094.87 ms /   511 runs   (   33.45 ms per token,    29.89 tokens per second)\n",
      "llama_print_timings:       total time =   18580.30 ms /   672 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.12 ms /   512 runs   (    0.16 ms per token,  6390.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7929.28 ms /  1203 tokens (    6.59 ms per token,   151.72 tokens per second)\n",
      "llama_print_timings:        eval time =   21927.49 ms /   511 runs   (   42.91 ms per token,    23.30 tokens per second)\n",
      "llama_print_timings:       total time =   30363.51 ms /  1714 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.86 ms /   512 runs   (    0.14 ms per token,  7225.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3627.24 ms /   605 tokens (    6.00 ms per token,   166.79 tokens per second)\n",
      "llama_print_timings:        eval time =   18897.09 ms /   511 runs   (   36.98 ms per token,    27.04 tokens per second)\n",
      "llama_print_timings:       total time =   22850.55 ms /  1116 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.40 ms /   512 runs   (    0.16 ms per token,  6368.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8793.89 ms /  1286 tokens (    6.84 ms per token,   146.24 tokens per second)\n",
      "llama_print_timings:        eval time =   21861.86 ms /   511 runs   (   42.78 ms per token,    23.37 tokens per second)\n",
      "llama_print_timings:       total time =   31164.93 ms /  1797 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.86 ms /   512 runs   (    0.14 ms per token,  7225.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8286.07 ms /  1077 tokens (    7.69 ms per token,   129.98 tokens per second)\n",
      "llama_print_timings:        eval time =   20455.75 ms /   511 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
      "llama_print_timings:       total time =   29078.06 ms /  1588 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.56 ms /   512 runs   (    0.16 ms per token,  6355.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10510.53 ms /  1485 tokens (    7.08 ms per token,   141.29 tokens per second)\n",
      "llama_print_timings:        eval time =   22723.88 ms /   511 runs   (   44.47 ms per token,    22.49 tokens per second)\n",
      "llama_print_timings:       total time =   33748.87 ms /  1996 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.78 ms /   512 runs   (    0.16 ms per token,  6338.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7100.60 ms /  1087 tokens (    6.53 ms per token,   153.09 tokens per second)\n",
      "llama_print_timings:        eval time =   21136.49 ms /   511 runs   (   41.36 ms per token,    24.18 tokens per second)\n",
      "llama_print_timings:       total time =   28745.47 ms /  1598 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.82 ms /   512 runs   (    0.16 ms per token,  6335.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2003.58 ms /   330 tokens (    6.07 ms per token,   164.71 tokens per second)\n",
      "llama_print_timings:        eval time =   18452.05 ms /   511 runs   (   36.11 ms per token,    27.69 tokens per second)\n",
      "llama_print_timings:       total time =   20951.35 ms /   841 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.64 ms /   512 runs   (    0.16 ms per token,  6349.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8068.99 ms /  1097 tokens (    7.36 ms per token,   135.95 tokens per second)\n",
      "llama_print_timings:        eval time =   21323.89 ms /   511 runs   (   41.73 ms per token,    23.96 tokens per second)\n",
      "llama_print_timings:       total time =   29899.10 ms /  1608 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.15 ms /   512 runs   (    0.14 ms per token,  7196.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.31 ms /   214 tokens (    5.44 ms per token,   183.96 tokens per second)\n",
      "llama_print_timings:        eval time =   17426.25 ms /   511 runs   (   34.10 ms per token,    29.32 tokens per second)\n",
      "llama_print_timings:       total time =   18910.62 ms /   725 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.41 ms /   512 runs   (    0.14 ms per token,  7271.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9661.83 ms /  1428 tokens (    6.77 ms per token,   147.80 tokens per second)\n",
      "llama_print_timings:        eval time =   21580.04 ms /   511 runs   (   42.23 ms per token,    23.68 tokens per second)\n",
      "llama_print_timings:       total time =   31585.48 ms /  1939 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.48 ms /   512 runs   (    0.16 ms per token,  6362.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13686.95 ms /  1817 tokens (    7.53 ms per token,   132.75 tokens per second)\n",
      "llama_print_timings:        eval time =   23889.35 ms /   511 runs   (   46.75 ms per token,    21.39 tokens per second)\n",
      "llama_print_timings:       total time =   38096.18 ms /  2328 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.54 ms /   512 runs   (    0.14 ms per token,  7258.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15978.94 ms /  2253 tokens (    7.09 ms per token,   141.00 tokens per second)\n",
      "llama_print_timings:        eval time =   24308.20 ms /   511 runs   (   47.57 ms per token,    21.02 tokens per second)\n",
      "llama_print_timings:       total time =   40640.82 ms /  2764 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.03 ms /   512 runs   (    0.14 ms per token,  7208.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14228.23 ms /  2035 tokens (    6.99 ms per token,   143.03 tokens per second)\n",
      "llama_print_timings:        eval time =   23583.22 ms /   511 runs   (   46.15 ms per token,    21.67 tokens per second)\n",
      "llama_print_timings:       total time =   38161.64 ms /  2546 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.01 ms /   512 runs   (    0.14 ms per token,  7210.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3790.85 ms /   628 tokens (    6.04 ms per token,   165.66 tokens per second)\n",
      "llama_print_timings:        eval time =   18908.32 ms /   511 runs   (   37.00 ms per token,    27.03 tokens per second)\n",
      "llama_print_timings:       total time =   23024.23 ms /  1139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.12 ms /   512 runs   (    0.14 ms per token,  7302.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14719.18 ms /  2008 tokens (    7.33 ms per token,   136.42 tokens per second)\n",
      "llama_print_timings:        eval time =   23462.72 ms /   511 runs   (   45.92 ms per token,    21.78 tokens per second)\n",
      "llama_print_timings:       total time =   38525.47 ms /  2519 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.83 ms /   512 runs   (    0.14 ms per token,  7228.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2772.47 ms /   452 tokens (    6.13 ms per token,   163.03 tokens per second)\n",
      "llama_print_timings:        eval time =   18235.68 ms /   511 runs   (   35.69 ms per token,    28.02 tokens per second)\n",
      "llama_print_timings:       total time =   21332.99 ms /   963 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.27 ms /   512 runs   (    0.14 ms per token,  7183.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2429.84 ms /   419 tokens (    5.80 ms per token,   172.44 tokens per second)\n",
      "llama_print_timings:        eval time =   18225.28 ms /   511 runs   (   35.67 ms per token,    28.04 tokens per second)\n",
      "llama_print_timings:       total time =   20975.36 ms /   930 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.49 ms /   512 runs   (    0.14 ms per token,  7263.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7294.88 ms /  1142 tokens (    6.39 ms per token,   156.55 tokens per second)\n",
      "llama_print_timings:        eval time =   20607.66 ms /   511 runs   (   40.33 ms per token,    24.80 tokens per second)\n",
      "llama_print_timings:       total time =   28234.78 ms /  1653 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.68 ms /   512 runs   (    0.16 ms per token,  6346.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7453.45 ms /  1125 tokens (    6.63 ms per token,   150.94 tokens per second)\n",
      "llama_print_timings:        eval time =   21314.62 ms /   511 runs   (   41.71 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:       total time =   29275.55 ms /  1636 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.55 ms /   512 runs   (    0.14 ms per token,  7155.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2080.51 ms /   328 tokens (    6.34 ms per token,   157.65 tokens per second)\n",
      "llama_print_timings:        eval time =   17722.05 ms /   511 runs   (   34.68 ms per token,    28.83 tokens per second)\n",
      "llama_print_timings:       total time =   20123.83 ms /   839 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.80 ms /   512 runs   (    0.16 ms per token,  6336.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3028.23 ms /   502 tokens (    6.03 ms per token,   165.77 tokens per second)\n",
      "llama_print_timings:        eval time =   19099.90 ms /   511 runs   (   37.38 ms per token,    26.75 tokens per second)\n",
      "llama_print_timings:       total time =   22626.76 ms /  1013 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.99 ms /   512 runs   (    0.14 ms per token,  7212.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3366.80 ms /   525 tokens (    6.41 ms per token,   155.93 tokens per second)\n",
      "llama_print_timings:        eval time =   18551.16 ms /   511 runs   (   36.30 ms per token,    27.55 tokens per second)\n",
      "llama_print_timings:       total time =   22240.94 ms /  1036 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.52 ms /   512 runs   (    0.14 ms per token,  7158.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1039.08 ms /   189 tokens (    5.50 ms per token,   181.89 tokens per second)\n",
      "llama_print_timings:        eval time =   17231.24 ms /   511 runs   (   33.72 ms per token,    29.66 tokens per second)\n",
      "llama_print_timings:       total time =   18591.88 ms /   700 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.61 ms /   512 runs   (    0.14 ms per token,  7149.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1457.16 ms /   261 tokens (    5.58 ms per token,   179.12 tokens per second)\n",
      "llama_print_timings:        eval time =   17480.03 ms /   511 runs   (   34.21 ms per token,    29.23 tokens per second)\n",
      "llama_print_timings:       total time =   19259.06 ms /   772 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.38 ms /   512 runs   (    0.14 ms per token,  7172.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3284.64 ms /   543 tokens (    6.05 ms per token,   165.31 tokens per second)\n",
      "llama_print_timings:        eval time =   18702.24 ms /   511 runs   (   36.60 ms per token,    27.32 tokens per second)\n",
      "llama_print_timings:       total time =   22312.82 ms /  1054 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.83 ms /   512 runs   (    0.14 ms per token,  7228.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6279.11 ms /   980 tokens (    6.41 ms per token,   156.07 tokens per second)\n",
      "llama_print_timings:        eval time =   20116.12 ms /   511 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
      "llama_print_timings:       total time =   26725.41 ms /  1491 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.34 ms /   512 runs   (    0.14 ms per token,  7278.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10798.86 ms /  1628 tokens (    6.63 ms per token,   150.76 tokens per second)\n",
      "llama_print_timings:        eval time =   22281.30 ms /   511 runs   (   43.60 ms per token,    22.93 tokens per second)\n",
      "llama_print_timings:       total time =   33418.51 ms /  2139 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.48 ms /   512 runs   (    0.14 ms per token,  7162.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1481.72 ms /   208 tokens (    7.12 ms per token,   140.38 tokens per second)\n",
      "llama_print_timings:        eval time =   17317.75 ms /   511 runs   (   33.89 ms per token,    29.51 tokens per second)\n",
      "llama_print_timings:       total time =   19121.75 ms /   719 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.23 ms /   512 runs   (    0.14 ms per token,  7187.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1842.50 ms /   322 tokens (    5.72 ms per token,   174.76 tokens per second)\n",
      "llama_print_timings:        eval time =   17766.16 ms /   511 runs   (   34.77 ms per token,    28.76 tokens per second)\n",
      "llama_print_timings:       total time =   19930.31 ms /   833 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.21 ms /   512 runs   (    0.14 ms per token,  7189.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2862.55 ms /   479 tokens (    5.98 ms per token,   167.33 tokens per second)\n",
      "llama_print_timings:        eval time =   18491.43 ms /   511 runs   (   36.19 ms per token,    27.63 tokens per second)\n",
      "llama_print_timings:       total time =   21676.77 ms /   990 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.97 ms /   512 runs   (    0.16 ms per token,  6323.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1547.78 ms /   264 tokens (    5.86 ms per token,   170.57 tokens per second)\n",
      "llama_print_timings:        eval time =   18128.74 ms /   511 runs   (   35.48 ms per token,    28.19 tokens per second)\n",
      "llama_print_timings:       total time =   20171.48 ms /   775 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.31 ms /   512 runs   (    0.16 ms per token,  6375.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14243.62 ms /  2032 tokens (    7.01 ms per token,   142.66 tokens per second)\n",
      "llama_print_timings:        eval time =   24648.91 ms /   511 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_print_timings:       total time =   39411.63 ms /  2543 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.66 ms /   512 runs   (    0.14 ms per token,  7245.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9710.52 ms /  1423 tokens (    6.82 ms per token,   146.54 tokens per second)\n",
      "llama_print_timings:        eval time =   21640.97 ms /   511 runs   (   42.35 ms per token,    23.61 tokens per second)\n",
      "llama_print_timings:       total time =   31693.63 ms /  1934 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.92 ms /   512 runs   (    0.16 ms per token,  6327.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3896.65 ms /   576 tokens (    6.77 ms per token,   147.82 tokens per second)\n",
      "llama_print_timings:        eval time =   19458.99 ms /   511 runs   (   38.08 ms per token,    26.26 tokens per second)\n",
      "llama_print_timings:       total time =   23855.28 ms /  1087 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.36 ms /   512 runs   (    0.14 ms per token,  7276.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7795.79 ms /  1219 tokens (    6.40 ms per token,   156.37 tokens per second)\n",
      "llama_print_timings:        eval time =   20917.19 ms /   511 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
      "llama_print_timings:       total time =   29045.62 ms /  1730 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.17 ms /   512 runs   (    0.14 ms per token,  7194.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1846.63 ms /   325 tokens (    5.68 ms per token,   176.00 tokens per second)\n",
      "llama_print_timings:        eval time =   17838.28 ms /   511 runs   (   34.91 ms per token,    28.65 tokens per second)\n",
      "llama_print_timings:       total time =   20005.40 ms /   836 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.19 ms /   512 runs   (    0.14 ms per token,  7294.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13244.69 ms /  1894 tokens (    6.99 ms per token,   143.00 tokens per second)\n",
      "llama_print_timings:        eval time =   23132.24 ms /   511 runs   (   45.27 ms per token,    22.09 tokens per second)\n",
      "llama_print_timings:       total time =   36717.35 ms /  2405 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.96 ms /   512 runs   (    0.14 ms per token,  7215.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1813.98 ms /   317 tokens (    5.72 ms per token,   174.75 tokens per second)\n",
      "llama_print_timings:        eval time =   17815.33 ms /   511 runs   (   34.86 ms per token,    28.68 tokens per second)\n",
      "llama_print_timings:       total time =   19949.62 ms /   828 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.19 ms /   512 runs   (    0.14 ms per token,  7294.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12007.24 ms /  1756 tokens (    6.84 ms per token,   146.25 tokens per second)\n",
      "llama_print_timings:        eval time =   22607.29 ms /   511 runs   (   44.24 ms per token,    22.60 tokens per second)\n",
      "llama_print_timings:       total time =   34954.70 ms /  2267 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.97 ms /   512 runs   (    0.16 ms per token,  6323.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2410.22 ms /   348 tokens (    6.93 ms per token,   144.39 tokens per second)\n",
      "llama_print_timings:        eval time =   18434.20 ms /   511 runs   (   36.07 ms per token,    27.72 tokens per second)\n",
      "llama_print_timings:       total time =   21341.95 ms /   859 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.23 ms /   512 runs   (    0.14 ms per token,  7187.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14244.60 ms /  2023 tokens (    7.04 ms per token,   142.02 tokens per second)\n",
      "llama_print_timings:        eval time =   23559.94 ms /   511 runs   (   46.11 ms per token,    21.69 tokens per second)\n",
      "llama_print_timings:       total time =   38151.06 ms /  2534 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.12 ms /   512 runs   (    0.14 ms per token,  7301.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14614.35 ms /  2036 tokens (    7.18 ms per token,   139.32 tokens per second)\n",
      "llama_print_timings:        eval time =   23551.13 ms /   511 runs   (   46.09 ms per token,    21.70 tokens per second)\n",
      "llama_print_timings:       total time =   38508.52 ms /  2547 tokens\n",
      "100%|██████████| 173/173 [1:15:18<00:00, 26.12s/it]    \n",
      "  0%|          | 0/346 [00:00<?, ?it/s]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.63 ms /   512 runs   (    0.14 ms per token,  7353.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17991.22 ms /  2418 tokens (    7.44 ms per token,   134.40 tokens per second)\n",
      "llama_print_timings:        eval time =   24818.51 ms /   511 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_print_timings:       total time =   43156.52 ms /  2929 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      72.84 ms /   512 runs   (    0.14 ms per token,  7029.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2245.77 ms /   348 tokens (    6.45 ms per token,   154.96 tokens per second)\n",
      "llama_print_timings:        eval time =   17933.79 ms /   511 runs   (   35.10 ms per token,    28.49 tokens per second)\n",
      "llama_print_timings:       total time =   20524.65 ms /   859 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.14 ms /   512 runs   (    0.16 ms per token,  6389.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15918.59 ms /  2195 tokens (    7.25 ms per token,   137.89 tokens per second)\n",
      "llama_print_timings:        eval time =   25392.12 ms /   511 runs   (   49.69 ms per token,    20.12 tokens per second)\n",
      "llama_print_timings:       total time =   41836.77 ms /  2706 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      72.07 ms /   512 runs   (    0.14 ms per token,  7104.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4540.56 ms /   565 tokens (    8.04 ms per token,   124.43 tokens per second)\n",
      "llama_print_timings:        eval time =   18641.44 ms /   511 runs   (   36.48 ms per token,    27.41 tokens per second)\n",
      "llama_print_timings:       total time =   23512.50 ms /  1076 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.65 ms /   512 runs   (    0.14 ms per token,  7246.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12108.39 ms /  1666 tokens (    7.27 ms per token,   137.59 tokens per second)\n",
      "llama_print_timings:        eval time =   23483.12 ms /   511 runs   (   45.96 ms per token,    21.76 tokens per second)\n",
      "llama_print_timings:       total time =   35939.40 ms /  2177 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.43 ms /   512 runs   (    0.14 ms per token,  7167.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2438.90 ms /   410 tokens (    5.95 ms per token,   168.11 tokens per second)\n",
      "llama_print_timings:        eval time =   18085.09 ms /   511 runs   (   35.39 ms per token,    28.26 tokens per second)\n",
      "llama_print_timings:       total time =   20848.48 ms /   921 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.64 ms /   512 runs   (    0.14 ms per token,  7248.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12226.10 ms /  1757 tokens (    6.96 ms per token,   143.71 tokens per second)\n",
      "llama_print_timings:        eval time =   22824.69 ms /   511 runs   (   44.67 ms per token,    22.39 tokens per second)\n",
      "llama_print_timings:       total time =   35393.61 ms /  2268 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.06 ms /   512 runs   (    0.14 ms per token,  7205.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4166.87 ms /   633 tokens (    6.58 ms per token,   151.91 tokens per second)\n",
      "llama_print_timings:        eval time =   18885.99 ms /   511 runs   (   36.96 ms per token,    27.06 tokens per second)\n",
      "llama_print_timings:       total time =   23378.83 ms /  1144 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.01 ms /   512 runs   (    0.14 ms per token,  7210.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9705.17 ms /  1409 tokens (    6.89 ms per token,   145.18 tokens per second)\n",
      "llama_print_timings:        eval time =   22495.73 ms /   511 runs   (   44.02 ms per token,    22.72 tokens per second)\n",
      "llama_print_timings:       total time =   32545.59 ms /  1920 tokens\n",
      "  0%|          | 1/346 [04:37<26:34:17, 277.27s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.77 ms /   512 runs   (    0.16 ms per token,  6338.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2970.04 ms /   478 tokens (    6.21 ms per token,   160.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19037.83 ms /   511 runs   (   37.26 ms per token,    26.84 tokens per second)\n",
      "llama_print_timings:       total time =   22506.05 ms /   989 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.61 ms /   512 runs   (    0.14 ms per token,  7250.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10043.19 ms /  1498 tokens (    6.70 ms per token,   149.16 tokens per second)\n",
      "llama_print_timings:        eval time =   22138.65 ms /   511 runs   (   43.32 ms per token,    23.08 tokens per second)\n",
      "llama_print_timings:       total time =   32523.07 ms /  2009 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.16 ms /   512 runs   (    0.14 ms per token,  7297.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10604.93 ms /  1498 tokens (    7.08 ms per token,   141.26 tokens per second)\n",
      "llama_print_timings:        eval time =   21773.55 ms /   511 runs   (   42.61 ms per token,    23.47 tokens per second)\n",
      "llama_print_timings:       total time =   32721.83 ms /  2009 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     109.03 ms /   512 runs   (    0.21 ms per token,  4695.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2160.99 ms /   328 tokens (    6.59 ms per token,   151.78 tokens per second)\n",
      "llama_print_timings:        eval time =   19009.55 ms /   511 runs   (   37.20 ms per token,    26.88 tokens per second)\n",
      "llama_print_timings:       total time =   21564.06 ms /   839 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.16 ms /   512 runs   (    0.14 ms per token,  7298.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9082.73 ms /  1349 tokens (    6.73 ms per token,   148.52 tokens per second)\n",
      "llama_print_timings:        eval time =   21256.90 ms /   511 runs   (   41.60 ms per token,    24.04 tokens per second)\n",
      "llama_print_timings:       total time =   30681.15 ms /  1860 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      77.05 ms /   512 runs   (    0.15 ms per token,  6645.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2998.92 ms /   422 tokens (    7.11 ms per token,   140.72 tokens per second)\n",
      "llama_print_timings:        eval time =   18499.24 ms /   511 runs   (   36.20 ms per token,    27.62 tokens per second)\n",
      "llama_print_timings:       total time =   21851.63 ms /   933 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      99.04 ms /   512 runs   (    0.19 ms per token,  5169.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2647.22 ms /   416 tokens (    6.36 ms per token,   157.15 tokens per second)\n",
      "llama_print_timings:        eval time =   18319.89 ms /   511 runs   (   35.85 ms per token,    27.89 tokens per second)\n",
      "llama_print_timings:       total time =   21341.76 ms /   927 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.29 ms /   512 runs   (    0.14 ms per token,  7388.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9164.51 ms /  1296 tokens (    7.07 ms per token,   141.42 tokens per second)\n",
      "llama_print_timings:        eval time =   22130.30 ms /   511 runs   (   43.31 ms per token,    23.09 tokens per second)\n",
      "llama_print_timings:       total time =   31635.63 ms /  1807 tokens\n",
      "  3%|▎         | 9/346 [08:12<4:24:03, 47.01s/it]  \n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      72.75 ms /   512 runs   (    0.14 ms per token,  7037.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1977.71 ms /   263 tokens (    7.52 ms per token,   132.98 tokens per second)\n",
      "llama_print_timings:        eval time =   17588.59 ms /   511 runs   (   34.42 ms per token,    29.05 tokens per second)\n",
      "llama_print_timings:       total time =   19909.94 ms /   774 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.02 ms /   512 runs   (    0.13 ms per token,  7418.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9406.73 ms /  1386 tokens (    6.79 ms per token,   147.34 tokens per second)\n",
      "llama_print_timings:        eval time =   21578.93 ms /   511 runs   (   42.23 ms per token,    23.68 tokens per second)\n",
      "llama_print_timings:       total time =   31326.08 ms /  1897 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.34 ms /   512 runs   (    0.14 ms per token,  7279.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4217.98 ms /   645 tokens (    6.54 ms per token,   152.92 tokens per second)\n",
      "llama_print_timings:        eval time =   18932.93 ms /   511 runs   (   37.05 ms per token,    26.99 tokens per second)\n",
      "llama_print_timings:       total time =   23475.72 ms /  1156 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.81 ms /   512 runs   (    0.14 ms per token,  7333.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17526.32 ms /  2311 tokens (    7.58 ms per token,   131.86 tokens per second)\n",
      "llama_print_timings:        eval time =   25528.25 ms /   511 runs   (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:       total time =   43411.35 ms /  2822 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.80 ms /   512 runs   (    0.16 ms per token,  6336.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3129.22 ms /   491 tokens (    6.37 ms per token,   156.91 tokens per second)\n",
      "llama_print_timings:        eval time =   19063.00 ms /   511 runs   (   37.31 ms per token,    26.81 tokens per second)\n",
      "llama_print_timings:       total time =   22690.13 ms /  1002 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.33 ms /   512 runs   (    0.14 ms per token,  7384.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17424.92 ms /  2402 tokens (    7.25 ms per token,   137.85 tokens per second)\n",
      "llama_print_timings:        eval time =   25197.53 ms /   511 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_print_timings:       total time =   42975.02 ms /  2913 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.55 ms /   512 runs   (    0.14 ms per token,  7361.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18743.05 ms /  2519 tokens (    7.44 ms per token,   134.40 tokens per second)\n",
      "llama_print_timings:        eval time =   25114.66 ms /   511 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_print_timings:       total time =   44208.64 ms /  3030 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     116.88 ms /   512 runs   (    0.23 ms per token,  4380.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1997.41 ms /   295 tokens (    6.77 ms per token,   147.69 tokens per second)\n",
      "llama_print_timings:        eval time =   18730.78 ms /   511 runs   (   36.66 ms per token,    27.28 tokens per second)\n",
      "llama_print_timings:       total time =   21119.21 ms /   806 tokens\n",
      "  5%|▍         | 17/346 [12:21<3:28:24, 38.01s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.89 ms /   512 runs   (    0.14 ms per token,  7222.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17573.24 ms /  2363 tokens (    7.44 ms per token,   134.47 tokens per second)\n",
      "llama_print_timings:        eval time =   24596.58 ms /   511 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_print_timings:       total time =   42526.71 ms /  2874 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      88.20 ms /   512 runs   (    0.17 ms per token,  5804.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2025.98 ms /   320 tokens (    6.33 ms per token,   157.95 tokens per second)\n",
      "llama_print_timings:        eval time =   18978.77 ms /   511 runs   (   37.14 ms per token,    26.92 tokens per second)\n",
      "llama_print_timings:       total time =   21544.42 ms /   831 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     122.62 ms /   512 runs   (    0.24 ms per token,  4175.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3586.89 ms /   555 tokens (    6.46 ms per token,   154.73 tokens per second)\n",
      "llama_print_timings:        eval time =   18765.69 ms /   511 runs   (   36.72 ms per token,    27.23 tokens per second)\n",
      "llama_print_timings:       total time =   22754.50 ms /  1066 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      95.40 ms /   512 runs   (    0.19 ms per token,  5366.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4059.55 ms /   572 tokens (    7.10 ms per token,   140.90 tokens per second)\n",
      "llama_print_timings:        eval time =   20207.28 ms /   511 runs   (   39.54 ms per token,    25.29 tokens per second)\n",
      "llama_print_timings:       total time =   24811.01 ms /  1083 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     130.06 ms /   512 runs   (    0.25 ms per token,  3936.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2683.79 ms /   398 tokens (    6.74 ms per token,   148.30 tokens per second)\n",
      "llama_print_timings:        eval time =   18757.70 ms /   511 runs   (   36.71 ms per token,    27.24 tokens per second)\n",
      "llama_print_timings:       total time =   22021.03 ms /   909 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      83.67 ms /   512 runs   (    0.16 ms per token,  6119.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4090.86 ms /   596 tokens (    6.86 ms per token,   145.69 tokens per second)\n",
      "llama_print_timings:        eval time =   19775.93 ms /   511 runs   (   38.70 ms per token,    25.84 tokens per second)\n",
      "llama_print_timings:       total time =   24408.87 ms /  1107 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.35 ms /   512 runs   (    0.14 ms per token,  7175.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7562.60 ms /  1085 tokens (    6.97 ms per token,   143.47 tokens per second)\n",
      "llama_print_timings:        eval time =   20387.74 ms /   511 runs   (   39.90 ms per token,    25.06 tokens per second)\n",
      "llama_print_timings:       total time =   28285.58 ms /  1596 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     127.40 ms /   512 runs   (    0.25 ms per token,  4018.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1539.20 ms /   220 tokens (    7.00 ms per token,   142.93 tokens per second)\n",
      "llama_print_timings:        eval time =   19410.63 ms /   511 runs   (   37.99 ms per token,    26.33 tokens per second)\n",
      "llama_print_timings:       total time =   21530.86 ms /   731 tokens\n",
      "  7%|▋         | 25/346 [15:49<2:54:33, 32.63s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      84.43 ms /   512 runs   (    0.16 ms per token,  6064.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6400.83 ms /   936 tokens (    6.84 ms per token,   146.23 tokens per second)\n",
      "llama_print_timings:        eval time =   20684.03 ms /   511 runs   (   40.48 ms per token,    24.71 tokens per second)\n",
      "llama_print_timings:       total time =   27612.21 ms /  1447 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      77.31 ms /   512 runs   (    0.15 ms per token,  6622.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1944.58 ms /   311 tokens (    6.25 ms per token,   159.93 tokens per second)\n",
      "llama_print_timings:        eval time =   18086.55 ms /   511 runs   (   35.39 ms per token,    28.25 tokens per second)\n",
      "llama_print_timings:       total time =   20387.22 ms /   822 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.24 ms /   512 runs   (    0.14 ms per token,  7289.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7703.42 ms /  1111 tokens (    6.93 ms per token,   144.22 tokens per second)\n",
      "llama_print_timings:        eval time =   20452.59 ms /   511 runs   (   40.02 ms per token,    24.98 tokens per second)\n",
      "llama_print_timings:       total time =   28489.17 ms /  1622 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     101.13 ms /   512 runs   (    0.20 ms per token,  5062.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2658.24 ms /   372 tokens (    7.15 ms per token,   139.94 tokens per second)\n",
      "llama_print_timings:        eval time =   19146.74 ms /   511 runs   (   37.47 ms per token,    26.69 tokens per second)\n",
      "llama_print_timings:       total time =   22189.21 ms /   883 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      78.45 ms /   512 runs   (    0.15 ms per token,  6526.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6541.71 ms /   957 tokens (    6.84 ms per token,   146.29 tokens per second)\n",
      "llama_print_timings:        eval time =   19954.15 ms /   511 runs   (   39.05 ms per token,    25.61 tokens per second)\n",
      "llama_print_timings:       total time =   26843.73 ms /  1468 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     117.48 ms /   512 runs   (    0.23 ms per token,  4358.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3054.11 ms /   465 tokens (    6.57 ms per token,   152.25 tokens per second)\n",
      "llama_print_timings:        eval time =   18757.90 ms /   511 runs   (   36.71 ms per token,    27.24 tokens per second)\n",
      "llama_print_timings:       total time =   22211.56 ms /   976 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      89.30 ms /   512 runs   (    0.17 ms per token,  5733.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4675.76 ms /   722 tokens (    6.48 ms per token,   154.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19257.62 ms /   511 runs   (   37.69 ms per token,    26.53 tokens per second)\n",
      "llama_print_timings:       total time =   24296.91 ms /  1233 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.34 ms /   512 runs   (    0.16 ms per token,  6373.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16076.24 ms /  2132 tokens (    7.54 ms per token,   132.62 tokens per second)\n",
      "llama_print_timings:        eval time =   25819.34 ms /   511 runs   (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_print_timings:       total time =   42426.39 ms /  2643 tokens\n",
      " 10%|▉         | 33/346 [19:23<2:38:23, 30.36s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      94.44 ms /   512 runs   (    0.18 ms per token,  5421.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3814.68 ms /   573 tokens (    6.66 ms per token,   150.21 tokens per second)\n",
      "llama_print_timings:        eval time =   18725.48 ms /   511 runs   (   36.64 ms per token,    27.29 tokens per second)\n",
      "llama_print_timings:       total time =   22914.10 ms /  1084 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.29 ms /   512 runs   (    0.16 ms per token,  6376.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16311.13 ms /  2221 tokens (    7.34 ms per token,   136.16 tokens per second)\n",
      "llama_print_timings:        eval time =   25530.31 ms /   511 runs   (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_print_timings:       total time =   42368.33 ms /  2732 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.70 ms /   512 runs   (    0.14 ms per token,  7141.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3949.32 ms /   565 tokens (    6.99 ms per token,   143.06 tokens per second)\n",
      "llama_print_timings:        eval time =   18564.94 ms /   511 runs   (   36.33 ms per token,    27.53 tokens per second)\n",
      "llama_print_timings:       total time =   22842.34 ms /  1076 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.93 ms /   512 runs   (    0.14 ms per token,  7321.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9900.47 ms /  1437 tokens (    6.89 ms per token,   145.14 tokens per second)\n",
      "llama_print_timings:        eval time =   22750.33 ms /   511 runs   (   44.52 ms per token,    22.46 tokens per second)\n",
      "llama_print_timings:       total time =   32993.93 ms /  1948 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.92 ms /   512 runs   (    0.14 ms per token,  7219.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2426.32 ms /   410 tokens (    5.92 ms per token,   168.98 tokens per second)\n",
      "llama_print_timings:        eval time =   18009.43 ms /   511 runs   (   35.24 ms per token,    28.37 tokens per second)\n",
      "llama_print_timings:       total time =   20760.61 ms /   921 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.08 ms /   512 runs   (    0.14 ms per token,  7305.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10270.25 ms /  1529 tokens (    6.72 ms per token,   148.88 tokens per second)\n",
      "llama_print_timings:        eval time =   22092.12 ms /   511 runs   (   43.23 ms per token,    23.13 tokens per second)\n",
      "llama_print_timings:       total time =   32701.80 ms /  2040 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.36 ms /   512 runs   (    0.16 ms per token,  6371.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11242.08 ms /  1566 tokens (    7.18 ms per token,   139.30 tokens per second)\n",
      "llama_print_timings:        eval time =   23120.61 ms /   511 runs   (   45.25 ms per token,    22.10 tokens per second)\n",
      "llama_print_timings:       total time =   34874.61 ms /  2077 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     112.89 ms /   512 runs   (    0.22 ms per token,  4535.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     628.50 ms /   100 tokens (    6.29 ms per token,   159.11 tokens per second)\n",
      "llama_print_timings:        eval time =   18233.86 ms /   511 runs   (   35.68 ms per token,    28.02 tokens per second)\n",
      "llama_print_timings:       total time =   19253.38 ms /   611 tokens\n",
      " 12%|█▏        | 41/346 [23:12<2:31:08, 29.73s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.80 ms /   512 runs   (    0.16 ms per token,  6336.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9860.58 ms /  1412 tokens (    6.98 ms per token,   143.20 tokens per second)\n",
      "llama_print_timings:        eval time =   22230.48 ms /   511 runs   (   43.50 ms per token,    22.99 tokens per second)\n",
      "llama_print_timings:       total time =   32606.69 ms /  1923 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.59 ms /   512 runs   (    0.16 ms per token,  6353.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10946.96 ms /  1563 tokens (    7.00 ms per token,   142.78 tokens per second)\n",
      "llama_print_timings:        eval time =   22934.58 ms /   511 runs   (   44.88 ms per token,    22.28 tokens per second)\n",
      "llama_print_timings:       total time =   34396.55 ms /  2074 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      72.83 ms /   512 runs   (    0.14 ms per token,  7030.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2035.12 ms /   261 tokens (    7.80 ms per token,   128.25 tokens per second)\n",
      "llama_print_timings:        eval time =   17716.10 ms /   511 runs   (   34.67 ms per token,    28.84 tokens per second)\n",
      "llama_print_timings:       total time =   20096.70 ms /   772 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     116.56 ms /   512 runs   (    0.23 ms per token,  4392.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3472.29 ms /   527 tokens (    6.59 ms per token,   151.77 tokens per second)\n",
      "llama_print_timings:        eval time =   18636.61 ms /   511 runs   (   36.47 ms per token,    27.42 tokens per second)\n",
      "llama_print_timings:       total time =   22509.27 ms /  1038 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.01 ms /   512 runs   (    0.14 ms per token,  7209.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10215.15 ms /  1412 tokens (    7.23 ms per token,   138.23 tokens per second)\n",
      "llama_print_timings:        eval time =   21616.17 ms /   511 runs   (   42.30 ms per token,    23.64 tokens per second)\n",
      "llama_print_timings:       total time =   32169.08 ms /  1923 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     100.11 ms /   512 runs   (    0.20 ms per token,  5114.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5171.30 ms /   735 tokens (    7.04 ms per token,   142.13 tokens per second)\n",
      "llama_print_timings:        eval time =   19302.12 ms /   511 runs   (   37.77 ms per token,    26.47 tokens per second)\n",
      "llama_print_timings:       total time =   24855.07 ms /  1246 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      75.62 ms /   512 runs   (    0.15 ms per token,  6770.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2851.60 ms /   367 tokens (    7.77 ms per token,   128.70 tokens per second)\n",
      "llama_print_timings:        eval time =   18061.02 ms /   511 runs   (   35.34 ms per token,    28.29 tokens per second)\n",
      "llama_print_timings:       total time =   21266.19 ms /   878 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     113.26 ms /   512 runs   (    0.22 ms per token,  4520.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3904.97 ms /   609 tokens (    6.41 ms per token,   155.96 tokens per second)\n",
      "llama_print_timings:        eval time =   19009.45 ms /   511 runs   (   37.20 ms per token,    26.88 tokens per second)\n",
      "llama_print_timings:       total time =   23307.47 ms /  1120 tokens\n",
      " 14%|█▍        | 49/346 [26:44<2:21:36, 28.61s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     114.35 ms /   512 runs   (    0.22 ms per token,  4477.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4213.22 ms /   583 tokens (    7.23 ms per token,   138.37 tokens per second)\n",
      "llama_print_timings:        eval time =   19584.25 ms /   511 runs   (   38.33 ms per token,    26.09 tokens per second)\n",
      "llama_print_timings:       total time =   24372.65 ms /  1094 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     125.35 ms /   512 runs   (    0.24 ms per token,  4084.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3150.94 ms /   490 tokens (    6.43 ms per token,   155.51 tokens per second)\n",
      "llama_print_timings:        eval time =   19384.79 ms /   511 runs   (   37.94 ms per token,    26.36 tokens per second)\n",
      "llama_print_timings:       total time =   23118.96 ms /  1001 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      76.84 ms /   512 runs   (    0.15 ms per token,  6663.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3102.43 ms /   453 tokens (    6.85 ms per token,   146.01 tokens per second)\n",
      "llama_print_timings:        eval time =   18373.90 ms /   511 runs   (   35.96 ms per token,    27.81 tokens per second)\n",
      "llama_print_timings:       total time =   21829.30 ms /   964 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.79 ms /   512 runs   (    0.14 ms per token,  7335.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12578.95 ms /  1777 tokens (    7.08 ms per token,   141.27 tokens per second)\n",
      "llama_print_timings:        eval time =   22658.31 ms /   511 runs   (   44.34 ms per token,    22.55 tokens per second)\n",
      "llama_print_timings:       total time =   35578.49 ms /  2288 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     114.80 ms /   512 runs   (    0.22 ms per token,  4459.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2321.69 ms /   332 tokens (    6.99 ms per token,   143.00 tokens per second)\n",
      "llama_print_timings:        eval time =   17968.79 ms /   511 runs   (   35.16 ms per token,    28.44 tokens per second)\n",
      "llama_print_timings:       total time =   20680.75 ms /   843 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.56 ms /   512 runs   (    0.14 ms per token,  7256.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6997.08 ms /  1021 tokens (    6.85 ms per token,   145.92 tokens per second)\n",
      "llama_print_timings:        eval time =   20134.62 ms /   511 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
      "llama_print_timings:       total time =   27461.38 ms /  1532 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.46 ms /   512 runs   (    0.16 ms per token,  6363.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11226.42 ms /  1620 tokens (    6.93 ms per token,   144.30 tokens per second)\n",
      "llama_print_timings:        eval time =   23109.09 ms /   511 runs   (   45.22 ms per token,    22.11 tokens per second)\n",
      "llama_print_timings:       total time =   34852.19 ms /  2131 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     108.98 ms /   512 runs   (    0.21 ms per token,  4697.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3295.36 ms /   509 tokens (    6.47 ms per token,   154.46 tokens per second)\n",
      "llama_print_timings:        eval time =   18606.24 ms /   511 runs   (   36.41 ms per token,    27.46 tokens per second)\n",
      "llama_print_timings:       total time =   22287.85 ms /  1020 tokens\n",
      " 16%|█▋        | 57/346 [30:14<2:14:08, 27.85s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      84.94 ms /   512 runs   (    0.17 ms per token,  6027.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5828.16 ms /   872 tokens (    6.68 ms per token,   149.62 tokens per second)\n",
      "llama_print_timings:        eval time =   19729.20 ms /   511 runs   (   38.61 ms per token,    25.90 tokens per second)\n",
      "llama_print_timings:       total time =   25918.03 ms /  1383 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      97.83 ms /   512 runs   (    0.19 ms per token,  5233.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5792.61 ms /   829 tokens (    6.99 ms per token,   143.11 tokens per second)\n",
      "llama_print_timings:        eval time =   20264.71 ms /   511 runs   (   39.66 ms per token,    25.22 tokens per second)\n",
      "llama_print_timings:       total time =   26608.38 ms /  1340 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      85.69 ms /   512 runs   (    0.17 ms per token,  5975.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2160.20 ms /   349 tokens (    6.19 ms per token,   161.56 tokens per second)\n",
      "llama_print_timings:        eval time =   18601.75 ms /   511 runs   (   36.40 ms per token,    27.47 tokens per second)\n",
      "llama_print_timings:       total time =   21303.63 ms /   860 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      78.22 ms /   512 runs   (    0.15 ms per token,  6546.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6674.43 ms /   955 tokens (    6.99 ms per token,   143.08 tokens per second)\n",
      "llama_print_timings:        eval time =   19962.32 ms /   511 runs   (   39.07 ms per token,    25.60 tokens per second)\n",
      "llama_print_timings:       total time =   26984.30 ms /  1466 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      87.15 ms /   512 runs   (    0.17 ms per token,  5874.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4520.81 ms /   671 tokens (    6.74 ms per token,   148.42 tokens per second)\n",
      "llama_print_timings:        eval time =   19879.80 ms /   511 runs   (   38.90 ms per token,    25.70 tokens per second)\n",
      "llama_print_timings:       total time =   24947.18 ms /  1182 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     109.19 ms /   512 runs   (    0.21 ms per token,  4689.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2663.67 ms /   418 tokens (    6.37 ms per token,   156.93 tokens per second)\n",
      "llama_print_timings:        eval time =   18209.31 ms /   511 runs   (   35.63 ms per token,    28.06 tokens per second)\n",
      "llama_print_timings:       total time =   21259.62 ms /   929 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      89.33 ms /   512 runs   (    0.17 ms per token,  5731.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5452.69 ms /   803 tokens (    6.79 ms per token,   147.27 tokens per second)\n",
      "llama_print_timings:        eval time =   19602.03 ms /   511 runs   (   38.36 ms per token,    26.07 tokens per second)\n",
      "llama_print_timings:       total time =   25419.29 ms /  1314 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.31 ms /   512 runs   (    0.14 ms per token,  7282.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7352.19 ms /  1029 tokens (    7.14 ms per token,   139.96 tokens per second)\n",
      "llama_print_timings:        eval time =   20279.74 ms /   511 runs   (   39.69 ms per token,    25.20 tokens per second)\n",
      "llama_print_timings:       total time =   27960.04 ms /  1540 tokens\n",
      " 19%|█▉        | 65/346 [33:34<2:06:17, 26.96s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      72.94 ms /   512 runs   (    0.14 ms per token,  7019.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1623.00 ms /   264 tokens (    6.15 ms per token,   162.66 tokens per second)\n",
      "llama_print_timings:        eval time =   17612.28 ms /   511 runs   (   34.47 ms per token,    29.01 tokens per second)\n",
      "llama_print_timings:       total time =   19579.45 ms /   775 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.98 ms /   512 runs   (    0.14 ms per token,  7213.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7224.90 ms /  1057 tokens (    6.84 ms per token,   146.30 tokens per second)\n",
      "llama_print_timings:        eval time =   20315.70 ms /   511 runs   (   39.76 ms per token,    25.15 tokens per second)\n",
      "llama_print_timings:       total time =   27877.69 ms /  1568 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      83.47 ms /   512 runs   (    0.16 ms per token,  6133.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6105.97 ms /   873 tokens (    6.99 ms per token,   142.97 tokens per second)\n",
      "llama_print_timings:        eval time =   20687.11 ms /   511 runs   (   40.48 ms per token,    24.70 tokens per second)\n",
      "llama_print_timings:       total time =   27328.28 ms /  1384 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.38 ms /   512 runs   (    0.16 ms per token,  6369.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13635.93 ms /  1899 tokens (    7.18 ms per token,   139.26 tokens per second)\n",
      "llama_print_timings:        eval time =   23861.11 ms /   511 runs   (   46.69 ms per token,    21.42 tokens per second)\n",
      "llama_print_timings:       total time =   38016.81 ms /  2410 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      82.05 ms /   512 runs   (    0.16 ms per token,  6239.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6276.28 ms /   908 tokens (    6.91 ms per token,   144.67 tokens per second)\n",
      "llama_print_timings:        eval time =   20635.40 ms /   511 runs   (   40.38 ms per token,    24.76 tokens per second)\n",
      "llama_print_timings:       total time =   27443.77 ms /  1419 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     115.16 ms /   512 runs   (    0.22 ms per token,  4445.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3640.16 ms /   565 tokens (    6.44 ms per token,   155.21 tokens per second)\n",
      "llama_print_timings:        eval time =   18740.21 ms /   511 runs   (   36.67 ms per token,    27.27 tokens per second)\n",
      "llama_print_timings:       total time =   22778.76 ms /  1076 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.16 ms /   512 runs   (    0.14 ms per token,  7195.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12495.32 ms /  1740 tokens (    7.18 ms per token,   139.25 tokens per second)\n",
      "llama_print_timings:        eval time =   22529.64 ms /   511 runs   (   44.09 ms per token,    22.68 tokens per second)\n",
      "llama_print_timings:       total time =   35367.75 ms /  2251 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     115.50 ms /   512 runs   (    0.23 ms per token,  4432.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4370.41 ms /   646 tokens (    6.77 ms per token,   147.81 tokens per second)\n",
      "llama_print_timings:        eval time =   19927.83 ms /   511 runs   (   39.00 ms per token,    25.64 tokens per second)\n",
      "llama_print_timings:       total time =   24870.14 ms /  1157 tokens\n",
      " 21%|██        | 73/346 [37:18<2:04:02, 27.26s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      74.42 ms /   512 runs   (    0.15 ms per token,  6879.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2703.83 ms /   410 tokens (    6.59 ms per token,   151.64 tokens per second)\n",
      "llama_print_timings:        eval time =   18159.22 ms /   511 runs   (   35.54 ms per token,    28.14 tokens per second)\n",
      "llama_print_timings:       total time =   21212.31 ms /   921 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      79.43 ms /   512 runs   (    0.16 ms per token,  6446.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16375.20 ms /  2247 tokens (    7.29 ms per token,   137.22 tokens per second)\n",
      "llama_print_timings:        eval time =   25665.38 ms /   511 runs   (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_print_timings:       total time =   42565.85 ms /  2758 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     118.28 ms /   512 runs   (    0.23 ms per token,  4328.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3176.53 ms /   493 tokens (    6.44 ms per token,   155.20 tokens per second)\n",
      "llama_print_timings:        eval time =   18517.39 ms /   511 runs   (   36.24 ms per token,    27.60 tokens per second)\n",
      "llama_print_timings:       total time =   22096.25 ms /  1004 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     118.86 ms /   512 runs   (    0.23 ms per token,  4307.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3454.72 ms /   532 tokens (    6.49 ms per token,   153.99 tokens per second)\n",
      "llama_print_timings:        eval time =   18628.40 ms /   511 runs   (   36.45 ms per token,    27.43 tokens per second)\n",
      "llama_print_timings:       total time =   22480.63 ms /  1043 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.10 ms /   512 runs   (    0.16 ms per token,  6392.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15149.88 ms /  2092 tokens (    7.24 ms per token,   138.09 tokens per second)\n",
      "llama_print_timings:        eval time =   24829.16 ms /   511 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_print_timings:       total time =   40505.82 ms /  2603 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      78.77 ms /   512 runs   (    0.15 ms per token,  6499.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6494.17 ms /   945 tokens (    6.87 ms per token,   145.52 tokens per second)\n",
      "llama_print_timings:        eval time =   19910.14 ms /   511 runs   (   38.96 ms per token,    25.67 tokens per second)\n",
      "llama_print_timings:       total time =   26753.39 ms /  1456 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     113.78 ms /   512 runs   (    0.22 ms per token,  4499.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2549.07 ms /   373 tokens (    6.83 ms per token,   146.33 tokens per second)\n",
      "llama_print_timings:        eval time =   18032.23 ms /   511 runs   (   35.29 ms per token,    28.34 tokens per second)\n",
      "llama_print_timings:       total time =   20965.80 ms /   884 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     107.42 ms /   512 runs   (    0.21 ms per token,  4766.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3451.55 ms /   509 tokens (    6.78 ms per token,   147.47 tokens per second)\n",
      "llama_print_timings:        eval time =   18597.13 ms /   511 runs   (   36.39 ms per token,    27.48 tokens per second)\n",
      "llama_print_timings:       total time =   22434.50 ms /  1020 tokens\n",
      " 23%|██▎       | 81/346 [40:57<2:00:34, 27.30s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      75.92 ms /   512 runs   (    0.15 ms per token,  6744.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5260.18 ms /   793 tokens (    6.63 ms per token,   150.76 tokens per second)\n",
      "llama_print_timings:        eval time =   19467.30 ms /   511 runs   (   38.10 ms per token,    26.25 tokens per second)\n",
      "llama_print_timings:       total time =   25081.55 ms /  1304 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.20 ms /   512 runs   (    0.14 ms per token,  7293.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10493.14 ms /  1504 tokens (    6.98 ms per token,   143.33 tokens per second)\n",
      "llama_print_timings:        eval time =   21789.23 ms /   511 runs   (   42.64 ms per token,    23.45 tokens per second)\n",
      "llama_print_timings:       total time =   32619.02 ms /  2015 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      75.66 ms /   512 runs   (    0.15 ms per token,  6767.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2452.60 ms /   356 tokens (    6.89 ms per token,   145.15 tokens per second)\n",
      "llama_print_timings:        eval time =   18018.94 ms /   511 runs   (   35.26 ms per token,    28.36 tokens per second)\n",
      "llama_print_timings:       total time =   20822.75 ms /   867 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.20 ms /   512 runs   (    0.14 ms per token,  7293.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12975.71 ms /  1862 tokens (    6.97 ms per token,   143.50 tokens per second)\n",
      "llama_print_timings:        eval time =   22986.59 ms /   511 runs   (   44.98 ms per token,    22.23 tokens per second)\n",
      "llama_print_timings:       total time =   36307.20 ms /  2373 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.19 ms /   512 runs   (    0.14 ms per token,  7294.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9299.73 ms /  1345 tokens (    6.91 ms per token,   144.63 tokens per second)\n",
      "llama_print_timings:        eval time =   21261.01 ms /   511 runs   (   41.61 ms per token,    24.03 tokens per second)\n",
      "llama_print_timings:       total time =   30897.85 ms /  1856 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.55 ms /   512 runs   (    0.16 ms per token,  6355.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8408.72 ms /  1237 tokens (    6.80 ms per token,   147.11 tokens per second)\n",
      "llama_print_timings:        eval time =   21751.07 ms /   511 runs   (   42.57 ms per token,    23.49 tokens per second)\n",
      "llama_print_timings:       total time =   30671.50 ms /  1748 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.09 ms /   512 runs   (    0.14 ms per token,  7305.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11813.30 ms /  1711 tokens (    6.90 ms per token,   144.84 tokens per second)\n",
      "llama_print_timings:        eval time =   22466.13 ms /   511 runs   (   43.97 ms per token,    22.75 tokens per second)\n",
      "llama_print_timings:       total time =   34622.04 ms /  2222 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     117.30 ms /   512 runs   (    0.23 ms per token,  4364.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2777.00 ms /   436 tokens (    6.37 ms per token,   157.00 tokens per second)\n",
      "llama_print_timings:        eval time =   18268.16 ms /   511 runs   (   35.75 ms per token,    27.97 tokens per second)\n",
      "llama_print_timings:       total time =   21438.83 ms /   947 tokens\n",
      " 26%|██▌       | 89/346 [44:49<1:59:15, 27.84s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.17 ms /   512 runs   (    0.14 ms per token,  7296.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7471.02 ms /  1080 tokens (    6.92 ms per token,   144.56 tokens per second)\n",
      "llama_print_timings:        eval time =   20347.03 ms /   511 runs   (   39.82 ms per token,    25.11 tokens per second)\n",
      "llama_print_timings:       total time =   28149.70 ms /  1591 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.42 ms /   512 runs   (    0.14 ms per token,  7270.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9246.47 ms /  1341 tokens (    6.90 ms per token,   145.03 tokens per second)\n",
      "llama_print_timings:        eval time =   21261.91 ms /   511 runs   (   41.61 ms per token,    24.03 tokens per second)\n",
      "llama_print_timings:       total time =   30844.11 ms /  1852 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      83.92 ms /   512 runs   (    0.16 ms per token,  6101.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2108.43 ms /   274 tokens (    7.69 ms per token,   129.95 tokens per second)\n",
      "llama_print_timings:        eval time =   18248.27 ms /   511 runs   (   35.71 ms per token,    28.00 tokens per second)\n",
      "llama_print_timings:       total time =   20895.47 ms /   785 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     122.92 ms /   512 runs   (    0.24 ms per token,  4165.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3820.05 ms /   565 tokens (    6.76 ms per token,   147.90 tokens per second)\n",
      "llama_print_timings:        eval time =   19422.23 ms /   511 runs   (   38.01 ms per token,    26.31 tokens per second)\n",
      "llama_print_timings:       total time =   23828.20 ms /  1076 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.98 ms /   512 runs   (    0.14 ms per token,  7316.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8191.78 ms /  1190 tokens (    6.88 ms per token,   145.27 tokens per second)\n",
      "llama_print_timings:        eval time =   20718.93 ms /   511 runs   (   40.55 ms per token,    24.66 tokens per second)\n",
      "llama_print_timings:       total time =   29243.15 ms /  1701 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.94 ms /   512 runs   (    0.14 ms per token,  7217.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7624.19 ms /  1105 tokens (    6.90 ms per token,   144.93 tokens per second)\n",
      "llama_print_timings:        eval time =   20465.37 ms /   511 runs   (   40.05 ms per token,    24.97 tokens per second)\n",
      "llama_print_timings:       total time =   28423.82 ms /  1616 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      86.33 ms /   512 runs   (    0.17 ms per token,  5930.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2662.95 ms /   417 tokens (    6.39 ms per token,   156.59 tokens per second)\n",
      "llama_print_timings:        eval time =   18874.42 ms /   511 runs   (   36.94 ms per token,    27.07 tokens per second)\n",
      "llama_print_timings:       total time =   22082.78 ms /   928 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.70 ms /   512 runs   (    0.14 ms per token,  7345.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14450.80 ms /  1985 tokens (    7.28 ms per token,   137.36 tokens per second)\n",
      "llama_print_timings:        eval time =   23458.24 ms /   511 runs   (   45.91 ms per token,    21.78 tokens per second)\n",
      "llama_print_timings:       total time =   38255.68 ms /  2496 tokens\n",
      " 28%|██▊       | 97/346 [48:31<1:55:24, 27.81s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      75.03 ms /   512 runs   (    0.15 ms per token,  6823.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6280.80 ms /   948 tokens (    6.63 ms per token,   150.94 tokens per second)\n",
      "llama_print_timings:        eval time =   20025.07 ms /   511 runs   (   39.19 ms per token,    25.52 tokens per second)\n",
      "llama_print_timings:       total time =   26655.20 ms /  1459 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.26 ms /   512 runs   (    0.16 ms per token,  6378.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6033.66 ms /   910 tokens (    6.63 ms per token,   150.82 tokens per second)\n",
      "llama_print_timings:        eval time =   19892.86 ms /   511 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
      "llama_print_timings:       total time =   26279.42 ms /  1421 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.01 ms /   512 runs   (    0.14 ms per token,  7313.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13234.49 ms /  1835 tokens (    7.21 ms per token,   138.65 tokens per second)\n",
      "llama_print_timings:        eval time =   23019.40 ms /   511 runs   (   45.05 ms per token,    22.20 tokens per second)\n",
      "llama_print_timings:       total time =   36599.17 ms /  2346 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     117.51 ms /   512 runs   (    0.23 ms per token,  4357.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2542.28 ms /   405 tokens (    6.28 ms per token,   159.31 tokens per second)\n",
      "llama_print_timings:        eval time =   18202.94 ms /   511 runs   (   35.62 ms per token,    28.07 tokens per second)\n",
      "llama_print_timings:       total time =   21142.67 ms /   916 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      74.61 ms /   512 runs   (    0.15 ms per token,  6861.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5419.65 ms /   761 tokens (    7.12 ms per token,   140.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19363.26 ms /   511 runs   (   37.89 ms per token,    26.39 tokens per second)\n",
      "llama_print_timings:       total time =   25139.28 ms /  1272 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.76 ms /   512 runs   (    0.14 ms per token,  7339.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10235.01 ms /  1449 tokens (    7.06 ms per token,   141.57 tokens per second)\n",
      "llama_print_timings:        eval time =   21635.21 ms /   511 runs   (   42.34 ms per token,    23.62 tokens per second)\n",
      "llama_print_timings:       total time =   32206.40 ms /  1960 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      83.91 ms /   512 runs   (    0.16 ms per token,  6101.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1560.91 ms /   251 tokens (    6.22 ms per token,   160.80 tokens per second)\n",
      "llama_print_timings:        eval time =   18140.34 ms /   511 runs   (   35.50 ms per token,    28.17 tokens per second)\n",
      "llama_print_timings:       total time =   20239.76 ms /   762 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      79.95 ms /   512 runs   (    0.16 ms per token,  6404.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7177.67 ms /  1035 tokens (    6.93 ms per token,   144.20 tokens per second)\n",
      "llama_print_timings:        eval time =   21188.56 ms /   511 runs   (   41.46 ms per token,    24.12 tokens per second)\n",
      "llama_print_timings:       total time =   28868.05 ms /  1546 tokens\n",
      " 30%|███       | 105/346 [52:08<1:50:53, 27.61s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.61 ms /   512 runs   (    0.16 ms per token,  6351.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8865.31 ms /  1287 tokens (    6.89 ms per token,   145.17 tokens per second)\n",
      "llama_print_timings:        eval time =   21962.44 ms /   511 runs   (   42.98 ms per token,    23.27 tokens per second)\n",
      "llama_print_timings:       total time =   31340.70 ms /  1798 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.86 ms /   512 runs   (    0.14 ms per token,  7328.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9282.97 ms /  1326 tokens (    7.00 ms per token,   142.84 tokens per second)\n",
      "llama_print_timings:        eval time =   21235.80 ms /   511 runs   (   41.56 ms per token,    24.06 tokens per second)\n",
      "llama_print_timings:       total time =   30853.24 ms /  1837 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.50 ms /   512 runs   (    0.14 ms per token,  7161.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5991.73 ms /   877 tokens (    6.83 ms per token,   146.37 tokens per second)\n",
      "llama_print_timings:        eval time =   19698.60 ms /   511 runs   (   38.55 ms per token,    25.94 tokens per second)\n",
      "llama_print_timings:       total time =   26040.10 ms /  1388 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     118.01 ms /   512 runs   (    0.23 ms per token,  4338.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3240.97 ms /   504 tokens (    6.43 ms per token,   155.51 tokens per second)\n",
      "llama_print_timings:        eval time =   18563.92 ms /   511 runs   (   36.33 ms per token,    27.53 tokens per second)\n",
      "llama_print_timings:       total time =   22202.56 ms /  1015 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.67 ms /   512 runs   (    0.14 ms per token,  7349.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7967.82 ms /  1169 tokens (    6.82 ms per token,   146.72 tokens per second)\n",
      "llama_print_timings:        eval time =   20636.76 ms /   511 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
      "llama_print_timings:       total time =   28936.01 ms /  1680 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     101.65 ms /   512 runs   (    0.20 ms per token,  5036.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4777.44 ms /   718 tokens (    6.65 ms per token,   150.29 tokens per second)\n",
      "llama_print_timings:        eval time =   19333.45 ms /   511 runs   (   37.83 ms per token,    26.43 tokens per second)\n",
      "llama_print_timings:       total time =   24492.43 ms /  1229 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      86.62 ms /   512 runs   (    0.17 ms per token,  5910.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2707.77 ms /   345 tokens (    7.85 ms per token,   127.41 tokens per second)\n",
      "llama_print_timings:        eval time =   18548.13 ms /   511 runs   (   36.30 ms per token,    27.55 tokens per second)\n",
      "llama_print_timings:       total time =   21799.32 ms /   856 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.05 ms /   512 runs   (    0.14 ms per token,  7206.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16637.77 ms /  2230 tokens (    7.46 ms per token,   134.03 tokens per second)\n",
      "llama_print_timings:        eval time =   24190.09 ms /   511 runs   (   47.34 ms per token,    21.12 tokens per second)\n",
      "llama_print_timings:       total time =   41187.13 ms /  2741 tokens\n",
      " 33%|███▎      | 113/346 [55:55<1:48:06, 27.84s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      86.59 ms /   512 runs   (    0.17 ms per token,  5912.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3733.46 ms /   567 tokens (    6.58 ms per token,   151.87 tokens per second)\n",
      "llama_print_timings:        eval time =   19529.99 ms /   511 runs   (   38.22 ms per token,    26.16 tokens per second)\n",
      "llama_print_timings:       total time =   23809.87 ms /  1078 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      94.02 ms /   512 runs   (    0.18 ms per token,  5445.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5384.55 ms /   744 tokens (    7.24 ms per token,   138.17 tokens per second)\n",
      "llama_print_timings:        eval time =   19350.69 ms /   511 runs   (   37.87 ms per token,    26.41 tokens per second)\n",
      "llama_print_timings:       total time =   25102.18 ms /  1255 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.50 ms /   512 runs   (    0.16 ms per token,  6360.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14892.58 ms /  2070 tokens (    7.19 ms per token,   139.00 tokens per second)\n",
      "llama_print_timings:        eval time =   24296.40 ms /   511 runs   (   47.55 ms per token,    21.03 tokens per second)\n",
      "llama_print_timings:       total time =   39717.67 ms /  2581 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     101.45 ms /   512 runs   (    0.20 ms per token,  5046.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2955.55 ms /   447 tokens (    6.61 ms per token,   151.24 tokens per second)\n",
      "llama_print_timings:        eval time =   18399.35 ms /   511 runs   (   36.01 ms per token,    27.77 tokens per second)\n",
      "llama_print_timings:       total time =   21737.05 ms /   958 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      73.55 ms /   512 runs   (    0.14 ms per token,  6961.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3784.17 ms /   586 tokens (    6.46 ms per token,   154.86 tokens per second)\n",
      "llama_print_timings:        eval time =   18866.17 ms /   511 runs   (   36.92 ms per token,    27.09 tokens per second)\n",
      "llama_print_timings:       total time =   23004.44 ms /  1097 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.41 ms /   512 runs   (    0.14 ms per token,  7169.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7563.97 ms /  1105 tokens (    6.85 ms per token,   146.09 tokens per second)\n",
      "llama_print_timings:        eval time =   20452.98 ms /   511 runs   (   40.03 ms per token,    24.98 tokens per second)\n",
      "llama_print_timings:       total time =   28355.08 ms /  1616 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      83.99 ms /   512 runs   (    0.16 ms per token,  6096.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1902.34 ms /   300 tokens (    6.34 ms per token,   157.70 tokens per second)\n",
      "llama_print_timings:        eval time =   18440.65 ms /   511 runs   (   36.09 ms per token,    27.71 tokens per second)\n",
      "llama_print_timings:       total time =   20883.86 ms /   811 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     114.61 ms /   512 runs   (    0.22 ms per token,  4467.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3367.09 ms /   512 tokens (    6.58 ms per token,   152.06 tokens per second)\n",
      "llama_print_timings:        eval time =   19356.56 ms /   512 runs   (   37.81 ms per token,    26.45 tokens per second)\n",
      "llama_print_timings:       total time =   23295.34 ms /  1024 tokens\n",
      " 35%|███▍      | 121/346 [59:21<1:42:02, 27.21s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      84.90 ms /   512 runs   (    0.17 ms per token,  6030.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6507.88 ms /   949 tokens (    6.86 ms per token,   145.82 tokens per second)\n",
      "llama_print_timings:        eval time =   20912.13 ms /   511 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
      "llama_print_timings:       total time =   27945.59 ms /  1460 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.83 ms /   512 runs   (    0.14 ms per token,  7332.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8945.72 ms /  1104 tokens (    8.10 ms per token,   123.41 tokens per second)\n",
      "llama_print_timings:        eval time =   20444.03 ms /   511 runs   (   40.01 ms per token,    25.00 tokens per second)\n",
      "llama_print_timings:       total time =   29720.67 ms /  1615 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      73.31 ms /   512 runs   (    0.14 ms per token,  6984.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2295.18 ms /   365 tokens (    6.29 ms per token,   159.03 tokens per second)\n",
      "llama_print_timings:        eval time =   17988.56 ms /   511 runs   (   35.20 ms per token,    28.41 tokens per second)\n",
      "llama_print_timings:       total time =   20634.78 ms /   876 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.04 ms /   512 runs   (    0.14 ms per token,  7309.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11179.01 ms /  1569 tokens (    7.12 ms per token,   140.35 tokens per second)\n",
      "llama_print_timings:        eval time =   21981.17 ms /   511 runs   (   43.02 ms per token,    23.25 tokens per second)\n",
      "llama_print_timings:       total time =   33498.97 ms /  2080 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.09 ms /   512 runs   (    0.14 ms per token,  7201.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6716.54 ms /   956 tokens (    7.03 ms per token,   142.34 tokens per second)\n",
      "llama_print_timings:        eval time =   19958.81 ms /   511 runs   (   39.06 ms per token,    25.60 tokens per second)\n",
      "llama_print_timings:       total time =   27014.50 ms /  1467 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.14 ms /   512 runs   (    0.14 ms per token,  7299.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11750.86 ms /  1626 tokens (    7.23 ms per token,   138.37 tokens per second)\n",
      "llama_print_timings:        eval time =   22166.35 ms /   511 runs   (   43.38 ms per token,    23.05 tokens per second)\n",
      "llama_print_timings:       total time =   34259.38 ms /  2137 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.28 ms /   512 runs   (    0.14 ms per token,  7285.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9801.56 ms /  1416 tokens (    6.92 ms per token,   144.47 tokens per second)\n",
      "llama_print_timings:        eval time =   21470.31 ms /   511 runs   (   42.02 ms per token,    23.80 tokens per second)\n",
      "llama_print_timings:       total time =   31609.05 ms /  1927 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.24 ms /   512 runs   (    0.14 ms per token,  7187.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8096.61 ms /  1155 tokens (    7.01 ms per token,   142.65 tokens per second)\n",
      "llama_print_timings:        eval time =   20639.90 ms /   511 runs   (   40.39 ms per token,    24.76 tokens per second)\n",
      "llama_print_timings:       total time =   29076.31 ms /  1666 tokens\n",
      " 37%|███▋      | 129/346 [1:03:15<1:40:36, 27.82s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.06 ms /   512 runs   (    0.14 ms per token,  7307.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10473.93 ms /  1464 tokens (    7.15 ms per token,   139.78 tokens per second)\n",
      "llama_print_timings:        eval time =   21731.26 ms /   511 runs   (   42.53 ms per token,    23.51 tokens per second)\n",
      "llama_print_timings:       total time =   32541.94 ms /  1975 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      88.10 ms /   512 runs   (    0.17 ms per token,  5811.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5585.77 ms /   818 tokens (    6.83 ms per token,   146.44 tokens per second)\n",
      "llama_print_timings:        eval time =   19580.44 ms /   511 runs   (   38.32 ms per token,    26.10 tokens per second)\n",
      "llama_print_timings:       total time =   25533.37 ms /  1329 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      83.08 ms /   512 runs   (    0.16 ms per token,  6162.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6908.72 ms /  1001 tokens (    6.90 ms per token,   144.89 tokens per second)\n",
      "llama_print_timings:        eval time =   20827.68 ms /   511 runs   (   40.76 ms per token,    24.53 tokens per second)\n",
      "llama_print_timings:       total time =   28250.80 ms /  1512 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      79.52 ms /   512 runs   (    0.16 ms per token,  6438.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9480.52 ms /  1372 tokens (    6.91 ms per token,   144.72 tokens per second)\n",
      "llama_print_timings:        eval time =   22478.47 ms /   511 runs   (   43.99 ms per token,    22.73 tokens per second)\n",
      "llama_print_timings:       total time =   32467.14 ms /  1883 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      84.47 ms /   512 runs   (    0.16 ms per token,  6061.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4719.15 ms /   661 tokens (    7.14 ms per token,   140.07 tokens per second)\n",
      "llama_print_timings:        eval time =   19850.25 ms /   511 runs   (   38.85 ms per token,    25.74 tokens per second)\n",
      "llama_print_timings:       total time =   25114.23 ms /  1172 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     100.25 ms /   512 runs   (    0.20 ms per token,  5107.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5599.80 ms /   838 tokens (    6.68 ms per token,   149.65 tokens per second)\n",
      "llama_print_timings:        eval time =   20274.80 ms /   511 runs   (   39.68 ms per token,    25.20 tokens per second)\n",
      "llama_print_timings:       total time =   26437.35 ms /  1349 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.06 ms /   512 runs   (    0.14 ms per token,  7205.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9322.47 ms /  1213 tokens (    7.69 ms per token,   130.12 tokens per second)\n",
      "llama_print_timings:        eval time =   20846.74 ms /   511 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
      "llama_print_timings:       total time =   30510.37 ms /  1724 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     103.25 ms /   512 runs   (    0.20 ms per token,  4958.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4083.21 ms /   615 tokens (    6.64 ms per token,   150.62 tokens per second)\n",
      "llama_print_timings:        eval time =   19038.95 ms /   511 runs   (   37.26 ms per token,    26.84 tokens per second)\n",
      "llama_print_timings:       total time =   23501.79 ms /  1126 tokens\n",
      " 40%|███▉      | 137/346 [1:07:00<1:37:08, 27.89s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      76.90 ms /   512 runs   (    0.15 ms per token,  6658.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4605.30 ms /   689 tokens (    6.68 ms per token,   149.61 tokens per second)\n",
      "llama_print_timings:        eval time =   19126.12 ms /   511 runs   (   37.43 ms per token,    26.72 tokens per second)\n",
      "llama_print_timings:       total time =   24086.70 ms /  1200 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     113.67 ms /   512 runs   (    0.22 ms per token,  4504.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3848.94 ms /   583 tokens (    6.60 ms per token,   151.47 tokens per second)\n",
      "llama_print_timings:        eval time =   18859.07 ms /   511 runs   (   36.91 ms per token,    27.10 tokens per second)\n",
      "llama_print_timings:       total time =   23106.17 ms /  1094 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     120.34 ms /   512 runs   (    0.24 ms per token,  4254.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3091.64 ms /   455 tokens (    6.79 ms per token,   147.17 tokens per second)\n",
      "llama_print_timings:        eval time =   19111.99 ms /   511 runs   (   37.40 ms per token,    26.74 tokens per second)\n",
      "llama_print_timings:       total time =   22784.55 ms /   966 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.58 ms /   512 runs   (    0.16 ms per token,  6354.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11819.69 ms /  1690 tokens (    6.99 ms per token,   142.98 tokens per second)\n",
      "llama_print_timings:        eval time =   23024.67 ms /   511 runs   (   45.06 ms per token,    22.19 tokens per second)\n",
      "llama_print_timings:       total time =   35365.50 ms /  2201 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     120.23 ms /   512 runs   (    0.23 ms per token,  4258.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2723.49 ms /   421 tokens (    6.47 ms per token,   154.58 tokens per second)\n",
      "llama_print_timings:        eval time =   18344.27 ms /   511 runs   (   35.90 ms per token,    27.86 tokens per second)\n",
      "llama_print_timings:       total time =   21466.16 ms /   932 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     105.07 ms /   512 runs   (    0.21 ms per token,  4872.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2867.06 ms /   443 tokens (    6.47 ms per token,   154.51 tokens per second)\n",
      "llama_print_timings:        eval time =   18400.69 ms /   511 runs   (   36.01 ms per token,    27.77 tokens per second)\n",
      "llama_print_timings:       total time =   21647.86 ms /   954 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.73 ms /   512 runs   (    0.16 ms per token,  6341.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10770.94 ms /  1544 tokens (    6.98 ms per token,   143.35 tokens per second)\n",
      "llama_print_timings:        eval time =   22547.89 ms /   511 runs   (   44.13 ms per token,    22.66 tokens per second)\n",
      "llama_print_timings:       total time =   33836.55 ms /  2055 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     109.54 ms /   512 runs   (    0.21 ms per token,  4674.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4318.64 ms /   646 tokens (    6.69 ms per token,   149.58 tokens per second)\n",
      "llama_print_timings:        eval time =   19094.21 ms /   511 runs   (   37.37 ms per token,    26.76 tokens per second)\n",
      "llama_print_timings:       total time =   23804.18 ms /  1157 tokens\n",
      " 42%|████▏     | 145/346 [1:10:26<1:31:18, 27.25s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      76.81 ms /   512 runs   (    0.15 ms per token,  6665.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1812.06 ms /   284 tokens (    6.38 ms per token,   156.73 tokens per second)\n",
      "llama_print_timings:        eval time =   17810.14 ms /   511 runs   (   34.85 ms per token,    28.69 tokens per second)\n",
      "llama_print_timings:       total time =   19975.88 ms /   795 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     113.73 ms /   512 runs   (    0.22 ms per token,  4502.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4515.25 ms /   687 tokens (    6.57 ms per token,   152.15 tokens per second)\n",
      "llama_print_timings:        eval time =   19917.14 ms /   511 runs   (   38.98 ms per token,    25.66 tokens per second)\n",
      "llama_print_timings:       total time =   25006.01 ms /  1198 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     122.45 ms /   512 runs   (    0.24 ms per token,  4181.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3252.67 ms /   486 tokens (    6.69 ms per token,   149.42 tokens per second)\n",
      "llama_print_timings:        eval time =   19375.67 ms /   511 runs   (   37.92 ms per token,    26.37 tokens per second)\n",
      "llama_print_timings:       total time =   23207.07 ms /   997 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.54 ms /   512 runs   (    0.14 ms per token,  7258.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10441.40 ms /  1520 tokens (    6.87 ms per token,   145.57 tokens per second)\n",
      "llama_print_timings:        eval time =   21963.19 ms /   511 runs   (   42.98 ms per token,    23.27 tokens per second)\n",
      "llama_print_timings:       total time =   32745.36 ms /  2031 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      89.05 ms /   512 runs   (    0.17 ms per token,  5749.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3571.02 ms /   546 tokens (    6.54 ms per token,   152.90 tokens per second)\n",
      "llama_print_timings:        eval time =   19334.29 ms /   511 runs   (   37.84 ms per token,    26.43 tokens per second)\n",
      "llama_print_timings:       total time =   23457.23 ms /  1057 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     101.37 ms /   512 runs   (    0.20 ms per token,  5051.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5082.39 ms /   762 tokens (    6.67 ms per token,   149.93 tokens per second)\n",
      "llama_print_timings:        eval time =   20150.98 ms /   511 runs   (   39.43 ms per token,    25.36 tokens per second)\n",
      "llama_print_timings:       total time =   25782.90 ms /  1273 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.31 ms /   512 runs   (    0.16 ms per token,  6374.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9397.93 ms /  1362 tokens (    6.90 ms per token,   144.93 tokens per second)\n",
      "llama_print_timings:        eval time =   22201.95 ms /   511 runs   (   43.45 ms per token,    23.02 tokens per second)\n",
      "llama_print_timings:       total time =   32110.68 ms /  1873 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     107.78 ms /   512 runs   (    0.21 ms per token,  4750.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2604.82 ms /   413 tokens (    6.31 ms per token,   158.55 tokens per second)\n",
      "llama_print_timings:        eval time =   18250.99 ms /   511 runs   (   35.72 ms per token,    28.00 tokens per second)\n",
      "llama_print_timings:       total time =   21240.85 ms /   924 tokens\n",
      " 44%|████▍     | 153/346 [1:13:49<1:25:55, 26.71s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      72.06 ms /   512 runs   (    0.14 ms per token,  7104.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4276.90 ms /   608 tokens (    7.03 ms per token,   142.16 tokens per second)\n",
      "llama_print_timings:        eval time =   19003.57 ms /   511 runs   (   37.19 ms per token,    26.89 tokens per second)\n",
      "llama_print_timings:       total time =   23636.77 ms /  1119 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.45 ms /   512 runs   (    0.14 ms per token,  7267.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7631.60 ms /  1104 tokens (    6.91 ms per token,   144.66 tokens per second)\n",
      "llama_print_timings:        eval time =   20529.73 ms /   511 runs   (   40.18 ms per token,    24.89 tokens per second)\n",
      "llama_print_timings:       total time =   28493.41 ms /  1615 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      72.79 ms /   512 runs   (    0.14 ms per token,  7033.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1520.45 ms /   249 tokens (    6.11 ms per token,   163.77 tokens per second)\n",
      "llama_print_timings:        eval time =   17521.58 ms /   511 runs   (   34.29 ms per token,    29.16 tokens per second)\n",
      "llama_print_timings:       total time =   19387.28 ms /   760 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.84 ms /   512 runs   (    0.16 ms per token,  6333.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9553.92 ms /  1371 tokens (    6.97 ms per token,   143.50 tokens per second)\n",
      "llama_print_timings:        eval time =   22230.55 ms /   511 runs   (   43.50 ms per token,    22.99 tokens per second)\n",
      "llama_print_timings:       total time =   32296.58 ms /  1882 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      74.93 ms /   512 runs   (    0.15 ms per token,  6833.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6510.26 ms /   944 tokens (    6.90 ms per token,   145.00 tokens per second)\n",
      "llama_print_timings:        eval time =   20043.99 ms /   511 runs   (   39.23 ms per token,    25.49 tokens per second)\n",
      "llama_print_timings:       total time =   26897.59 ms /  1455 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     115.12 ms /   512 runs   (    0.22 ms per token,  4447.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3757.42 ms /   565 tokens (    6.65 ms per token,   150.37 tokens per second)\n",
      "llama_print_timings:        eval time =   18765.50 ms /   511 runs   (   36.72 ms per token,    27.23 tokens per second)\n",
      "llama_print_timings:       total time =   22925.27 ms /  1076 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.17 ms /   512 runs   (    0.14 ms per token,  7296.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8305.82 ms /  1210 tokens (    6.86 ms per token,   145.68 tokens per second)\n",
      "llama_print_timings:        eval time =   20836.63 ms /   511 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
      "llama_print_timings:       total time =   29477.16 ms /  1721 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.17 ms /   512 runs   (    0.14 ms per token,  7296.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8913.63 ms /  1252 tokens (    7.12 ms per token,   140.46 tokens per second)\n",
      "llama_print_timings:        eval time =   20949.88 ms /   511 runs   (   41.00 ms per token,    24.39 tokens per second)\n",
      "llama_print_timings:       total time =   30196.09 ms /  1763 tokens\n",
      " 47%|████▋     | 161/346 [1:17:23<1:22:19, 26.70s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      73.53 ms /   512 runs   (    0.14 ms per token,  6963.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2594.10 ms /   410 tokens (    6.33 ms per token,   158.05 tokens per second)\n",
      "llama_print_timings:        eval time =   18266.28 ms /   511 runs   (   35.75 ms per token,    27.98 tokens per second)\n",
      "llama_print_timings:       total time =   21208.76 ms /   921 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.04 ms /   512 runs   (    0.14 ms per token,  7207.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9691.77 ms /  1283 tokens (    7.55 ms per token,   132.38 tokens per second)\n",
      "llama_print_timings:        eval time =   21073.86 ms /   511 runs   (   41.24 ms per token,    24.25 tokens per second)\n",
      "llama_print_timings:       total time =   31108.88 ms /  1794 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.33 ms /   512 runs   (    0.14 ms per token,  7177.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8748.28 ms /  1097 tokens (    7.97 ms per token,   125.40 tokens per second)\n",
      "llama_print_timings:        eval time =   20449.05 ms /   511 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
      "llama_print_timings:       total time =   29535.68 ms /  1608 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      92.78 ms /   512 runs   (    0.18 ms per token,  5518.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5426.07 ms /   793 tokens (    6.84 ms per token,   146.15 tokens per second)\n",
      "llama_print_timings:        eval time =   19446.71 ms /   511 runs   (   38.06 ms per token,    26.28 tokens per second)\n",
      "llama_print_timings:       total time =   25241.23 ms /  1304 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.71 ms /   512 runs   (    0.14 ms per token,  7344.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7827.59 ms /  1130 tokens (    6.93 ms per token,   144.36 tokens per second)\n",
      "llama_print_timings:        eval time =   20521.92 ms /   511 runs   (   40.16 ms per token,    24.90 tokens per second)\n",
      "llama_print_timings:       total time =   28683.63 ms /  1641 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.20 ms /   512 runs   (    0.16 ms per token,  6384.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10496.70 ms /  1520 tokens (    6.91 ms per token,   144.81 tokens per second)\n",
      "llama_print_timings:        eval time =   22768.22 ms /   511 runs   (   44.56 ms per token,    22.44 tokens per second)\n",
      "llama_print_timings:       total time =   33780.73 ms /  2031 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      75.75 ms /   512 runs   (    0.15 ms per token,  6758.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4206.24 ms /   635 tokens (    6.62 ms per token,   150.97 tokens per second)\n",
      "llama_print_timings:        eval time =   19084.74 ms /   511 runs   (   37.35 ms per token,    26.78 tokens per second)\n",
      "llama_print_timings:       total time =   23645.03 ms /  1146 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.91 ms /   512 runs   (    0.14 ms per token,  7220.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18135.85 ms /  2430 tokens (    7.46 ms per token,   133.99 tokens per second)\n",
      "llama_print_timings:        eval time =   24815.71 ms /   511 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_print_timings:       total time =   43303.42 ms /  2941 tokens\n",
      " 49%|████▉     | 169/346 [1:21:19<1:21:18, 27.56s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.14 ms /   512 runs   (    0.14 ms per token,  7299.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9532.27 ms /  1363 tokens (    6.99 ms per token,   142.99 tokens per second)\n",
      "llama_print_timings:        eval time =   21422.64 ms /   511 runs   (   41.92 ms per token,    23.85 tokens per second)\n",
      "llama_print_timings:       total time =   31297.42 ms /  1874 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      82.28 ms /   512 runs   (    0.16 ms per token,  6222.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5926.41 ms /   882 tokens (    6.72 ms per token,   148.83 tokens per second)\n",
      "llama_print_timings:        eval time =   19856.35 ms /   511 runs   (   38.86 ms per token,    25.73 tokens per second)\n",
      "llama_print_timings:       total time =   26145.31 ms /  1393 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.57 ms /   512 runs   (    0.14 ms per token,  7255.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17808.72 ms /  2279 tokens (    7.81 ms per token,   127.97 tokens per second)\n",
      "llama_print_timings:        eval time =   24305.76 ms /   511 runs   (   47.57 ms per token,    21.02 tokens per second)\n",
      "llama_print_timings:       total time =   42468.15 ms /  2790 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.28 ms /   512 runs   (    0.14 ms per token,  7284.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10153.96 ms /  1453 tokens (    6.99 ms per token,   143.10 tokens per second)\n",
      "llama_print_timings:        eval time =   21633.79 ms /   511 runs   (   42.34 ms per token,    23.62 tokens per second)\n",
      "llama_print_timings:       total time =   32124.84 ms /  1964 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      76.43 ms /   512 runs   (    0.15 ms per token,  6698.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4942.08 ms /   728 tokens (    6.79 ms per token,   147.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19282.93 ms /   511 runs   (   37.74 ms per token,    26.50 tokens per second)\n",
      "llama_print_timings:       total time =   24586.30 ms /  1239 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     116.56 ms /   512 runs   (    0.23 ms per token,  4392.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2582.89 ms /   411 tokens (    6.28 ms per token,   159.12 tokens per second)\n",
      "llama_print_timings:        eval time =   18818.93 ms /   511 runs   (   36.83 ms per token,    27.15 tokens per second)\n",
      "llama_print_timings:       total time =   21975.48 ms /   922 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.36 ms /   512 runs   (    0.14 ms per token,  7276.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11074.34 ms /  1296 tokens (    8.55 ms per token,   117.03 tokens per second)\n",
      "llama_print_timings:        eval time =   21112.83 ms /   511 runs   (   41.32 ms per token,    24.20 tokens per second)\n",
      "llama_print_timings:       total time =   32521.03 ms /  1807 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      85.53 ms /   512 runs   (    0.17 ms per token,  5986.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5998.04 ms /   856 tokens (    7.01 ms per token,   142.71 tokens per second)\n",
      "llama_print_timings:        eval time =   19645.81 ms /   511 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
      "llama_print_timings:       total time =   25997.94 ms /  1367 tokens\n",
      " 51%|█████     | 177/346 [1:25:17<1:19:24, 28.19s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      74.09 ms /   512 runs   (    0.14 ms per token,  6910.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1549.12 ms /   254 tokens (    6.10 ms per token,   163.96 tokens per second)\n",
      "llama_print_timings:        eval time =   17533.05 ms /   511 runs   (   34.31 ms per token,    29.14 tokens per second)\n",
      "llama_print_timings:       total time =   19431.78 ms /   765 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.10 ms /   512 runs   (    0.14 ms per token,  7304.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9165.48 ms /  1326 tokens (    6.91 ms per token,   144.67 tokens per second)\n",
      "llama_print_timings:        eval time =   21142.81 ms /   511 runs   (   41.38 ms per token,    24.17 tokens per second)\n",
      "llama_print_timings:       total time =   30641.90 ms /  1837 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      75.73 ms /   512 runs   (    0.15 ms per token,  6760.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4816.34 ms /   694 tokens (    6.94 ms per token,   144.09 tokens per second)\n",
      "llama_print_timings:        eval time =   19144.90 ms /   511 runs   (   37.47 ms per token,    26.69 tokens per second)\n",
      "llama_print_timings:       total time =   24313.97 ms /  1205 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.88 ms /   512 runs   (    0.14 ms per token,  7326.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11045.92 ms /  1528 tokens (    7.23 ms per token,   138.33 tokens per second)\n",
      "llama_print_timings:        eval time =   21843.94 ms /   511 runs   (   42.75 ms per token,    23.39 tokens per second)\n",
      "llama_print_timings:       total time =   33228.02 ms /  2039 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.11 ms /   512 runs   (    0.14 ms per token,  7302.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7953.31 ms /  1170 tokens (    6.80 ms per token,   147.11 tokens per second)\n",
      "llama_print_timings:        eval time =   20715.44 ms /   511 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
      "llama_print_timings:       total time =   29000.81 ms /  1681 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.25 ms /   512 runs   (    0.16 ms per token,  6380.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12234.51 ms /  1727 tokens (    7.08 ms per token,   141.16 tokens per second)\n",
      "llama_print_timings:        eval time =   23526.86 ms /   511 runs   (   46.04 ms per token,    21.72 tokens per second)\n",
      "llama_print_timings:       total time =   36281.67 ms /  2238 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     123.78 ms /   512 runs   (    0.24 ms per token,  4136.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3507.86 ms /   247 tokens (   14.20 ms per token,    70.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19499.86 ms /   511 runs   (   38.16 ms per token,    26.21 tokens per second)\n",
      "llama_print_timings:       total time =   23593.63 ms /   758 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.48 ms /   512 runs   (    0.14 ms per token,  7369.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9536.27 ms /  1371 tokens (    6.96 ms per token,   143.77 tokens per second)\n",
      "llama_print_timings:        eval time =   21333.56 ms /   511 runs   (   41.75 ms per token,    23.95 tokens per second)\n",
      "llama_print_timings:       total time =   31208.47 ms /  1882 tokens\n",
      " 53%|█████▎    | 185/346 [1:29:04<1:15:52, 28.28s/it]Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.42 ms /   512 runs   (    0.16 ms per token,  6366.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10526.56 ms /  1508 tokens (    6.98 ms per token,   143.26 tokens per second)\n",
      "llama_print_timings:        eval time =   22963.01 ms /   511 runs   (   44.94 ms per token,    22.25 tokens per second)\n",
      "llama_print_timings:       total time =   34007.98 ms /  2019 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.54 ms /   512 runs   (    0.16 ms per token,  6356.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9254.97 ms /  1335 tokens (    6.93 ms per token,   144.25 tokens per second)\n",
      "llama_print_timings:        eval time =   21852.03 ms /   511 runs   (   42.76 ms per token,    23.38 tokens per second)\n",
      "llama_print_timings:       total time =   31620.83 ms /  1846 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      86.14 ms /   512 runs   (    0.17 ms per token,  5944.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2602.45 ms /   415 tokens (    6.27 ms per token,   159.46 tokens per second)\n",
      "llama_print_timings:        eval time =   18834.51 ms /   511 runs   (   36.86 ms per token,    27.13 tokens per second)\n",
      "llama_print_timings:       total time =   21981.78 ms /   926 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.75 ms /   512 runs   (    0.14 ms per token,  7237.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9375.61 ms /  1348 tokens (    6.96 ms per token,   143.78 tokens per second)\n",
      "llama_print_timings:        eval time =   21263.57 ms /   511 runs   (   41.61 ms per token,    24.03 tokens per second)\n",
      "llama_print_timings:       total time =   30980.58 ms /  1859 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.14 ms /   512 runs   (    0.14 ms per token,  7299.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8000.55 ms /  1177 tokens (    6.80 ms per token,   147.11 tokens per second)\n",
      "llama_print_timings:        eval time =   20651.34 ms /   511 runs   (   40.41 ms per token,    24.74 tokens per second)\n",
      "llama_print_timings:       total time =   28985.86 ms /  1688 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.73 ms /   512 runs   (    0.14 ms per token,  7238.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11919.22 ms /  1666 tokens (    7.15 ms per token,   139.77 tokens per second)\n",
      "llama_print_timings:        eval time =   22292.79 ms /   511 runs   (   43.63 ms per token,    22.92 tokens per second)\n",
      "llama_print_timings:       total time =   34554.00 ms /  2177 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.54 ms /   512 runs   (    0.16 ms per token,  6356.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8232.40 ms /  1190 tokens (    6.92 ms per token,   144.55 tokens per second)\n",
      "llama_print_timings:        eval time =   21577.06 ms /   511 runs   (   42.23 ms per token,    23.68 tokens per second)\n",
      "llama_print_timings:       total time =   30321.07 ms /  1701 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     118.58 ms /   512 runs   (    0.23 ms per token,  4317.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2987.50 ms /   459 tokens (    6.51 ms per token,   153.64 tokens per second)\n",
      "llama_print_timings:        eval time =   18398.65 ms /   511 runs   (   36.01 ms per token,    27.77 tokens per second)\n",
      "llama_print_timings:       total time =   21783.62 ms /   970 tokens\n",
      " 56%|█████▌    | 193/346 [1:32:59<1:12:52, 28.58s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      79.58 ms /   512 runs   (    0.16 ms per token,  6433.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11073.73 ms /  1517 tokens (    7.30 ms per token,   136.99 tokens per second)\n",
      "llama_print_timings:        eval time =   23005.47 ms /   511 runs   (   45.02 ms per token,    22.21 tokens per second)\n",
      "llama_print_timings:       total time =   34590.26 ms /  2028 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.16 ms /   512 runs   (    0.14 ms per token,  7195.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14986.33 ms /  2070 tokens (    7.24 ms per token,   138.13 tokens per second)\n",
      "llama_print_timings:        eval time =   23636.66 ms /   511 runs   (   46.26 ms per token,    21.62 tokens per second)\n",
      "llama_print_timings:       total time =   38974.29 ms /  2581 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      73.13 ms /   512 runs   (    0.14 ms per token,  7001.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1938.91 ms /   307 tokens (    6.32 ms per token,   158.34 tokens per second)\n",
      "llama_print_timings:        eval time =   17832.05 ms /   511 runs   (   34.90 ms per token,    28.66 tokens per second)\n",
      "llama_print_timings:       total time =   20120.00 ms /   818 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.97 ms /   512 runs   (    0.14 ms per token,  7317.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16560.12 ms /  2265 tokens (    7.31 ms per token,   136.77 tokens per second)\n",
      "llama_print_timings:        eval time =   24273.45 ms /   511 runs   (   47.50 ms per token,    21.05 tokens per second)\n",
      "llama_print_timings:       total time =   41185.08 ms /  2776 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.09 ms /   512 runs   (    0.14 ms per token,  7202.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13443.70 ms /  1909 tokens (    7.04 ms per token,   142.00 tokens per second)\n",
      "llama_print_timings:        eval time =   23126.97 ms /   511 runs   (   45.26 ms per token,    22.10 tokens per second)\n",
      "llama_print_timings:       total time =   36919.64 ms /  2420 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.88 ms /   512 runs   (    0.14 ms per token,  7326.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =   18594.60 ms /  2500 tokens (    7.44 ms per token,   134.45 tokens per second)\n",
      "llama_print_timings:        eval time =   25060.19 ms /   511 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_print_timings:       total time =   44002.11 ms /  3011 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.08 ms /   512 runs   (    0.16 ms per token,  6393.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15871.55 ms /  2119 tokens (    7.49 ms per token,   133.51 tokens per second)\n",
      "llama_print_timings:        eval time =   24876.36 ms /   511 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_print_timings:       total time =   41272.95 ms /  2630 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      84.44 ms /   512 runs   (    0.16 ms per token,  6063.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5786.83 ms /   882 tokens (    6.56 ms per token,   152.41 tokens per second)\n",
      "llama_print_timings:        eval time =   19709.18 ms /   511 runs   (   38.57 ms per token,    25.93 tokens per second)\n",
      "llama_print_timings:       total time =   25852.82 ms /  1393 tokens\n",
      " 58%|█████▊    | 201/346 [1:37:42<1:14:00, 30.62s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.71 ms /   512 runs   (    0.14 ms per token,  7344.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17136.60 ms /  2346 tokens (    7.30 ms per token,   136.90 tokens per second)\n",
      "llama_print_timings:        eval time =   24541.01 ms /   511 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_print_timings:       total time =   42029.40 ms /  2857 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      99.96 ms /   512 runs   (    0.20 ms per token,  5121.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4576.11 ms /   689 tokens (    6.64 ms per token,   150.56 tokens per second)\n",
      "llama_print_timings:        eval time =   19139.53 ms /   511 runs   (   37.46 ms per token,    26.70 tokens per second)\n",
      "llama_print_timings:       total time =   24095.27 ms /  1200 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      76.17 ms /   512 runs   (    0.15 ms per token,  6722.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5009.08 ms /   725 tokens (    6.91 ms per token,   144.74 tokens per second)\n",
      "llama_print_timings:        eval time =   19256.35 ms /   511 runs   (   37.68 ms per token,    26.54 tokens per second)\n",
      "llama_print_timings:       total time =   24620.52 ms /  1236 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.05 ms /   512 runs   (    0.16 ms per token,  6396.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17756.06 ms /  2252 tokens (    7.88 ms per token,   126.83 tokens per second)\n",
      "llama_print_timings:        eval time =   25340.09 ms /   511 runs   (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_print_timings:       total time =   43624.01 ms /  2763 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      89.19 ms /   512 runs   (    0.17 ms per token,  5740.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3625.87 ms /   545 tokens (    6.65 ms per token,   150.31 tokens per second)\n",
      "llama_print_timings:        eval time =   19381.71 ms /   511 runs   (   37.93 ms per token,    26.37 tokens per second)\n",
      "llama_print_timings:       total time =   23557.23 ms /  1056 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      73.79 ms /   512 runs   (    0.14 ms per token,  6938.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4536.74 ms /   668 tokens (    6.79 ms per token,   147.24 tokens per second)\n",
      "llama_print_timings:        eval time =   19219.40 ms /   511 runs   (   37.61 ms per token,    26.59 tokens per second)\n",
      "llama_print_timings:       total time =   24097.76 ms /  1179 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.91 ms /   512 runs   (    0.14 ms per token,  7323.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15093.29 ms /  2101 tokens (    7.18 ms per token,   139.20 tokens per second)\n",
      "llama_print_timings:        eval time =   23680.94 ms /   511 runs   (   46.34 ms per token,    21.58 tokens per second)\n",
      "llama_print_timings:       total time =   39122.14 ms /  2612 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.45 ms /   512 runs   (    0.16 ms per token,  6364.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9292.06 ms /  1361 tokens (    6.83 ms per token,   146.47 tokens per second)\n",
      "llama_print_timings:        eval time =   22225.94 ms /   511 runs   (   43.49 ms per token,    22.99 tokens per second)\n",
      "llama_print_timings:       total time =   32028.54 ms /  1872 tokens\n",
      " 60%|██████    | 209/346 [1:41:55<1:10:37, 30.93s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      84.23 ms /   512 runs   (    0.16 ms per token,  6078.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3380.21 ms /   512 tokens (    6.60 ms per token,   151.47 tokens per second)\n",
      "llama_print_timings:        eval time =   19241.33 ms /   511 runs   (   37.65 ms per token,    26.56 tokens per second)\n",
      "llama_print_timings:       total time =   23168.36 ms /  1023 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      79.76 ms /   512 runs   (    0.16 ms per token,  6419.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9598.52 ms /  1387 tokens (    6.92 ms per token,   144.50 tokens per second)\n",
      "llama_print_timings:        eval time =   22517.63 ms /   511 runs   (   44.07 ms per token,    22.69 tokens per second)\n",
      "llama_print_timings:       total time =   32628.41 ms /  1898 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.71 ms /   512 runs   (    0.16 ms per token,  6343.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8341.21 ms /  1213 tokens (    6.88 ms per token,   145.42 tokens per second)\n",
      "llama_print_timings:        eval time =   21695.71 ms /   511 runs   (   42.46 ms per token,    23.55 tokens per second)\n",
      "llama_print_timings:       total time =   30549.56 ms /  1724 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.00 ms /   512 runs   (    0.14 ms per token,  7314.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7917.83 ms /  1160 tokens (    6.83 ms per token,   146.50 tokens per second)\n",
      "llama_print_timings:        eval time =   20983.91 ms /   511 runs   (   41.06 ms per token,    24.35 tokens per second)\n",
      "llama_print_timings:       total time =   29233.77 ms /  1671 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.60 ms /   512 runs   (    0.16 ms per token,  6352.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4844.33 ms /   746 tokens (    6.49 ms per token,   153.99 tokens per second)\n",
      "llama_print_timings:        eval time =   19993.66 ms /   511 runs   (   39.13 ms per token,    25.56 tokens per second)\n",
      "llama_print_timings:       total time =   25339.45 ms /  1257 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.43 ms /   512 runs   (    0.16 ms per token,  6365.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1707.43 ms /   247 tokens (    6.91 ms per token,   144.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19485.58 ms /   511 runs   (   38.13 ms per token,    26.22 tokens per second)\n",
      "llama_print_timings:       total time =   21690.57 ms /   758 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.66 ms /   512 runs   (    0.14 ms per token,  7246.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4633.99 ms /   595 tokens (    7.79 ms per token,   128.40 tokens per second)\n",
      "llama_print_timings:        eval time =   18732.06 ms /   511 runs   (   36.66 ms per token,    27.28 tokens per second)\n",
      "llama_print_timings:       total time =   23688.74 ms /  1106 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      84.14 ms /   512 runs   (    0.16 ms per token,  6085.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2692.03 ms /   343 tokens (    7.85 ms per token,   127.41 tokens per second)\n",
      "llama_print_timings:        eval time =   18687.21 ms /   511 runs   (   36.57 ms per token,    27.34 tokens per second)\n",
      "llama_print_timings:       total time =   21898.27 ms /   854 tokens\n",
      " 63%|██████▎   | 217/346 [1:45:23<1:03:20, 29.46s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      88.29 ms /   512 runs   (    0.17 ms per token,  5798.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2959.84 ms /   433 tokens (    6.84 ms per token,   146.29 tokens per second)\n",
      "llama_print_timings:        eval time =   18768.50 ms /   511 runs   (   36.73 ms per token,    27.23 tokens per second)\n",
      "llama_print_timings:       total time =   22248.50 ms /   944 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.54 ms /   512 runs   (    0.16 ms per token,  6357.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2932.17 ms /   452 tokens (    6.49 ms per token,   154.15 tokens per second)\n",
      "llama_print_timings:        eval time =   19969.00 ms /   511 runs   (   39.08 ms per token,    25.59 tokens per second)\n",
      "llama_print_timings:       total time =   23406.05 ms /   963 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      81.51 ms /   512 runs   (    0.16 ms per token,  6281.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1783.14 ms /   281 tokens (    6.35 ms per token,   157.59 tokens per second)\n",
      "llama_print_timings:        eval time =   18350.25 ms /   511 runs   (   35.91 ms per token,    27.85 tokens per second)\n",
      "llama_print_timings:       total time =   20629.56 ms /   792 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.56 ms /   512 runs   (    0.14 ms per token,  7256.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3415.77 ms /   546 tokens (    6.26 ms per token,   159.85 tokens per second)\n",
      "llama_print_timings:        eval time =   18760.16 ms /   511 runs   (   36.71 ms per token,    27.24 tokens per second)\n",
      "llama_print_timings:       total time =   22499.81 ms /  1057 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.30 ms /   512 runs   (    0.14 ms per token,  7180.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5170.94 ms /   787 tokens (    6.57 ms per token,   152.20 tokens per second)\n",
      "llama_print_timings:        eval time =   19370.67 ms /   511 runs   (   37.91 ms per token,    26.38 tokens per second)\n",
      "llama_print_timings:       total time =   24871.72 ms /  1298 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      72.63 ms /   512 runs   (    0.14 ms per token,  7049.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.09 ms /   184 tokens (    6.39 ms per token,   156.45 tokens per second)\n",
      "llama_print_timings:        eval time =   18415.44 ms /   511 runs   (   36.04 ms per token,    27.75 tokens per second)\n",
      "llama_print_timings:       total time =   19919.00 ms /   695 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.59 ms /   512 runs   (    0.14 ms per token,  7252.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4087.30 ms /   636 tokens (    6.43 ms per token,   155.60 tokens per second)\n",
      "llama_print_timings:        eval time =   18875.41 ms /   511 runs   (   36.94 ms per token,    27.07 tokens per second)\n",
      "llama_print_timings:       total time =   23288.69 ms /  1147 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      85.10 ms /   512 runs   (    0.17 ms per token,  6016.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1678.04 ms /   274 tokens (    6.12 ms per token,   163.29 tokens per second)\n",
      "llama_print_timings:        eval time =   17861.49 ms /   511 runs   (   34.95 ms per token,    28.61 tokens per second)\n",
      "llama_print_timings:       total time =   19896.10 ms /   785 tokens\n",
      " 65%|██████▌   | 225/346 [1:48:20<54:58, 27.26s/it]  \n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.36 ms /   512 runs   (    0.16 ms per token,  6371.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13370.91 ms /  1862 tokens (    7.18 ms per token,   139.26 tokens per second)\n",
      "llama_print_timings:        eval time =   23984.21 ms /   511 runs   (   46.94 ms per token,    21.31 tokens per second)\n",
      "llama_print_timings:       total time =   37878.42 ms /  2373 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.38 ms /   512 runs   (    0.14 ms per token,  7275.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6329.44 ms /   908 tokens (    6.97 ms per token,   143.46 tokens per second)\n",
      "llama_print_timings:        eval time =   20818.23 ms /   511 runs   (   40.74 ms per token,    24.55 tokens per second)\n",
      "llama_print_timings:       total time =   27481.75 ms /  1419 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.97 ms /   512 runs   (    0.14 ms per token,  7317.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12145.91 ms /  1720 tokens (    7.06 ms per token,   141.61 tokens per second)\n",
      "llama_print_timings:        eval time =   22517.80 ms /   511 runs   (   44.07 ms per token,    22.69 tokens per second)\n",
      "llama_print_timings:       total time =   35007.84 ms /  2231 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.23 ms /   512 runs   (    0.14 ms per token,  7187.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6870.18 ms /  1002 tokens (    6.86 ms per token,   145.85 tokens per second)\n",
      "llama_print_timings:        eval time =   20372.80 ms /   511 runs   (   39.87 ms per token,    25.08 tokens per second)\n",
      "llama_print_timings:       total time =   27577.82 ms /  1513 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      72.42 ms /   512 runs   (    0.14 ms per token,  7069.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4190.97 ms /   565 tokens (    7.42 ms per token,   134.81 tokens per second)\n",
      "llama_print_timings:        eval time =   18585.63 ms /   511 runs   (   36.37 ms per token,    27.49 tokens per second)\n",
      "llama_print_timings:       total time =   23106.11 ms /  1076 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      82.52 ms /   512 runs   (    0.16 ms per token,  6204.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     807.91 ms /   129 tokens (    6.26 ms per token,   159.67 tokens per second)\n",
      "llama_print_timings:        eval time =   18191.02 ms /   511 runs   (   35.60 ms per token,    28.09 tokens per second)\n",
      "llama_print_timings:       total time =   19347.25 ms /   640 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      84.51 ms /   512 runs   (    0.17 ms per token,  6058.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2738.07 ms /   415 tokens (    6.60 ms per token,   151.57 tokens per second)\n",
      "llama_print_timings:        eval time =   18694.65 ms /   511 runs   (   36.58 ms per token,    27.33 tokens per second)\n",
      "llama_print_timings:       total time =   21967.11 ms /   926 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      83.22 ms /   512 runs   (    0.16 ms per token,  6152.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.56 ms /   226 tokens (    6.18 ms per token,   161.83 tokens per second)\n",
      "llama_print_timings:        eval time =   18396.17 ms /   511 runs   (   36.00 ms per token,    27.78 tokens per second)\n",
      "llama_print_timings:       total time =   20329.60 ms /   737 tokens\n",
      " 67%|██████▋   | 233/346 [1:51:53<50:57, 27.06s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      77.15 ms /   512 runs   (    0.15 ms per token,  6636.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3269.25 ms /   507 tokens (    6.45 ms per token,   155.08 tokens per second)\n",
      "llama_print_timings:        eval time =   18406.27 ms /   511 runs   (   36.02 ms per token,    27.76 tokens per second)\n",
      "llama_print_timings:       total time =   22016.52 ms /  1018 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.59 ms /   512 runs   (    0.16 ms per token,  6353.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2820.46 ms /   408 tokens (    6.91 ms per token,   144.66 tokens per second)\n",
      "llama_print_timings:        eval time =   19795.93 ms /   511 runs   (   38.74 ms per token,    25.81 tokens per second)\n",
      "llama_print_timings:       total time =   23118.94 ms /   919 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      81.15 ms /   512 runs   (    0.16 ms per token,  6309.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2100.18 ms /   355 tokens (    5.92 ms per token,   169.03 tokens per second)\n",
      "llama_print_timings:        eval time =   18439.87 ms /   511 runs   (   36.09 ms per token,    27.71 tokens per second)\n",
      "llama_print_timings:       total time =   21037.94 ms /   866 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.87 ms /   512 runs   (    0.14 ms per token,  7224.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3085.78 ms /   502 tokens (    6.15 ms per token,   162.68 tokens per second)\n",
      "llama_print_timings:        eval time =   18602.50 ms /   511 runs   (   36.40 ms per token,    27.47 tokens per second)\n",
      "llama_print_timings:       total time =   22014.95 ms /  1013 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.92 ms /   512 runs   (    0.14 ms per token,  7219.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12504.46 ms /  1660 tokens (    7.53 ms per token,   132.75 tokens per second)\n",
      "llama_print_timings:        eval time =   22346.27 ms /   511 runs   (   43.73 ms per token,    22.87 tokens per second)\n",
      "llama_print_timings:       total time =   35200.35 ms /  2171 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.77 ms /   512 runs   (    0.14 ms per token,  7234.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15165.57 ms /  1953 tokens (    7.77 ms per token,   128.78 tokens per second)\n",
      "llama_print_timings:        eval time =   24274.82 ms /   511 runs   (   47.50 ms per token,    21.05 tokens per second)\n",
      "llama_print_timings:       total time =   39790.48 ms /  2464 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.30 ms /   512 runs   (    0.16 ms per token,  6375.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10630.94 ms /  1510 tokens (    7.04 ms per token,   142.04 tokens per second)\n",
      "llama_print_timings:        eval time =   22741.58 ms /   511 runs   (   44.50 ms per token,    22.47 tokens per second)\n",
      "llama_print_timings:       total time =   33885.24 ms /  2021 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      79.48 ms /   512 runs   (    0.16 ms per token,  6441.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15207.73 ms /  2048 tokens (    7.43 ms per token,   134.67 tokens per second)\n",
      "llama_print_timings:        eval time =   25259.30 ms /   512 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_print_timings:       total time =   40984.85 ms /  2560 tokens\n",
      " 70%|██████▉   | 241/346 [1:55:51<48:46, 27.87s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.36 ms /   512 runs   (    0.16 ms per token,  6371.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10140.53 ms /  1452 tokens (    6.98 ms per token,   143.19 tokens per second)\n",
      "llama_print_timings:        eval time =   22253.01 ms /   511 runs   (   43.55 ms per token,    22.96 tokens per second)\n",
      "llama_print_timings:       total time =   32909.63 ms /  1963 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      99.96 ms /   512 runs   (    0.20 ms per token,  5121.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3501.06 ms /   502 tokens (    6.97 ms per token,   143.39 tokens per second)\n",
      "llama_print_timings:        eval time =   20324.44 ms /   511 runs   (   39.77 ms per token,    25.14 tokens per second)\n",
      "llama_print_timings:       total time =   24382.04 ms /  1013 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.15 ms /   512 runs   (    0.14 ms per token,  7298.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8940.58 ms /  1306 tokens (    6.85 ms per token,   146.08 tokens per second)\n",
      "llama_print_timings:        eval time =   21150.07 ms /   511 runs   (   41.39 ms per token,    24.16 tokens per second)\n",
      "llama_print_timings:       total time =   30424.09 ms /  1817 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      87.42 ms /   512 runs   (    0.17 ms per token,  5856.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3897.77 ms /   596 tokens (    6.54 ms per token,   152.91 tokens per second)\n",
      "llama_print_timings:        eval time =   20014.22 ms /   511 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
      "llama_print_timings:       total time =   24457.09 ms /  1107 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.94 ms /   512 runs   (    0.14 ms per token,  7217.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15474.75 ms /  2119 tokens (    7.30 ms per token,   136.93 tokens per second)\n",
      "llama_print_timings:        eval time =   23838.43 ms /   511 runs   (   46.65 ms per token,    21.44 tokens per second)\n",
      "llama_print_timings:       total time =   39664.48 ms /  2630 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     116.27 ms /   512 runs   (    0.23 ms per token,  4403.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1593.66 ms /   247 tokens (    6.45 ms per token,   154.99 tokens per second)\n",
      "llama_print_timings:        eval time =   18741.93 ms /   511 runs   (   36.68 ms per token,    27.27 tokens per second)\n",
      "llama_print_timings:       total time =   20734.76 ms /   758 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.78 ms /   512 runs   (    0.14 ms per token,  7337.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14315.98 ms /  1979 tokens (    7.23 ms per token,   138.24 tokens per second)\n",
      "llama_print_timings:        eval time =   23338.61 ms /   511 runs   (   45.67 ms per token,    21.90 tokens per second)\n",
      "llama_print_timings:       total time =   37998.39 ms /  2490 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      74.40 ms /   512 runs   (    0.15 ms per token,  6881.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2321.09 ms /   337 tokens (    6.89 ms per token,   145.19 tokens per second)\n",
      "llama_print_timings:        eval time =   18347.02 ms /   511 runs   (   35.90 ms per token,    27.85 tokens per second)\n",
      "llama_print_timings:       total time =   21018.57 ms /   848 tokens\n",
      " 72%|███████▏  | 249/346 [1:59:43<45:35, 28.20s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      79.75 ms /   512 runs   (    0.16 ms per token,  6420.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14318.92 ms /  1995 tokens (    7.18 ms per token,   139.33 tokens per second)\n",
      "llama_print_timings:        eval time =   24688.30 ms /   511 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_print_timings:       total time =   39526.98 ms /  2506 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     119.38 ms /   512 runs   (    0.23 ms per token,  4289.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1569.58 ms /   245 tokens (    6.41 ms per token,   156.09 tokens per second)\n",
      "llama_print_timings:        eval time =   18769.99 ms /   511 runs   (   36.73 ms per token,    27.22 tokens per second)\n",
      "llama_print_timings:       total time =   20736.16 ms /   756 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.20 ms /   512 runs   (    0.16 ms per token,  6383.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13032.36 ms /  1846 tokens (    7.06 ms per token,   141.65 tokens per second)\n",
      "llama_print_timings:        eval time =   24262.89 ms /   511 runs   (   47.48 ms per token,    21.06 tokens per second)\n",
      "llama_print_timings:       total time =   37814.82 ms /  2357 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      83.74 ms /   512 runs   (    0.16 ms per token,  6113.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2077.01 ms /   333 tokens (    6.24 ms per token,   160.33 tokens per second)\n",
      "llama_print_timings:        eval time =   19021.36 ms /   511 runs   (   37.22 ms per token,    26.86 tokens per second)\n",
      "llama_print_timings:       total time =   21637.58 ms /   844 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.63 ms /   512 runs   (    0.14 ms per token,  7248.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16329.31 ms /  2265 tokens (    7.21 ms per token,   138.71 tokens per second)\n",
      "llama_print_timings:        eval time =   24300.76 ms /   511 runs   (   47.56 ms per token,    21.03 tokens per second)\n",
      "llama_print_timings:       total time =   40986.56 ms /  2776 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     115.58 ms /   512 runs   (    0.23 ms per token,  4429.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1912.33 ms /   275 tokens (    6.95 ms per token,   143.80 tokens per second)\n",
      "llama_print_timings:        eval time =   18872.51 ms /   511 runs   (   36.93 ms per token,    27.08 tokens per second)\n",
      "llama_print_timings:       total time =   21184.32 ms /   786 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.89 ms /   512 runs   (    0.14 ms per token,  7325.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   16388.24 ms /  2115 tokens (    7.75 ms per token,   129.06 tokens per second)\n",
      "llama_print_timings:        eval time =   23787.60 ms /   511 runs   (   46.55 ms per token,    21.48 tokens per second)\n",
      "llama_print_timings:       total time =   40522.91 ms /  2626 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      72.74 ms /   512 runs   (    0.14 ms per token,  7038.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2284.49 ms /   363 tokens (    6.29 ms per token,   158.90 tokens per second)\n",
      "llama_print_timings:        eval time =   18255.92 ms /   511 runs   (   35.73 ms per token,    27.99 tokens per second)\n",
      "llama_print_timings:       total time =   20888.45 ms /   874 tokens\n",
      " 74%|███████▍  | 257/346 [2:03:46<42:49, 28.87s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.67 ms /   512 runs   (    0.14 ms per token,  7348.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =   17137.71 ms /  2264 tokens (    7.57 ms per token,   132.11 tokens per second)\n",
      "llama_print_timings:        eval time =   24272.07 ms /   511 runs   (   47.50 ms per token,    21.05 tokens per second)\n",
      "llama_print_timings:       total time =   41765.53 ms /  2775 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.89 ms /   512 runs   (    0.14 ms per token,  7325.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    8184.10 ms /  1048 tokens (    7.81 ms per token,   128.05 tokens per second)\n",
      "llama_print_timings:        eval time =   21304.65 ms /   511 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =   29826.93 ms /  1559 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.59 ms /   512 runs   (    0.14 ms per token,  7357.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15321.15 ms /  2122 tokens (    7.22 ms per token,   138.50 tokens per second)\n",
      "llama_print_timings:        eval time =   23776.80 ms /   511 runs   (   46.53 ms per token,    21.49 tokens per second)\n",
      "llama_print_timings:       total time =   39452.88 ms /  2633 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.76 ms /   512 runs   (    0.16 ms per token,  6339.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7743.66 ms /  1140 tokens (    6.79 ms per token,   147.22 tokens per second)\n",
      "llama_print_timings:        eval time =   21676.33 ms /   511 runs   (   42.42 ms per token,    23.57 tokens per second)\n",
      "llama_print_timings:       total time =   29928.60 ms /  1651 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.22 ms /   512 runs   (    0.14 ms per token,  7291.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6581.44 ms /  1011 tokens (    6.51 ms per token,   153.61 tokens per second)\n",
      "llama_print_timings:        eval time =   20131.97 ms /   511 runs   (   39.40 ms per token,    25.38 tokens per second)\n",
      "llama_print_timings:       total time =   27042.74 ms /  1522 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.72 ms /   512 runs   (    0.14 ms per token,  7240.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2843.02 ms /   460 tokens (    6.18 ms per token,   161.80 tokens per second)\n",
      "llama_print_timings:        eval time =   19110.91 ms /   511 runs   (   37.40 ms per token,    26.74 tokens per second)\n",
      "llama_print_timings:       total time =   22279.98 ms /   971 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.78 ms /   512 runs   (    0.14 ms per token,  7234.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5468.89 ms /   856 tokens (    6.39 ms per token,   156.52 tokens per second)\n",
      "llama_print_timings:        eval time =   19609.85 ms /   511 runs   (   38.38 ms per token,    26.06 tokens per second)\n",
      "llama_print_timings:       total time =   25408.47 ms /  1367 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.99 ms /   512 runs   (    0.14 ms per token,  7212.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2934.62 ms /   483 tokens (    6.08 ms per token,   164.59 tokens per second)\n",
      "llama_print_timings:        eval time =   18554.77 ms /   511 runs   (   36.31 ms per token,    27.54 tokens per second)\n",
      "llama_print_timings:       total time =   21812.78 ms /   994 tokens\n",
      " 77%|███████▋  | 265/346 [2:07:44<39:18, 29.12s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.97 ms /   512 runs   (    0.14 ms per token,  7214.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4750.46 ms /   719 tokens (    6.61 ms per token,   151.35 tokens per second)\n",
      "llama_print_timings:        eval time =   19155.07 ms /   511 runs   (   37.49 ms per token,    26.68 tokens per second)\n",
      "llama_print_timings:       total time =   24232.69 ms /  1230 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.28 ms /   512 runs   (    0.14 ms per token,  7285.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6896.40 ms /  1017 tokens (    6.78 ms per token,   147.47 tokens per second)\n",
      "llama_print_timings:        eval time =   20998.30 ms /   511 runs   (   41.09 ms per token,    24.34 tokens per second)\n",
      "llama_print_timings:       total time =   28233.31 ms /  1528 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.04 ms /   512 runs   (    0.14 ms per token,  7207.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3584.89 ms /   556 tokens (    6.45 ms per token,   155.10 tokens per second)\n",
      "llama_print_timings:        eval time =   18571.26 ms /   511 runs   (   36.34 ms per token,    27.52 tokens per second)\n",
      "llama_print_timings:       total time =   22483.00 ms /  1067 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.06 ms /   512 runs   (    0.14 ms per token,  7205.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6922.93 ms /  1038 tokens (    6.67 ms per token,   149.94 tokens per second)\n",
      "llama_print_timings:        eval time =   20497.58 ms /   511 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
      "llama_print_timings:       total time =   27757.83 ms /  1549 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.71 ms /   512 runs   (    0.14 ms per token,  7241.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4740.11 ms /   714 tokens (    6.64 ms per token,   150.63 tokens per second)\n",
      "llama_print_timings:        eval time =   19250.07 ms /   511 runs   (   37.67 ms per token,    26.55 tokens per second)\n",
      "llama_print_timings:       total time =   24320.39 ms /  1225 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.51 ms /   512 runs   (    0.14 ms per token,  7261.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3784.39 ms /   507 tokens (    7.46 ms per token,   133.97 tokens per second)\n",
      "llama_print_timings:        eval time =   19228.77 ms /   511 runs   (   37.63 ms per token,    26.57 tokens per second)\n",
      "llama_print_timings:       total time =   23336.94 ms /  1018 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.26 ms /   512 runs   (    0.14 ms per token,  7184.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3640.30 ms /   552 tokens (    6.59 ms per token,   151.64 tokens per second)\n",
      "llama_print_timings:        eval time =   18581.45 ms /   511 runs   (   36.36 ms per token,    27.50 tokens per second)\n",
      "llama_print_timings:       total time =   22544.72 ms /  1063 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.39 ms /   512 runs   (    0.14 ms per token,  7273.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3232.55 ms /   526 tokens (    6.15 ms per token,   162.72 tokens per second)\n",
      "llama_print_timings:        eval time =   18842.76 ms /   511 runs   (   36.87 ms per token,    27.12 tokens per second)\n",
      "llama_print_timings:       total time =   22399.12 ms /  1037 tokens\n",
      " 79%|███████▉  | 273/346 [2:10:59<33:42, 27.71s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.39 ms /   512 runs   (    0.14 ms per token,  7273.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6759.48 ms /  1021 tokens (    6.62 ms per token,   151.05 tokens per second)\n",
      "llama_print_timings:        eval time =   20118.24 ms /   511 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
      "llama_print_timings:       total time =   27210.09 ms /  1532 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.72 ms /   512 runs   (    0.14 ms per token,  7240.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2223.93 ms /   355 tokens (    6.26 ms per token,   159.63 tokens per second)\n",
      "llama_print_timings:        eval time =   18982.39 ms /   511 runs   (   37.15 ms per token,    26.92 tokens per second)\n",
      "llama_print_timings:       total time =   21531.88 ms /   866 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.73 ms /   512 runs   (    0.14 ms per token,  7238.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5571.57 ms /   865 tokens (    6.44 ms per token,   155.25 tokens per second)\n",
      "llama_print_timings:        eval time =   19607.58 ms /   511 runs   (   38.37 ms per token,    26.06 tokens per second)\n",
      "llama_print_timings:       total time =   25506.55 ms /  1376 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.28 ms /   512 runs   (    0.14 ms per token,  7285.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2763.93 ms /   453 tokens (    6.10 ms per token,   163.90 tokens per second)\n",
      "llama_print_timings:        eval time =   18576.10 ms /   511 runs   (   36.35 ms per token,    27.51 tokens per second)\n",
      "llama_print_timings:       total time =   21660.87 ms /   964 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.72 ms /   512 runs   (    0.14 ms per token,  7240.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3073.76 ms /   469 tokens (    6.55 ms per token,   152.58 tokens per second)\n",
      "llama_print_timings:        eval time =   18284.63 ms /   511 runs   (   35.78 ms per token,    27.95 tokens per second)\n",
      "llama_print_timings:       total time =   21680.46 ms /   980 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.83 ms /   512 runs   (    0.14 ms per token,  7331.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11938.35 ms /  1690 tokens (    7.06 ms per token,   141.56 tokens per second)\n",
      "llama_print_timings:        eval time =   23454.53 ms /   511 runs   (   45.90 ms per token,    21.79 tokens per second)\n",
      "llama_print_timings:       total time =   35741.65 ms /  2201 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.23 ms /   512 runs   (    0.14 ms per token,  7188.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2011.88 ms /   307 tokens (    6.55 ms per token,   152.59 tokens per second)\n",
      "llama_print_timings:        eval time =   17665.12 ms /   511 runs   (   34.57 ms per token,    28.93 tokens per second)\n",
      "llama_print_timings:       total time =   19999.80 ms /   818 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.96 ms /   512 runs   (    0.14 ms per token,  7318.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12375.38 ms /  1789 tokens (    6.92 ms per token,   144.56 tokens per second)\n",
      "llama_print_timings:        eval time =   22916.03 ms /   511 runs   (   44.85 ms per token,    22.30 tokens per second)\n",
      "llama_print_timings:       total time =   35635.52 ms /  2300 tokens\n",
      " 81%|████████  | 281/346 [2:14:28<29:30, 27.24s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.66 ms /   512 runs   (    0.14 ms per token,  7245.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5869.16 ms /   904 tokens (    6.49 ms per token,   154.03 tokens per second)\n",
      "llama_print_timings:        eval time =   19800.01 ms /   511 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
      "llama_print_timings:       total time =   26004.86 ms /  1415 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.74 ms /   512 runs   (    0.14 ms per token,  7237.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1337.07 ms /   220 tokens (    6.08 ms per token,   164.54 tokens per second)\n",
      "llama_print_timings:        eval time =   18532.58 ms /   511 runs   (   36.27 ms per token,    27.57 tokens per second)\n",
      "llama_print_timings:       total time =   20195.71 ms /   731 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.55 ms /   512 runs   (    0.14 ms per token,  7156.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5376.16 ms /   746 tokens (    7.21 ms per token,   138.76 tokens per second)\n",
      "llama_print_timings:        eval time =   19261.45 ms /   511 runs   (   37.69 ms per token,    26.53 tokens per second)\n",
      "llama_print_timings:       total time =   24967.82 ms /  1257 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      76.44 ms /   512 runs   (    0.15 ms per token,  6698.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1902.88 ms /   305 tokens (    6.24 ms per token,   160.28 tokens per second)\n",
      "llama_print_timings:        eval time =   17951.11 ms /   511 runs   (   35.13 ms per token,    28.47 tokens per second)\n",
      "llama_print_timings:       total time =   20200.55 ms /   816 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.89 ms /   512 runs   (    0.16 ms per token,  6329.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3631.70 ms /   565 tokens (    6.43 ms per token,   155.57 tokens per second)\n",
      "llama_print_timings:        eval time =   19369.85 ms /   511 runs   (   37.91 ms per token,    26.38 tokens per second)\n",
      "llama_print_timings:       total time =   23501.92 ms /  1076 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      76.83 ms /   512 runs   (    0.15 ms per token,  6663.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1195.21 ms /   131 tokens (    9.12 ms per token,   109.60 tokens per second)\n",
      "llama_print_timings:        eval time =   18205.20 ms /   511 runs   (   35.63 ms per token,    28.07 tokens per second)\n",
      "llama_print_timings:       total time =   19738.63 ms /   642 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      73.38 ms /   512 runs   (    0.14 ms per token,  6977.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2554.12 ms /   402 tokens (    6.35 ms per token,   157.39 tokens per second)\n",
      "llama_print_timings:        eval time =   18024.04 ms /   511 runs   (   35.27 ms per token,    28.35 tokens per second)\n",
      "llama_print_timings:       total time =   20915.83 ms /   913 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      72.05 ms /   512 runs   (    0.14 ms per token,  7105.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1324.70 ms /   218 tokens (    6.08 ms per token,   164.57 tokens per second)\n",
      "llama_print_timings:        eval time =   17634.41 ms /   511 runs   (   34.51 ms per token,    28.98 tokens per second)\n",
      "llama_print_timings:       total time =   19301.82 ms /   729 tokens\n",
      " 84%|████████▎ | 289/346 [2:17:23<24:20, 25.62s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.17 ms /   512 runs   (    0.14 ms per token,  7296.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6688.02 ms /  1021 tokens (    6.55 ms per token,   152.66 tokens per second)\n",
      "llama_print_timings:        eval time =   20161.39 ms /   511 runs   (   39.45 ms per token,    25.35 tokens per second)\n",
      "llama_print_timings:       total time =   27181.09 ms /  1532 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      74.33 ms /   512 runs   (    0.15 ms per token,  6887.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     959.86 ms /   152 tokens (    6.31 ms per token,   158.36 tokens per second)\n",
      "llama_print_timings:        eval time =   18312.84 ms /   511 runs   (   35.84 ms per token,    27.90 tokens per second)\n",
      "llama_print_timings:       total time =   19605.00 ms /   663 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.66 ms /   512 runs   (    0.14 ms per token,  7245.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5654.24 ms /   861 tokens (    6.57 ms per token,   152.28 tokens per second)\n",
      "llama_print_timings:        eval time =   19633.67 ms /   511 runs   (   38.42 ms per token,    26.03 tokens per second)\n",
      "llama_print_timings:       total time =   25616.72 ms /  1372 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      82.37 ms /   512 runs   (    0.16 ms per token,  6215.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2209.31 ms /   236 tokens (    9.36 ms per token,   106.82 tokens per second)\n",
      "llama_print_timings:        eval time =   18523.31 ms /   511 runs   (   36.25 ms per token,    27.59 tokens per second)\n",
      "llama_print_timings:       total time =   21262.94 ms /   747 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.64 ms /   512 runs   (    0.16 ms per token,  6349.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14739.42 ms /  2033 tokens (    7.25 ms per token,   137.93 tokens per second)\n",
      "llama_print_timings:        eval time =   24121.09 ms /   511 runs   (   47.20 ms per token,    21.18 tokens per second)\n",
      "llama_print_timings:       total time =   39388.87 ms /  2544 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      99.11 ms /   512 runs   (    0.19 ms per token,  5166.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     679.91 ms /   105 tokens (    6.48 ms per token,   154.43 tokens per second)\n",
      "llama_print_timings:        eval time =   18271.21 ms /   511 runs   (   35.76 ms per token,    27.97 tokens per second)\n",
      "llama_print_timings:       total time =   19327.61 ms /   616 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.02 ms /   512 runs   (    0.14 ms per token,  7312.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13485.21 ms /  1871 tokens (    7.21 ms per token,   138.74 tokens per second)\n",
      "llama_print_timings:        eval time =   22951.49 ms /   511 runs   (   44.91 ms per token,    22.26 tokens per second)\n",
      "llama_print_timings:       total time =   36778.75 ms /  2382 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.62 ms /   512 runs   (    0.14 ms per token,  7148.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1461.57 ms /   191 tokens (    7.65 ms per token,   130.68 tokens per second)\n",
      "llama_print_timings:        eval time =   17695.48 ms /   511 runs   (   34.63 ms per token,    28.88 tokens per second)\n",
      "llama_print_timings:       total time =   19499.33 ms /   702 tokens\n",
      " 86%|████████▌ | 297/346 [2:20:52<21:02, 25.76s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      85.67 ms /   512 runs   (    0.17 ms per token,  5976.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6059.55 ms /   871 tokens (    6.96 ms per token,   143.74 tokens per second)\n",
      "llama_print_timings:        eval time =   19802.12 ms /   511 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
      "llama_print_timings:       total time =   26224.91 ms /  1382 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.75 ms /   512 runs   (    0.14 ms per token,  7237.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12090.60 ms /  1683 tokens (    7.18 ms per token,   139.20 tokens per second)\n",
      "llama_print_timings:        eval time =   23443.68 ms /   511 runs   (   45.88 ms per token,    21.80 tokens per second)\n",
      "llama_print_timings:       total time =   35885.22 ms /  2194 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      76.32 ms /   512 runs   (    0.15 ms per token,  6708.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4638.10 ms /   716 tokens (    6.48 ms per token,   154.37 tokens per second)\n",
      "llama_print_timings:        eval time =   19184.22 ms /   511 runs   (   37.54 ms per token,    26.64 tokens per second)\n",
      "llama_print_timings:       total time =   24170.34 ms /  1227 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      79.04 ms /   512 runs   (    0.15 ms per token,  6477.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   13266.19 ms /  1770 tokens (    7.50 ms per token,   133.42 tokens per second)\n",
      "llama_print_timings:        eval time =   24194.68 ms /   511 runs   (   47.35 ms per token,    21.12 tokens per second)\n",
      "llama_print_timings:       total time =   37976.24 ms /  2281 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.55 ms /   512 runs   (    0.14 ms per token,  7155.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3644.28 ms /   565 tokens (    6.45 ms per token,   155.04 tokens per second)\n",
      "llama_print_timings:        eval time =   18600.28 ms /   511 runs   (   36.40 ms per token,    27.47 tokens per second)\n",
      "llama_print_timings:       total time =   22571.96 ms /  1076 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.95 ms /   512 runs   (    0.14 ms per token,  7115.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1635.13 ms /   265 tokens (    6.17 ms per token,   162.07 tokens per second)\n",
      "llama_print_timings:        eval time =   18662.00 ms /   511 runs   (   36.52 ms per token,    27.38 tokens per second)\n",
      "llama_print_timings:       total time =   20625.65 ms /   776 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.75 ms /   512 runs   (    0.16 ms per token,  6340.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2496.87 ms /   410 tokens (    6.09 ms per token,   164.21 tokens per second)\n",
      "llama_print_timings:        eval time =   18741.02 ms /   511 runs   (   36.68 ms per token,    27.27 tokens per second)\n",
      "llama_print_timings:       total time =   21735.82 ms /   921 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.86 ms /   512 runs   (    0.14 ms per token,  7225.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2407.25 ms /   351 tokens (    6.86 ms per token,   145.81 tokens per second)\n",
      "llama_print_timings:        eval time =   18042.58 ms /   511 runs   (   35.31 ms per token,    28.32 tokens per second)\n",
      "llama_print_timings:       total time =   20773.45 ms /   862 tokens\n",
      " 88%|████████▊ | 305/346 [2:24:22<17:42, 25.91s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.87 ms /   512 runs   (    0.14 ms per token,  7224.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   11024.49 ms /  1550 tokens (    7.11 ms per token,   140.60 tokens per second)\n",
      "llama_print_timings:        eval time =   21937.67 ms /   511 runs   (   42.93 ms per token,    23.29 tokens per second)\n",
      "llama_print_timings:       total time =   33304.02 ms /  2061 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     103.70 ms /   512 runs   (    0.20 ms per token,  4937.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.85 ms /   192 tokens (    6.39 ms per token,   156.50 tokens per second)\n",
      "llama_print_timings:        eval time =   18581.66 ms /   511 runs   (   36.36 ms per token,    27.50 tokens per second)\n",
      "llama_print_timings:       total time =   20192.33 ms /   703 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      70.77 ms /   512 runs   (    0.14 ms per token,  7234.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10199.78 ms /  1395 tokens (    7.31 ms per token,   136.77 tokens per second)\n",
      "llama_print_timings:        eval time =   21475.74 ms /   511 runs   (   42.03 ms per token,    23.79 tokens per second)\n",
      "llama_print_timings:       total time =   32018.38 ms /  1906 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      83.76 ms /   512 runs   (    0.16 ms per token,  6112.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2032.30 ms /   291 tokens (    6.98 ms per token,   143.19 tokens per second)\n",
      "llama_print_timings:        eval time =   18750.85 ms /   511 runs   (   36.69 ms per token,    27.25 tokens per second)\n",
      "llama_print_timings:       total time =   21324.91 ms /   802 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      84.88 ms /   512 runs   (    0.17 ms per token,  6032.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6901.71 ms /   985 tokens (    7.01 ms per token,   142.72 tokens per second)\n",
      "llama_print_timings:        eval time =   20780.32 ms /   511 runs   (   40.67 ms per token,    24.59 tokens per second)\n",
      "llama_print_timings:       total time =   28202.65 ms /  1496 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     124.23 ms /   512 runs   (    0.24 ms per token,  4121.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1578.25 ms /   247 tokens (    6.39 ms per token,   156.50 tokens per second)\n",
      "llama_print_timings:        eval time =   19420.42 ms /   511 runs   (   38.00 ms per token,    26.31 tokens per second)\n",
      "llama_print_timings:       total time =   21587.69 ms /   758 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      76.59 ms /   512 runs   (    0.15 ms per token,  6685.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5635.51 ms /   829 tokens (    6.80 ms per token,   147.10 tokens per second)\n",
      "llama_print_timings:        eval time =   19616.53 ms /   511 runs   (   38.39 ms per token,    26.05 tokens per second)\n",
      "llama_print_timings:       total time =   25607.07 ms /  1340 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      74.12 ms /   512 runs   (    0.14 ms per token,  6907.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2489.48 ms /   331 tokens (    7.52 ms per token,   132.96 tokens per second)\n",
      "llama_print_timings:        eval time =   18174.77 ms /   511 runs   (   35.57 ms per token,    28.12 tokens per second)\n",
      "llama_print_timings:       total time =   21013.95 ms /   842 tokens\n",
      " 90%|█████████ | 313/346 [2:27:45<14:10, 25.76s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =     113.56 ms /   512 runs   (    0.22 ms per token,  4508.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3150.25 ms /   478 tokens (    6.59 ms per token,   151.73 tokens per second)\n",
      "llama_print_timings:        eval time =   18496.21 ms /   511 runs   (   36.20 ms per token,    27.63 tokens per second)\n",
      "llama_print_timings:       total time =   22044.69 ms /   989 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.22 ms /   512 runs   (    0.16 ms per token,  6382.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15658.51 ms /  2056 tokens (    7.62 ms per token,   131.30 tokens per second)\n",
      "llama_print_timings:        eval time =   25791.33 ms /   511 runs   (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_print_timings:       total time =   41981.30 ms /  2567 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      87.61 ms /   512 runs   (    0.17 ms per token,  5843.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2003.47 ms /   321 tokens (    6.24 ms per token,   160.22 tokens per second)\n",
      "llama_print_timings:        eval time =   18527.92 ms /   511 runs   (   36.26 ms per token,    27.58 tokens per second)\n",
      "llama_print_timings:       total time =   21076.73 ms /   832 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.03 ms /   512 runs   (    0.14 ms per token,  7208.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15598.62 ms /  2145 tokens (    7.27 ms per token,   137.51 tokens per second)\n",
      "llama_print_timings:        eval time =   24142.30 ms /   511 runs   (   47.25 ms per token,    21.17 tokens per second)\n",
      "llama_print_timings:       total time =   40093.65 ms /  2656 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      78.70 ms /   512 runs   (    0.15 ms per token,  6505.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3026.59 ms /   469 tokens (    6.45 ms per token,   154.96 tokens per second)\n",
      "llama_print_timings:        eval time =   18272.30 ms /   511 runs   (   35.76 ms per token,    27.97 tokens per second)\n",
      "llama_print_timings:       total time =   21642.88 ms /   980 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      78.44 ms /   512 runs   (    0.15 ms per token,  6527.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1213.79 ms /   191 tokens (    6.35 ms per token,   157.36 tokens per second)\n",
      "llama_print_timings:        eval time =   18437.09 ms /   511 runs   (   36.08 ms per token,    27.72 tokens per second)\n",
      "llama_print_timings:       total time =   19995.09 ms /   702 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      72.79 ms /   512 runs   (    0.14 ms per token,  7034.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1925.18 ms /   307 tokens (    6.27 ms per token,   159.47 tokens per second)\n",
      "llama_print_timings:        eval time =   17722.60 ms /   511 runs   (   34.68 ms per token,    28.83 tokens per second)\n",
      "llama_print_timings:       total time =   19997.45 ms /   818 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      71.79 ms /   512 runs   (    0.14 ms per token,  7131.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2187.40 ms /   278 tokens (    7.87 ms per token,   127.09 tokens per second)\n",
      "llama_print_timings:        eval time =   17978.76 ms /   511 runs   (   35.18 ms per token,    28.42 tokens per second)\n",
      "llama_print_timings:       total time =   20510.30 ms /   789 tokens\n",
      " 93%|█████████▎| 321/346 [2:31:13<10:45, 25.81s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      94.09 ms /   512 runs   (    0.18 ms per token,  5441.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2736.99 ms /   423 tokens (    6.47 ms per token,   154.55 tokens per second)\n",
      "llama_print_timings:        eval time =   18815.55 ms /   511 runs   (   36.82 ms per token,    27.16 tokens per second)\n",
      "llama_print_timings:       total time =   22086.32 ms /   934 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      91.17 ms /   512 runs   (    0.18 ms per token,  5615.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1060.29 ms /   152 tokens (    6.98 ms per token,   143.36 tokens per second)\n",
      "llama_print_timings:        eval time =   18940.30 ms /   511 runs   (   37.07 ms per token,    26.98 tokens per second)\n",
      "llama_print_timings:       total time =   20527.30 ms /   663 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      74.74 ms /   512 runs   (    0.15 ms per token,  6850.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2466.26 ms /   264 tokens (    9.34 ms per token,   107.04 tokens per second)\n",
      "llama_print_timings:        eval time =   17583.63 ms /   511 runs   (   34.41 ms per token,    29.06 tokens per second)\n",
      "llama_print_timings:       total time =   20399.20 ms /   775 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      82.72 ms /   512 runs   (    0.16 ms per token,  6189.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1561.92 ms /   242 tokens (    6.45 ms per token,   154.94 tokens per second)\n",
      "llama_print_timings:        eval time =   18567.28 ms /   511 runs   (   36.34 ms per token,    27.52 tokens per second)\n",
      "llama_print_timings:       total time =   20664.93 ms /   753 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.50 ms /   512 runs   (    0.16 ms per token,  6359.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7700.74 ms /  1123 tokens (    6.86 ms per token,   145.83 tokens per second)\n",
      "llama_print_timings:        eval time =   21375.63 ms /   511 runs   (   41.83 ms per token,    23.91 tokens per second)\n",
      "llama_print_timings:       total time =   29582.93 ms /  1634 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.86 ms /   512 runs   (    0.14 ms per token,  7329.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6268.95 ms /   745 tokens (    8.41 ms per token,   118.84 tokens per second)\n",
      "llama_print_timings:        eval time =   20286.59 ms /   511 runs   (   39.70 ms per token,    25.19 tokens per second)\n",
      "llama_print_timings:       total time =   26884.72 ms /  1256 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.76 ms /   512 runs   (    0.16 ms per token,  6339.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6551.59 ms /   968 tokens (    6.77 ms per token,   147.75 tokens per second)\n",
      "llama_print_timings:        eval time =   20660.47 ms /   511 runs   (   40.43 ms per token,    24.73 tokens per second)\n",
      "llama_print_timings:       total time =   27721.05 ms /  1479 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.40 ms /   512 runs   (    0.16 ms per token,  6368.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5474.77 ms /   837 tokens (    6.54 ms per token,   152.88 tokens per second)\n",
      "llama_print_timings:        eval time =   20593.50 ms /   511 runs   (   40.30 ms per token,    24.81 tokens per second)\n",
      "llama_print_timings:       total time =   26573.62 ms /  1348 tokens\n",
      " 95%|█████████▌| 329/346 [2:34:27<07:11, 25.36s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      81.03 ms /   512 runs   (    0.16 ms per token,  6318.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3419.93 ms /   527 tokens (    6.49 ms per token,   154.10 tokens per second)\n",
      "llama_print_timings:        eval time =   19209.27 ms /   511 runs   (   37.59 ms per token,    26.60 tokens per second)\n",
      "llama_print_timings:       total time =   23129.68 ms /  1038 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      73.67 ms /   512 runs   (    0.14 ms per token,  6949.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1081.92 ms /   172 tokens (    6.29 ms per token,   158.98 tokens per second)\n",
      "llama_print_timings:        eval time =   18357.64 ms /   511 runs   (   35.92 ms per token,    27.84 tokens per second)\n",
      "llama_print_timings:       total time =   19772.41 ms /   683 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      84.26 ms /   512 runs   (    0.16 ms per token,  6076.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2335.51 ms /   367 tokens (    6.36 ms per token,   157.14 tokens per second)\n",
      "llama_print_timings:        eval time =   18621.19 ms /   511 runs   (   36.44 ms per token,    27.44 tokens per second)\n",
      "llama_print_timings:       total time =   21489.36 ms /   878 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      86.43 ms /   512 runs   (    0.17 ms per token,  5923.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1623.70 ms /   265 tokens (    6.13 ms per token,   163.21 tokens per second)\n",
      "llama_print_timings:        eval time =   18504.36 ms /   511 runs   (   36.21 ms per token,    27.62 tokens per second)\n",
      "llama_print_timings:       total time =   20667.66 ms /   776 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.62 ms /   512 runs   (    0.16 ms per token,  6350.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   10864.13 ms /  1550 tokens (    7.01 ms per token,   142.67 tokens per second)\n",
      "llama_print_timings:        eval time =   22901.81 ms /   511 runs   (   44.82 ms per token,    22.31 tokens per second)\n",
      "llama_print_timings:       total time =   34281.50 ms /  2061 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      80.11 ms /   512 runs   (    0.16 ms per token,  6390.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9070.62 ms /  1296 tokens (    7.00 ms per token,   142.88 tokens per second)\n",
      "llama_print_timings:        eval time =   22957.62 ms /   511 runs   (   44.93 ms per token,    22.26 tokens per second)\n",
      "llama_print_timings:       total time =   32545.28 ms /  1807 tokens\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      79.99 ms /   512 runs   (    0.16 ms per token,  6401.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9575.28 ms /  1396 tokens (    6.86 ms per token,   145.79 tokens per second)\n",
      "llama_print_timings:        eval time =   22564.04 ms /   511 runs   (   44.16 ms per token,    22.65 tokens per second)\n",
      "llama_print_timings:       total time =   32650.38 ms /  1907 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      69.48 ms /   512 runs   (    0.14 ms per token,  7368.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    9330.61 ms /  1388 tokens (    6.72 ms per token,   148.76 tokens per second)\n",
      "llama_print_timings:        eval time =   21620.65 ms /   511 runs   (   42.31 ms per token,    23.63 tokens per second)\n",
      "llama_print_timings:       total time =   31286.94 ms /  1899 tokens\n",
      " 97%|█████████▋| 337/346 [2:38:03<03:52, 25.85s/it]\n",
      "llama_print_timings:        load time =    2114.37 ms\n",
      "llama_print_timings:      sample time =      78.21 ms /   512 runs   (    0.15 ms per token,  6546.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3227.84 ms /   502 tokens (    6.43 ms per token,   155.52 tokens per second)\n",
      "llama_print_timings:        eval time =   18360.01 ms /   511 runs   (   35.93 ms per token,    27.83 tokens per second)\n",
      "llama_print_timings:       total time =   21927.90 ms /  1013 tokens\n",
      "100%|██████████| 346/346 [2:38:25<00:00, 27.47s/it]\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model)\n",
    "\n",
    "faithfulness = FaithfulnessEvaluator(service_context=service_context)\n",
    "relevancy = RelevancyEvaluator(service_context=service_context)\n",
    "\n",
    "batch_eval_queries = broad_queries\n",
    "\n",
    "# Initiate BatchEvalRunner to compute FaithFulness and Relevancy Evaluation.\n",
    "runner = BatchEvalRunner(\n",
    "    {\"faithfulness\": faithfulness, \"relevancy\": relevancy},\n",
    "    workers=8,\n",
    "    show_progress=True\n",
    ")\n",
    "query_engine = index.as_query_engine(llm=llm, similar_top_k=3)\n",
    "# Compute evaluation\n",
    "eval_results = await runner.aevaluate_queries(\n",
    "    query_engine, queries=batch_eval_queries\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness_score 0.21965317919075145\n",
      "relevancy_score 0.1676300578034682\n"
     ]
    }
   ],
   "source": [
    "# Let's get faithfulness score\n",
    "\n",
    "faithfulness_score = sum(result.passing for result in eval_results['faithfulness']) / len(eval_results['faithfulness'])\n",
    "print(\"faithfulness_score\", faithfulness_score)\n",
    "\n",
    "# Let's get relevancy score\n",
    "\n",
    "relevancy_score = sum(result.passing for result in eval_results['relevancy']) / len(eval_results['relevancy'])\n",
    "print(\"relevancy_score\", relevancy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
