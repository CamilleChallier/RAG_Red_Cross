{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph RAG experimentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nvme/home/durech/camille/rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-09-18 16:14:38.315067: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-18 16:14:38.322861: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-18 16:14:38.331731: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-18 16:14:38.334529: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-18 16:14:38.342025: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-18 16:14:38.861109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-xqqr5e_k because the default path (/mnt/nvme/home/durech/camille/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'wurlitzer', 'leidenalg', 'bayanpy', 'graph_tool', 'infomap'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'pyclustering', 'ASLPAw'}\n",
      "Note: to be able to use all crisp methods, you need to install some additional packages:  {'leidenalg', 'infomap', 'wurlitzer'}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply asyncio modifications\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Llama Index imports\n",
    "from llama_index.core import (\n",
    "    KnowledgeGraphIndex,\n",
    "    StorageContext\n",
    ")\n",
    "from llama_index.core.graph_stores import SimpleGraphStore\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "\n",
    "# Llama Index embeddings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Llama Index LLMs\n",
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "\n",
    "# Graph stores\n",
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "from graphs import triplets_extraction, GraphRAGExtractor, parse_fn, GraphRAGStore, graph_rag_pipeline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils import retriever_evaluation, display_results_retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 27 key-value pairs and 291 tensors from /tmp/llama_index/models/Meta-Llama-3-8B-Instruct.Q4_0.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Models\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 8.0B\n",
      "llama_model_loader: - kv   4:                            general.license str              = llama3\n",
      "llama_model_loader: - kv   5:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   6:                          general.languages arr[str,1]       = [\"en\"]\n",
      "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   8:                       llama.context_length u32              = 8192\n",
      "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  16:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  17:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  25:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
      "llama_model_loader: - kv  26:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_0:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 8B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.33 GiB (4.64 BPW) \n",
      "llm_load_print_meta: general.name     = Models\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4437.80 MiB\n",
      ".......................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 3904\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: flash_attn = 0\n",
      "llama_new_context_with_model: freq_base  = 500000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   488.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  488.00 MiB, K (f16):  244.00 MiB, V (f16):  244.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   283.63 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1030\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 0 | \n",
      "Model metadata: {'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Models', 'general.type': 'model', 'general.size_label': '8.0B', 'general.license': 'llama3', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: llama-3\n",
      "You try to use a model that was created with version 3.0.1, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "Some weights of the model checkpoint at dunzhang/stella_en_400M_v5 were not used when initializing NewModel: ['new.pooler.dense.bias', 'new.pooler.dense.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_url = \"https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q4_0.gguf\"\n",
    "llm_llama3 = LlamaCPP(\n",
    "    model_url=model_url,\n",
    "    model_path=None,\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=512,\n",
    "    context_window=3900,\n",
    "    generate_kwargs={},\n",
    "    model_kwargs={\"n_gpu_layers\": -1},\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name = \"dunzhang/stella_en_400M_v5\", device = \"cuda\", trust_remote_code=True, embed_batch_size=20)\n",
    "\n",
    "nodes = pickle.load(open('nodes_icrc_english.pkl','rb'))\n",
    "qa_dataset = pickle.load(open(\"qa_dataset_icrc_500.pkl\",'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sciphi Triplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing nodes:   0%|          | 0/2 [00:00<?, ?it/s]`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.70it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n",
      "Generating embeddings: 100%|██████████| 5/5 [00:00<00:00, 158.82it/s]\n",
      "Processing nodes:  50%|█████     | 1/2 [00:38<00:38, 38.78s/it]`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.69it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Generating embeddings: 100%|██████████| 5/5 [00:00<00:00, 296.63it/s]\n",
      "Processing nodes: 100%|██████████| 2/2 [01:13<00:00, 36.97s/it]\n"
     ]
    }
   ],
   "source": [
    "#setup the storage context\n",
    "graph_store = SimpleGraphStore()\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "# Construct the Knowlege Graph Undex\n",
    "index = KnowledgeGraphIndex(nodes,\n",
    "                                llm = llm_llama3,\n",
    "                                max_triplets_per_chunk=5,\n",
    "                                kg_triplet_extract_fn=triplets_extraction,\n",
    "                                storage_context=storage_context,\n",
    "                                embed_model=embed_model,\n",
    "                                include_embeddings=True,\n",
    "                                show_progress=True,\n",
    "                                )\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    2112.14 ms\n",
      "llama_print_timings:      sample time =      45.85 ms /    87 runs   (    0.53 ms per token,  1897.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2112.04 ms /    91 tokens (   23.21 ms per token,    43.09 tokens per second)\n",
      "llama_print_timings:        eval time =    8073.26 ms /    86 runs   (   93.88 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:       total time =   10284.95 ms /   177 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "base_retriever = index.as_retriever(similarity_top_k=3)\n",
    "base_retriever_evaluator = retriever_evaluation(base_retriever)\n",
    "\n",
    "base_eval_results = await base_retriever_evaluator.aevaluate_dataset(qa_dataset,workers=10, show_progress=True, kwargs={\"device\":\"cuda\", \"n_gpu_layers\": -1})\n",
    "display_results_retriever(\"Base Retriever\", base_eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_triplex_plot.html\n"
     ]
    }
   ],
   "source": [
    "#save the network\n",
    "\n",
    "from pyvis.network import Network\n",
    "from IPython.display import display\n",
    "g = index.get_networkx_graph()\n",
    "net = Network(notebook=True,cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "net.show(\"graph_triplex_plot.html\")\n",
    "net.save_graph(\"Knowledge_graph.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphRag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KG_TRIPLET_EXTRACT_TMPL = \"\"\"\n",
    "-Goal-\n",
    "Given a text document, identify all entities and their entity types from the text and all relationships among the identified entities.\n",
    "Given the text, extract up to {max_knowledge_triplets} entity-relation triplets.\n",
    "\n",
    "-Steps-\n",
    "1. Identify all entities. For each identified entity, extract the following information:\n",
    "- entity_name: Name of the entity, capitalized\n",
    "- entity_type: Type of the entity\n",
    "- entity_description: Comprehensive description of the entity's attributes and activities\n",
    "Format each entity as (\"entity\")\n",
    "\n",
    "2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\n",
    "For each pair of related entities, extract the following information:\n",
    "- source_entity: name of the source entity, as identified in step 1\n",
    "- target_entity: name of the target entity, as identified in step 1\n",
    "- relation: relationship between source_entity and target_entity\n",
    "- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n",
    "\n",
    "Format each relationship as (\"relationship\"$$$$<source_entity>$$$$<target_entity>$$$$<relation>$$$$<relationship_description>)\n",
    "\n",
    "3. When finished, output.\n",
    "\n",
    "-Real Data-\n",
    "######################\n",
    "text: {text}\n",
    "######################\n",
    "output:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_extractor = GraphRAGExtractor(\n",
    "    llm=llm_llama3,\n",
    "    extract_prompt=KG_TRIPLET_EXTRACT_TMPL,\n",
    "    max_paths_per_chunk=5,\n",
    "    parse_fn=parse_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "llama_print_timings:        load time =   11677.27 ms\n",
      "llama_print_timings:      sample time =     185.33 ms /   329 runs   (    0.56 ms per token,  1775.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12676.46 ms /   555 tokens (   22.84 ms per token,    43.78 tokens per second)\n",
      "llama_print_timings:        eval time =   32945.96 ms /   328 runs   (  100.44 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =   46146.55 ms /   883 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   11677.27 ms\n",
      "llama_print_timings:      sample time =     298.52 ms /   512 runs   (    0.58 ms per token,  1715.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4411.62 ms /   168 tokens (   26.26 ms per token,    38.08 tokens per second)\n",
      "llama_print_timings:        eval time =   51129.42 ms /   511 runs   (  100.06 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =   56428.96 ms /   679 tokens\n",
      "Extracting paths from text: 100%|██████████| 2/2 [01:42<00:00, 51.29s/it] \n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  7.53it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "index = PropertyGraphIndex(\n",
    "    embed_model=embed_model,\n",
    "    nodes=nodes,\n",
    "    property_graph_store=GraphRAGStore(),\n",
    "    kg_extractors=[kg_extractor],\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.property_graph_store.build_communities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "index.property_graph_store.save_networkx_graph(name=f\"./Graphs_openai.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:52<00:00,  2.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retriever Name</th>\n",
       "      <th>mrr</th>\n",
       "      <th>hit_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base Retriever</td>\n",
       "      <td>0.154467</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Retriever Name       mrr  hit_rate\n",
       "0  Base Retriever  0.154467      0.23"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation\n",
    "base_retriever = index.as_retriever(similarity_top_k=3)\n",
    "base_retriever_evaluator = retriever_evaluation(base_retriever)\n",
    "\n",
    "base_eval_results = await base_retriever_evaluator.aevaluate_dataset(qa_dataset,workers=10, show_progress=True, kwargs={\"device\":\"cuda\", \"n_gpu_layers\": -1})\n",
    "display_results_retriever(\"Base Retriever\", base_eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup the storage context\n",
    "graph_store = SimpleGraphStore()\n",
    "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
    "\n",
    "index = PropertyGraphIndex(\n",
    "    llm=llm_llama3,\n",
    "    embed_model=embed_model,\n",
    "    nodes=nodes,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "#Construct the Knowlege Graph Undex\n",
    "index = KnowledgeGraphIndex(nodes,\n",
    "                                           storage_context=storage_context,\n",
    "                                           embed_model=embed_model,\n",
    "                                          include_embeddings=True,\n",
    "                                          show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "from IPython.display import display\n",
    "g = index.get_networkx_graph()\n",
    "net = Network(notebook=True,cdn_resources=\"in_line\",directed=True)\n",
    "net.from_nx(g)\n",
    "net.show(\"graph10.html\")\n",
    "net.save_graph(\"Knowledge_graph.html\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "base_retriever = index.as_retriever(similarity_top_k=3)\n",
    "base_retriever_evaluator = retriever_evaluation(base_retriever)\n",
    "base_eval_results = await base_retriever_evaluator.aevaluate_dataset(qa_dataset)\n",
    "display_results_retriever(\"Base Retriever\", base_eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_store = Neo4jPropertyGraphStore(\n",
    "    username=\"neo4j\",\n",
    "    password=\"5hpb3rDtp99mgtFbFu68xJP19xlM3sBL5-pwdFZ5JpE\",\n",
    "    url=\"neo4j+s://4a10d0f8.databases.neo4j.io\",\n",
    ")#to complete with account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema: 100%|██████████| 500/500 [12:59<00:00,  1.56s/it]\n",
      "Generating embeddings: 100%|██████████| 25/25 [00:11<00:00,  2.09it/s]\n",
      "Generating embeddings: 100%|██████████| 60/60 [00:14<00:00,  4.09it/s]\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (e, row) { ... }} {position: line: 10, column: 21, offset: 397} for query: \"\\n                    UNWIND $data AS row\\n                    MERGE (e:__Node__ {id: row.id})\\n                    SET e += apoc.map.clean(row.properties, [], [])\\n                    SET e.name = row.name, e:`__Entity__`\\n                    WITH e, row\\n                    CALL apoc.create.addLabels(e, [row.label])\\n                    YIELD node\\n                    WITH e, row\\n                    CALL {\\n                        WITH e, row\\n                        WITH e, row\\n                        WHERE row.embedding IS NOT NULL\\n                        CALL db.create.setNodeVectorProperty(e, 'embedding', row.embedding)\\n                        RETURN count(*) AS count\\n                    }\\n                    WITH e, row WHERE row.properties.triplet_source_id IS NOT NULL\\n                    MERGE (c:__Node__ {id: row.properties.triplet_source_id})\\n                    MERGE (e)<-[:MENTIONS]-(c)\\n                    \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (e, row) { ... }} {position: line: 10, column: 21, offset: 397} for query: \"\\n                    UNWIND $data AS row\\n                    MERGE (e:__Node__ {id: row.id})\\n                    SET e += apoc.map.clean(row.properties, [], [])\\n                    SET e.name = row.name, e:`__Entity__`\\n                    WITH e, row\\n                    CALL apoc.create.addLabels(e, [row.label])\\n                    YIELD node\\n                    WITH e, row\\n                    CALL {\\n                        WITH e, row\\n                        WITH e, row\\n                        WHERE row.embedding IS NOT NULL\\n                        CALL db.create.setNodeVectorProperty(e, 'embedding', row.embedding)\\n                        RETURN count(*) AS count\\n                    }\\n                    WITH e, row WHERE row.properties.triplet_source_id IS NOT NULL\\n                    MERGE (c:__Node__ {id: row.properties.triplet_source_id})\\n                    MERGE (e)<-[:MENTIONS]-(c)\\n                    \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The procedure has a deprecated field. ('config' used by 'apoc.meta.graphSample' is deprecated.)} {position: line: 1, column: 1, offset: 0} for query: \"CALL apoc.meta.graphSample() YIELD nodes, relationships RETURN nodes, [rel in relationships | {name:apoc.any.property(rel, 'type'), count: apoc.any.property(rel, 'count')}] AS relationships\"\n"
     ]
    }
   ],
   "source": [
    "#create graph\n",
    "index = PropertyGraphIndex(\n",
    "    nodes,\n",
    "    embed_model=embed_model,\n",
    "    kg_extractors=[\n",
    "        SchemaLLMPathExtractor(\n",
    "            llm=llm_llama3\n",
    "        )\n",
    "    ],\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:27<00:00,  1.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retriever Name</th>\n",
       "      <th>mrr</th>\n",
       "      <th>hit_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base Retriever</td>\n",
       "      <td>0.09286</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Retriever Name      mrr  hit_rate\n",
       "0  Base Retriever  0.09286     0.136"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation\n",
    "base_retriever = index.as_retriever(similarity_top_k=3)\n",
    "base_retriever_evaluator = retriever_evaluation(base_retriever)\n",
    "\n",
    "base_eval_results = await base_retriever_evaluator.aevaluate_dataset(qa_dataset,workers=10, show_progress=True, kwargs={\"device\":\"cuda\", \"n_gpu_layers\": -1})\n",
    "display_results_retriever(\"Base Retriever\", base_eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify the kg extraction with predefined relationship\n",
    "\n",
    "from typing import Literal\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "\n",
    "# best practice to use upper-case\n",
    "entities = Literal[ \"LOCATION\", \"DATE\", \"ENTITIES\", \"ORGANIZATION\", \"PERSON\", \"EVENT\", \"SERVICE\", \"NUMBER\"]\n",
    "relations = Literal[\"HAS\", \"PART_OF\", \"WORKED_ON\", \"PROVIDED_AID_TO\", \"LOCATED_IN\", \"HAPPENED_ON\", \"SUFFERED\", \"PARTNERED_WITH\", \"PROVIDED\", \"AFFECTED_BY\", \"ASKED\"]\n",
    "\n",
    "# define which entities can have which relations\n",
    "validation_schema = {\n",
    "    \"PERSON\": [\"HAS\", \"PART_OF\", \"WORKED_ON\", \"PARTNERED_WITH\", \"SUFFERED\", \"ASKED\"],\n",
    "    \"LOCATION\": [\"HAS\", \"LOCATED_IN\"],\n",
    "    \"ORGANIZATION\": [\"HAS\", \"PART_OF\", \"PARTNERED_WITH\", \"PROVIDED_AID_TO\", \"AFFECTED_BY\", \"PROVIDED\"],\n",
    "    \"ENTITIES\": [\"HAS\", \"PROVIDED_AID_TO\", \"AFFECTED_BY\", \"PROVIDED\", \"SUFFERED\"],\n",
    "    \"EVENT\": [\"HAS\", \"HAPPENED_ON\", \"AFFECTED_BY\", \"SUFFERED\"],\n",
    "    \"SERVICE\": [\"PROVIDED\", \"AFFECTED_BY\"],\n",
    "    \"DATE\": [\"HAPPENED_ON\"]\n",
    "}\n",
    "\n",
    "kg_extractor = SchemaLLMPathExtractor(\n",
    "    llm=llm_llama3,\n",
    "    possible_entities=entities,\n",
    "    possible_relations=relations,\n",
    "    kg_validation_schema=validation_schema,\n",
    "    # if false, allows for values outside of the schema\n",
    "    # useful for using the schema as a suggestion\n",
    "    strict=True,\n",
    ")\n",
    "\n",
    "index = PropertyGraphIndex(\n",
    "    nodes[:500],\n",
    "    kg_extractors=[kg_extractor],\n",
    "    embed_model=embed_model,\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [05:29<00:00,  1.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retriever Name</th>\n",
       "      <th>mrr</th>\n",
       "      <th>hit_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Base Retriever</td>\n",
       "      <td>0.094471</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Retriever Name       mrr  hit_rate\n",
       "0  Base Retriever  0.094471     0.154"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation\n",
    "base_retriever = index.as_retriever(similarity_top_k=3)\n",
    "base_retriever_evaluator = retriever_evaluation(base_retriever)\n",
    "\n",
    "base_eval_results = await base_retriever_evaluator.aevaluate_dataset(qa_dataset,workers=10, show_progress=True, kwargs={\"device\":\"cuda\", \"n_gpu_layers\": -1})\n",
    "display_results_retriever(\"Base Retriever\", base_eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
